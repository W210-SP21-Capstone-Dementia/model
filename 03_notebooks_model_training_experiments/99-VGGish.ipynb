{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_io as tfio\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "import pathlib\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from plotnine import *\n",
    "import seaborn as sn\n",
    "%matplotlib inline\n",
    "\n",
    "seed = 30\n",
    "tf.random.set_seed(seed)\n",
    "gpus = tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## need this if training on GPU\n",
    "## tensorflow, get your shit together\n",
    "\n",
    "if len(gpus)>0:\n",
    "\n",
    "    from tensorflow.compat.v1 import ConfigProto\n",
    "    from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "    config = ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/tf/data/ADReSS-IS2020'\n",
    "\n",
    "filenames = tf.random.shuffle(tf.io.gfile.glob(data_path + '/Full_wave_enhanced_audio/*/*'))\n",
    "\n",
    "train_cutoff = int(len(filenames)*0.7)\n",
    "val_cutoff = int(len(filenames)*0.85)\n",
    "\n",
    "train_files = filenames[:train_cutoff]\n",
    "val_files = filenames[train_cutoff:val_cutoff]\n",
    "test_files = filenames[val_cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_cc = pd.read_csv(data_path + '/cc_meta_data.txt', sep=\";\", header=0, \n",
    "                  names = ['ID', 'Age', 'Gender', 'MMSE'])\n",
    "meta_cd = pd.read_csv(data_path + '/cd_meta_data.txt', sep=\";\", header=0, \n",
    "                      names = ['ID', 'Age', 'Gender', 'MMSE'])\n",
    "\n",
    "meta = meta_cc.assign(Group = 'cc').append(meta_cd.assign(Group = 'cd')).reset_index()\n",
    "meta.MMSE = pd.to_numeric(meta.MMSE.replace(' NA', 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_sec = 30\n",
    "stride_sec = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vggish = hub.load('https://tfhub.dev/google/vggish/1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window(x, size, stride):\n",
    "    length = int(len(x))\n",
    "    if length // size == 0:\n",
    "        zero_padding =  tf.zeros([size] - tf.shape(x), dtype=tf.float32)\n",
    "        x = tf.cast(x, tf.float32)\n",
    "        x = tf.concat([x, zero_padding], 0)\n",
    "        length = int(len(x))\n",
    "    return tf.map_fn(lambda i: x[i*stride:i*stride+size], tf.range((length-size)//stride+1), dtype=tf.float32)\n",
    "\n",
    "def get_data(file_path):\n",
    "\n",
    "    names = meta.ID\n",
    "    name = tf.strings.split(tf.strings.split(file_path, os.path.sep)[-1], '.')[0] + ' '\n",
    "    label = tf.gather(meta.MMSE, tf.where(tf.equal(names, name))[0][0])\n",
    "    \n",
    "    audio_binary = tf.io.read_file(file_path)\n",
    "    audio, _ = tf.audio.decode_wav(audio_binary)\n",
    "    waveform = tf.squeeze(audio, axis=-1)\n",
    "    \n",
    "    resampled_waveform = tfio.audio.resample(\n",
    "        waveform, 44100, 16000, name=None\n",
    "    )\n",
    "        \n",
    "    rolling_waveform_tensors = window(waveform, size=_*size_sec, stride=_*stride_sec)\n",
    "        \n",
    "    return rolling_waveform_tensors, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(files):\n",
    "    files_ds = tf.data.Dataset.from_tensor_slices(files)\n",
    "    output_ds = files_ds.map(get_data, num_parallel_calls=AUTOTUNE)\\\n",
    "                        .flat_map(lambda x,y: tf.data.Dataset.zip((\n",
    "                                    tf.data.Dataset.from_tensor_slices(x), \n",
    "                                    tf.data.Dataset.from_tensor_slices([y])\n",
    "                        )))\\\n",
    "                        .map(lambda x,y: (vggish(x),y))\\\n",
    "                        .cache()\\\n",
    "                        .prefetch(1000)\\\n",
    "                        .shuffle(1000)\n",
    "    return output_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:605: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:605: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n"
     ]
    }
   ],
   "source": [
    "train_ds = preprocess_dataset(train_files)\n",
    "val_ds = preprocess_dataset(val_files)\n",
    "test_ds = preprocess_dataset(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(86, 128)\n",
      "tf.Tensor(28, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for waveform, y in train_ds.take(1):\n",
    "    input_shape = waveform.shape\n",
    "    print(input_shape)\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_ds_b = train_ds.batch(batch_size)\n",
    "val_ds_b = val_ds.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_layer = preprocessing.Normalization()\n",
    "norm_layer.adapt(train_ds.map(lambda x, _: x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (86, 128)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 86, 128)           0         \n",
      "_________________________________________________________________\n",
      "normalization (Normalization (None, 86, 128)           257       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 86, 256)           33024     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 86, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 86, 128)           197120    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 86, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 281,922\n",
      "Trainable params: 281,665\n",
      "Non-trainable params: 257\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print('Input shape:', input_shape)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=input_shape),\n",
    "    layers.Reshape((input_shape[0],input_shape[1])),\n",
    "    norm_layer,\n",
    "    layers.Dense(256,  activation='relu', kernel_initializer='he_normal'),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.LSTM(128, \n",
    "                activation='tanh', \n",
    "                recurrent_activation='sigmoid', \n",
    "                recurrent_dropout=0,\n",
    "                unroll=False,\n",
    "                use_bias=True,\n",
    "                kernel_initializer='he_normal', \n",
    "                return_sequences=True),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.LSTM(64,\n",
    "                activation='tanh', \n",
    "                recurrent_activation='sigmoid', \n",
    "                recurrent_dropout=0,\n",
    "                unroll=False,\n",
    "                use_bias=True,\n",
    "                kernel_initializer='he_normal'),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Dense(32, activation='relu', kernel_initializer='he_normal'),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=200)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, clipnorm=1.0),\n",
    "    loss='mse',\n",
    "    metrics='mse'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "1/1 [==============================] - 37s 37s/step - loss: 608.9354 - mse: 608.9354 - val_loss: 574.6593 - val_mse: 574.6593\n",
      "Epoch 2/10000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 591.4404 - mse: 591.4404 - val_loss: 560.9148 - val_mse: 560.9148\n",
      "Epoch 3/10000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 577.1701 - mse: 577.1701 - val_loss: 548.9226 - val_mse: 548.9226\n",
      "Epoch 4/10000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 565.4528 - mse: 565.4528 - val_loss: 536.5770 - val_mse: 536.5770\n",
      "Epoch 5/10000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 553.3168 - mse: 553.3168 - val_loss: 523.7312 - val_mse: 523.7312\n",
      "Epoch 6/10000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 541.0367 - mse: 541.0367 - val_loss: 511.8730 - val_mse: 511.8730\n",
      "Epoch 7/10000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 527.9200 - mse: 527.9200 - val_loss: 500.5478 - val_mse: 500.5478\n",
      "Epoch 8/10000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 513.9360 - mse: 513.9360 - val_loss: 489.3800 - val_mse: 489.3800\n",
      "Epoch 9/10000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 506.9448 - mse: 506.9448 - val_loss: 478.2487 - val_mse: 478.2487\n",
      "Epoch 10/10000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 496.4819 - mse: 496.4819 - val_loss: 467.3215 - val_mse: 467.3215\n",
      "Epoch 11/10000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 490.0074 - mse: 490.0074 - val_loss: 456.7014 - val_mse: 456.7014\n",
      "Epoch 12/10000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 469.8406 - mse: 469.8406 - val_loss: 446.4190 - val_mse: 446.4190\n",
      "Epoch 13/10000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 463.1307 - mse: 463.1307 - val_loss: 436.3997 - val_mse: 436.3997\n",
      "Epoch 14/10000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 444.0007 - mse: 444.0007 - val_loss: 426.5607 - val_mse: 426.5607\n",
      "Epoch 15/10000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 432.3383 - mse: 432.3383 - val_loss: 416.8479 - val_mse: 416.8479\n",
      "Epoch 16/10000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 445.0157 - mse: 445.0157 - val_loss: 407.3876 - val_mse: 407.3876\n",
      "Epoch 17/10000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 429.2712 - mse: 429.2712 - val_loss: 398.1386 - val_mse: 398.1386\n",
      "Epoch 18/10000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 425.3134 - mse: 425.3134 - val_loss: 389.0474 - val_mse: 389.0474\n",
      "Epoch 19/10000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 413.8128 - mse: 413.8128 - val_loss: 380.0618 - val_mse: 380.0618\n",
      "Epoch 20/10000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 397.8143 - mse: 397.8143 - val_loss: 371.1508 - val_mse: 371.1508\n",
      "Epoch 21/10000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 376.9669 - mse: 376.9669 - val_loss: 362.2883 - val_mse: 362.2883\n",
      "Epoch 22/10000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 386.1444 - mse: 386.1444 - val_loss: 353.4791 - val_mse: 353.4791\n",
      "Epoch 23/10000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 366.0640 - mse: 366.0640 - val_loss: 344.7253 - val_mse: 344.7253\n",
      "Epoch 24/10000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 360.3980 - mse: 360.3980 - val_loss: 336.0837 - val_mse: 336.0837\n",
      "Epoch 25/10000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 355.9461 - mse: 355.9461 - val_loss: 327.5992 - val_mse: 327.5992\n",
      "Epoch 26/10000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 345.9688 - mse: 345.9688 - val_loss: 319.3434 - val_mse: 319.3434\n",
      "Epoch 27/10000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 338.9253 - mse: 338.9253 - val_loss: 311.3754 - val_mse: 311.3754\n",
      "Epoch 28/10000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 332.3305 - mse: 332.3305 - val_loss: 303.7447 - val_mse: 303.7447\n",
      "Epoch 29/10000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 315.6537 - mse: 315.6537 - val_loss: 296.4623 - val_mse: 296.4623\n",
      "Epoch 30/10000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 317.7386 - mse: 317.7386 - val_loss: 289.4945 - val_mse: 289.4945\n",
      "Epoch 31/10000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 310.7461 - mse: 310.7461 - val_loss: 282.8045 - val_mse: 282.8045\n",
      "Epoch 32/10000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 315.2910 - mse: 315.2910 - val_loss: 276.3658 - val_mse: 276.3658\n",
      "Epoch 33/10000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 291.0002 - mse: 291.0002 - val_loss: 270.1170 - val_mse: 270.1170\n",
      "Epoch 34/10000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 286.2981 - mse: 286.2981 - val_loss: 264.0419 - val_mse: 264.0419\n",
      "Epoch 35/10000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 282.3342 - mse: 282.3342 - val_loss: 258.1095 - val_mse: 258.1095\n",
      "Epoch 36/10000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 278.6631 - mse: 278.6631 - val_loss: 252.3164 - val_mse: 252.3164\n",
      "Epoch 37/10000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 260.7899 - mse: 260.7899 - val_loss: 246.6655 - val_mse: 246.6655\n",
      "Epoch 38/10000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 265.1346 - mse: 265.1346 - val_loss: 241.1658 - val_mse: 241.1658\n",
      "Epoch 39/10000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 270.5434 - mse: 270.5434 - val_loss: 235.8031 - val_mse: 235.8031\n",
      "Epoch 40/10000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 251.6930 - mse: 251.6930 - val_loss: 230.5616 - val_mse: 230.5616\n",
      "Epoch 41/10000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 240.6379 - mse: 240.6379 - val_loss: 225.4078 - val_mse: 225.4078\n",
      "Epoch 42/10000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 265.5126 - mse: 265.5126 - val_loss: 220.3460 - val_mse: 220.3460\n",
      "Epoch 43/10000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 263.3149 - mse: 263.3149 - val_loss: 215.3601 - val_mse: 215.3601\n",
      "Epoch 44/10000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 234.0173 - mse: 234.0173 - val_loss: 210.4473 - val_mse: 210.4473\n",
      "Epoch 45/10000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 230.2813 - mse: 230.2813 - val_loss: 205.6098 - val_mse: 205.6098\n",
      "Epoch 46/10000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 240.1641 - mse: 240.1641 - val_loss: 200.8635 - val_mse: 200.8635\n",
      "Epoch 47/10000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 208.8172 - mse: 208.8172 - val_loss: 196.2065 - val_mse: 196.2065\n",
      "Epoch 48/10000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 202.0592 - mse: 202.0592 - val_loss: 191.6172 - val_mse: 191.6172\n",
      "Epoch 49/10000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 214.6991 - mse: 214.6991 - val_loss: 187.1036 - val_mse: 187.1036\n",
      "Epoch 50/10000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 228.1235 - mse: 228.1235 - val_loss: 182.6498 - val_mse: 182.6498\n",
      "Epoch 51/10000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 219.8175 - mse: 219.8175 - val_loss: 178.2556 - val_mse: 178.2556\n",
      "Epoch 52/10000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 200.4962 - mse: 200.4962 - val_loss: 173.9151 - val_mse: 173.9151\n",
      "Epoch 53/10000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 201.2667 - mse: 201.2667 - val_loss: 169.6223 - val_mse: 169.6223\n",
      "Epoch 54/10000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 194.6237 - mse: 194.6237 - val_loss: 165.3802 - val_mse: 165.3802\n",
      "Epoch 55/10000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 181.1544 - mse: 181.1544 - val_loss: 161.1870 - val_mse: 161.1870\n",
      "Epoch 56/10000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 181.4433 - mse: 181.4433 - val_loss: 157.0289 - val_mse: 157.0289\n",
      "Epoch 57/10000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 174.7914 - mse: 174.7914 - val_loss: 152.9059 - val_mse: 152.9059\n",
      "Epoch 58/10000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 162.8976 - mse: 162.8976 - val_loss: 148.8191 - val_mse: 148.8191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/10000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 183.8791 - mse: 183.8791 - val_loss: 144.7749 - val_mse: 144.7749\n",
      "Epoch 60/10000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 154.9289 - mse: 154.9289 - val_loss: 140.7793 - val_mse: 140.7793\n",
      "Epoch 61/10000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 154.6270 - mse: 154.6270 - val_loss: 136.8242 - val_mse: 136.8242\n",
      "Epoch 62/10000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 154.4803 - mse: 154.4803 - val_loss: 132.9055 - val_mse: 132.9055\n",
      "Epoch 63/10000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 147.5855 - mse: 147.5855 - val_loss: 129.0332 - val_mse: 129.0332\n",
      "Epoch 64/10000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 160.2977 - mse: 160.2977 - val_loss: 125.2134 - val_mse: 125.2134\n",
      "Epoch 65/10000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 157.5984 - mse: 157.5984 - val_loss: 121.4546 - val_mse: 121.4546\n",
      "Epoch 66/10000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 143.7833 - mse: 143.7833 - val_loss: 117.7607 - val_mse: 117.7607\n",
      "Epoch 67/10000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 148.7816 - mse: 148.7816 - val_loss: 114.1425 - val_mse: 114.1425\n",
      "Epoch 68/10000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 139.2984 - mse: 139.2984 - val_loss: 110.5950 - val_mse: 110.5950\n",
      "Epoch 69/10000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 138.0957 - mse: 138.0957 - val_loss: 107.1219 - val_mse: 107.1219\n",
      "Epoch 70/10000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 127.8150 - mse: 127.8150 - val_loss: 103.7275 - val_mse: 103.7275\n",
      "Epoch 71/10000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 126.0025 - mse: 126.0025 - val_loss: 100.4063 - val_mse: 100.4063\n",
      "Epoch 72/10000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 138.6794 - mse: 138.6794 - val_loss: 97.1601 - val_mse: 97.1601\n",
      "Epoch 73/10000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 143.4469 - mse: 143.4469 - val_loss: 93.9941 - val_mse: 93.9941\n",
      "Epoch 74/10000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 111.2444 - mse: 111.2444 - val_loss: 90.9096 - val_mse: 90.9096\n",
      "Epoch 75/10000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 126.8001 - mse: 126.8001 - val_loss: 87.9087 - val_mse: 87.9087\n",
      "Epoch 76/10000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 122.0384 - mse: 122.0384 - val_loss: 84.9883 - val_mse: 84.9883\n",
      "Epoch 77/10000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 119.4582 - mse: 119.4582 - val_loss: 82.1549 - val_mse: 82.1549\n",
      "Epoch 78/10000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 110.1720 - mse: 110.1720 - val_loss: 79.4058 - val_mse: 79.4058\n",
      "Epoch 79/10000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 119.3784 - mse: 119.3784 - val_loss: 76.7358 - val_mse: 76.7358\n",
      "Epoch 80/10000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 100.1127 - mse: 100.1127 - val_loss: 74.1532 - val_mse: 74.1532\n",
      "Epoch 81/10000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 94.2464 - mse: 94.2464 - val_loss: 71.6541 - val_mse: 71.6541\n",
      "Epoch 82/10000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 104.6699 - mse: 104.6699 - val_loss: 69.2484 - val_mse: 69.2484\n",
      "Epoch 83/10000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 88.8710 - mse: 88.8710 - val_loss: 66.9278 - val_mse: 66.9278\n",
      "Epoch 84/10000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 95.5476 - mse: 95.5476 - val_loss: 64.6978 - val_mse: 64.6978\n",
      "Epoch 85/10000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 90.8683 - mse: 90.8683 - val_loss: 62.5570 - val_mse: 62.5570\n",
      "Epoch 86/10000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 92.7668 - mse: 92.7668 - val_loss: 60.5169 - val_mse: 60.5169\n",
      "Epoch 87/10000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 94.4814 - mse: 94.4814 - val_loss: 58.5713 - val_mse: 58.5713\n",
      "Epoch 88/10000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 93.9494 - mse: 93.9494 - val_loss: 56.7237 - val_mse: 56.7237\n",
      "Epoch 89/10000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 86.9512 - mse: 86.9512 - val_loss: 54.9804 - val_mse: 54.9804\n",
      "Epoch 90/10000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 82.9501 - mse: 82.9501 - val_loss: 53.3443 - val_mse: 53.3443\n",
      "Epoch 91/10000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 79.0616 - mse: 79.0616 - val_loss: 51.8242 - val_mse: 51.8242\n",
      "Epoch 92/10000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 78.1923 - mse: 78.1923 - val_loss: 50.4256 - val_mse: 50.4256\n",
      "Epoch 93/10000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 78.8861 - mse: 78.8861 - val_loss: 49.1422 - val_mse: 49.1422\n",
      "Epoch 94/10000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 86.3580 - mse: 86.3580 - val_loss: 48.0058 - val_mse: 48.0058\n",
      "Epoch 95/10000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 73.6907 - mse: 73.6907 - val_loss: 47.0114 - val_mse: 47.0114\n",
      "Epoch 96/10000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 87.1869 - mse: 87.1869 - val_loss: 46.1377 - val_mse: 46.1377\n",
      "Epoch 97/10000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 90.2299 - mse: 90.2299 - val_loss: 45.3662 - val_mse: 45.3662\n",
      "Epoch 98/10000\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 71.2197 - mse: 71.2197 - val_loss: 44.7301 - val_mse: 44.7301\n",
      "Epoch 99/10000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 69.6545 - mse: 69.6545 - val_loss: 44.2611 - val_mse: 44.2611\n",
      "Epoch 100/10000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 96.1379 - mse: 96.1379 - val_loss: 43.8592 - val_mse: 43.8592\n",
      "Epoch 101/10000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 89.6291 - mse: 89.6291 - val_loss: 43.5721 - val_mse: 43.5721\n",
      "Epoch 102/10000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 74.3431 - mse: 74.3431 - val_loss: 43.3653 - val_mse: 43.3653\n",
      "Epoch 103/10000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 60.5517 - mse: 60.5517 - val_loss: 43.2110 - val_mse: 43.2110\n",
      "Epoch 104/10000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 91.5907 - mse: 91.5907 - val_loss: 43.0911 - val_mse: 43.0911\n",
      "Epoch 105/10000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 70.9239 - mse: 70.9239 - val_loss: 42.9964 - val_mse: 42.9964\n",
      "Epoch 106/10000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 64.0913 - mse: 64.0913 - val_loss: 42.9319 - val_mse: 42.9319\n",
      "Epoch 107/10000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 79.8489 - mse: 79.8489 - val_loss: 42.8870 - val_mse: 42.8870\n",
      "Epoch 108/10000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 85.9777 - mse: 85.9777 - val_loss: 42.8529 - val_mse: 42.8529\n",
      "Epoch 109/10000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 67.4900 - mse: 67.4900 - val_loss: 42.8316 - val_mse: 42.8316\n",
      "Epoch 110/10000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 83.7294 - mse: 83.7294 - val_loss: 42.8082 - val_mse: 42.8082\n",
      "Epoch 111/10000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 81.1857 - mse: 81.1857 - val_loss: 42.7986 - val_mse: 42.7986\n",
      "Epoch 112/10000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 84.2224 - mse: 84.2224 - val_loss: 42.7996 - val_mse: 42.7996\n",
      "Epoch 113/10000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 72.9276 - mse: 72.9276 - val_loss: 42.8139 - val_mse: 42.8139\n",
      "Epoch 114/10000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 74.8910 - mse: 74.8910 - val_loss: 42.8334 - val_mse: 42.8334\n",
      "Epoch 115/10000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 72.5914 - mse: 72.5914 - val_loss: 42.8633 - val_mse: 42.8633\n",
      "Epoch 116/10000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 90.4697 - mse: 90.4697 - val_loss: 42.9065 - val_mse: 42.9065\n",
      "Epoch 117/10000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 89.9732 - mse: 89.9732 - val_loss: 42.9650 - val_mse: 42.9650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/10000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 88.6800 - mse: 88.6800 - val_loss: 43.0161 - val_mse: 43.0161\n",
      "Epoch 119/10000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 92.3244 - mse: 92.3244 - val_loss: 43.0633 - val_mse: 43.0633\n",
      "Epoch 120/10000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 71.8971 - mse: 71.8971 - val_loss: 43.0941 - val_mse: 43.0941\n",
      "Epoch 121/10000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 73.9667 - mse: 73.9667 - val_loss: 43.1508 - val_mse: 43.1508\n",
      "Epoch 122/10000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 68.6342 - mse: 68.6342 - val_loss: 43.1845 - val_mse: 43.1845\n",
      "Epoch 123/10000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 90.5308 - mse: 90.5308 - val_loss: 43.2401 - val_mse: 43.2401\n",
      "Epoch 124/10000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 74.9521 - mse: 74.9521 - val_loss: 43.2649 - val_mse: 43.2649\n",
      "Epoch 125/10000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 81.2370 - mse: 81.2370 - val_loss: 43.2958 - val_mse: 43.2958\n",
      "Epoch 126/10000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 75.6105 - mse: 75.6105 - val_loss: 43.3183 - val_mse: 43.3183\n",
      "Epoch 127/10000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 69.6829 - mse: 69.6829 - val_loss: 43.3452 - val_mse: 43.3452\n",
      "Epoch 128/10000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 67.3276 - mse: 67.3276 - val_loss: 43.3806 - val_mse: 43.3806\n",
      "Epoch 129/10000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 83.4495 - mse: 83.4495 - val_loss: 43.4264 - val_mse: 43.4264\n",
      "Epoch 130/10000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 74.0827 - mse: 74.0827 - val_loss: 43.4806 - val_mse: 43.4806\n",
      "Epoch 131/10000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 83.8623 - mse: 83.8623 - val_loss: 43.5505 - val_mse: 43.5505\n",
      "Epoch 132/10000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 72.6131 - mse: 72.6131 - val_loss: 43.6369 - val_mse: 43.6369\n",
      "Epoch 133/10000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 87.2926 - mse: 87.2926 - val_loss: 43.7429 - val_mse: 43.7429\n",
      "Epoch 134/10000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 84.9852 - mse: 84.9852 - val_loss: 43.8461 - val_mse: 43.8461\n",
      "Epoch 135/10000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 80.6450 - mse: 80.6450 - val_loss: 43.9464 - val_mse: 43.9464\n",
      "Epoch 136/10000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 89.5716 - mse: 89.5716 - val_loss: 44.0666 - val_mse: 44.0666\n",
      "Epoch 137/10000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 87.9089 - mse: 87.9089 - val_loss: 44.1247 - val_mse: 44.1247\n",
      "Epoch 138/10000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 81.8025 - mse: 81.8025 - val_loss: 44.1343 - val_mse: 44.1343\n",
      "Epoch 139/10000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 87.2126 - mse: 87.2126 - val_loss: 44.1556 - val_mse: 44.1556\n",
      "Epoch 140/10000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 87.5342 - mse: 87.5342 - val_loss: 44.2149 - val_mse: 44.2149\n",
      "Epoch 141/10000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 87.3304 - mse: 87.3304 - val_loss: 44.2714 - val_mse: 44.2714\n",
      "Epoch 142/10000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 83.9825 - mse: 83.9825 - val_loss: 44.3136 - val_mse: 44.3136\n",
      "Epoch 143/10000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 72.1884 - mse: 72.1884 - val_loss: 44.3075 - val_mse: 44.3075\n",
      "Epoch 144/10000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 95.3995 - mse: 95.3995 - val_loss: 44.3043 - val_mse: 44.3043\n",
      "Epoch 145/10000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 88.4797 - mse: 88.4797 - val_loss: 44.2686 - val_mse: 44.2686\n",
      "Epoch 146/10000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 79.6449 - mse: 79.6449 - val_loss: 44.1914 - val_mse: 44.1914\n",
      "Epoch 147/10000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 91.4847 - mse: 91.4847 - val_loss: 44.0803 - val_mse: 44.0803\n",
      "Epoch 148/10000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 70.3771 - mse: 70.3771 - val_loss: 43.9585 - val_mse: 43.9585\n",
      "Epoch 149/10000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 80.6849 - mse: 80.6849 - val_loss: 43.8518 - val_mse: 43.8518\n",
      "Epoch 150/10000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 76.1018 - mse: 76.1018 - val_loss: 43.8058 - val_mse: 43.8058\n",
      "Epoch 151/10000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 69.8808 - mse: 69.8808 - val_loss: 43.7677 - val_mse: 43.7677\n",
      "Epoch 152/10000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 68.2013 - mse: 68.2013 - val_loss: 43.7301 - val_mse: 43.7301\n",
      "Epoch 153/10000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 66.7512 - mse: 66.7512 - val_loss: 43.6837 - val_mse: 43.6837\n",
      "Epoch 154/10000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 84.8727 - mse: 84.8727 - val_loss: 43.6406 - val_mse: 43.6406\n",
      "Epoch 155/10000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 91.4073 - mse: 91.4073 - val_loss: 43.6290 - val_mse: 43.6290\n",
      "Epoch 156/10000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 70.7500 - mse: 70.7500 - val_loss: 43.6161 - val_mse: 43.6161\n",
      "Epoch 157/10000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 83.5129 - mse: 83.5129 - val_loss: 43.6306 - val_mse: 43.6306\n",
      "Epoch 158/10000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 74.2649 - mse: 74.2649 - val_loss: 43.6091 - val_mse: 43.6091\n",
      "Epoch 159/10000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 93.1264 - mse: 93.1264 - val_loss: 43.5970 - val_mse: 43.5970\n",
      "Epoch 160/10000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 81.3012 - mse: 81.3012 - val_loss: 43.5738 - val_mse: 43.5738\n",
      "Epoch 161/10000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 84.4699 - mse: 84.4699 - val_loss: 43.5239 - val_mse: 43.5239\n",
      "Epoch 162/10000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 71.9122 - mse: 71.9122 - val_loss: 43.5241 - val_mse: 43.5241\n",
      "Epoch 163/10000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 82.9066 - mse: 82.9066 - val_loss: 43.5514 - val_mse: 43.5514\n",
      "Epoch 164/10000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 75.8541 - mse: 75.8541 - val_loss: 43.6160 - val_mse: 43.6160\n",
      "Epoch 165/10000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 87.3583 - mse: 87.3583 - val_loss: 43.6543 - val_mse: 43.6543\n",
      "Epoch 166/10000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 81.1850 - mse: 81.1850 - val_loss: 43.6729 - val_mse: 43.6729\n",
      "Epoch 167/10000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 75.9487 - mse: 75.9487 - val_loss: 43.7339 - val_mse: 43.7339\n",
      "Epoch 168/10000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 94.9286 - mse: 94.9286 - val_loss: 43.8315 - val_mse: 43.8315\n",
      "Epoch 169/10000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 75.9813 - mse: 75.9813 - val_loss: 43.9357 - val_mse: 43.9357\n",
      "Epoch 170/10000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 83.2879 - mse: 83.2879 - val_loss: 44.0242 - val_mse: 44.0242\n",
      "Epoch 171/10000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 73.0851 - mse: 73.0851 - val_loss: 44.1022 - val_mse: 44.1022\n",
      "Epoch 172/10000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 68.1420 - mse: 68.1420 - val_loss: 44.1529 - val_mse: 44.1529\n",
      "Epoch 173/10000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 48.4782 - mse: 48.4782 - val_loss: 44.1638 - val_mse: 44.1638\n",
      "Epoch 174/10000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 69.9130 - mse: 69.9130 - val_loss: 44.1551 - val_mse: 44.1551\n",
      "Epoch 175/10000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 83.1317 - mse: 83.1317 - val_loss: 44.1460 - val_mse: 44.1460\n",
      "Epoch 176/10000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 78.5056 - mse: 78.5056 - val_loss: 44.1199 - val_mse: 44.1199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177/10000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 81.0350 - mse: 81.0350 - val_loss: 44.0511 - val_mse: 44.0511\n",
      "Epoch 178/10000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 78.3064 - mse: 78.3064 - val_loss: 43.9518 - val_mse: 43.9518\n",
      "Epoch 179/10000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 75.2772 - mse: 75.2772 - val_loss: 43.8710 - val_mse: 43.8710\n",
      "Epoch 180/10000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 82.2791 - mse: 82.2791 - val_loss: 43.8340 - val_mse: 43.8340\n",
      "Epoch 181/10000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 82.5356 - mse: 82.5356 - val_loss: 43.7960 - val_mse: 43.7960\n",
      "Epoch 182/10000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 75.5439 - mse: 75.5439 - val_loss: 43.7181 - val_mse: 43.7181\n",
      "Epoch 183/10000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 71.1688 - mse: 71.1688 - val_loss: 43.6570 - val_mse: 43.6570\n",
      "Epoch 184/10000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 86.8063 - mse: 86.8063 - val_loss: 43.6248 - val_mse: 43.6248\n",
      "Epoch 185/10000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 72.5728 - mse: 72.5728 - val_loss: 43.6296 - val_mse: 43.6296\n",
      "Epoch 186/10000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 77.9685 - mse: 77.9685 - val_loss: 43.6652 - val_mse: 43.6652\n",
      "Epoch 187/10000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 77.1926 - mse: 77.1926 - val_loss: 43.6550 - val_mse: 43.6550\n",
      "Epoch 188/10000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 80.5435 - mse: 80.5435 - val_loss: 43.6315 - val_mse: 43.6315\n",
      "Epoch 189/10000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 75.6287 - mse: 75.6287 - val_loss: 43.6075 - val_mse: 43.6075\n",
      "Epoch 190/10000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 80.6371 - mse: 80.6371 - val_loss: 43.6114 - val_mse: 43.6114\n",
      "Epoch 191/10000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 76.3755 - mse: 76.3755 - val_loss: 43.6481 - val_mse: 43.6481\n",
      "Epoch 192/10000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 87.2599 - mse: 87.2599 - val_loss: 43.6454 - val_mse: 43.6454\n",
      "Epoch 193/10000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 64.6002 - mse: 64.6002 - val_loss: 43.6115 - val_mse: 43.6115\n",
      "Epoch 194/10000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 78.5693 - mse: 78.5693 - val_loss: 43.5368 - val_mse: 43.5368\n",
      "Epoch 195/10000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 71.7474 - mse: 71.7474 - val_loss: 43.4439 - val_mse: 43.4439\n",
      "Epoch 196/10000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 56.5464 - mse: 56.5464 - val_loss: 43.3474 - val_mse: 43.3474\n",
      "Epoch 197/10000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 80.3149 - mse: 80.3149 - val_loss: 43.2465 - val_mse: 43.2465\n",
      "Epoch 198/10000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 77.4651 - mse: 77.4651 - val_loss: 43.1814 - val_mse: 43.1814\n",
      "Epoch 199/10000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 67.8665 - mse: 67.8665 - val_loss: 43.1220 - val_mse: 43.1220\n",
      "Epoch 200/10000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 52.4504 - mse: 52.4504 - val_loss: 43.0705 - val_mse: 43.0705\n",
      "Epoch 201/10000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 67.4077 - mse: 67.4077 - val_loss: 43.0470 - val_mse: 43.0470\n",
      "Epoch 202/10000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 85.6638 - mse: 85.6638 - val_loss: 43.0472 - val_mse: 43.0472\n",
      "Epoch 203/10000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 64.5389 - mse: 64.5389 - val_loss: 43.0452 - val_mse: 43.0452\n",
      "Epoch 204/10000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 91.9875 - mse: 91.9875 - val_loss: 43.0452 - val_mse: 43.0452\n",
      "Epoch 205/10000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 61.9136 - mse: 61.9136 - val_loss: 43.0629 - val_mse: 43.0629\n",
      "Epoch 206/10000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 67.5299 - mse: 67.5299 - val_loss: 43.1071 - val_mse: 43.1071\n",
      "Epoch 207/10000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 80.0766 - mse: 80.0766 - val_loss: 43.1678 - val_mse: 43.1678\n",
      "Epoch 208/10000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 68.5395 - mse: 68.5395 - val_loss: 43.2552 - val_mse: 43.2552\n",
      "Epoch 209/10000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 98.5835 - mse: 98.5835 - val_loss: 43.3648 - val_mse: 43.3648\n",
      "Epoch 210/10000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 71.8805 - mse: 71.8805 - val_loss: 43.4509 - val_mse: 43.4509\n",
      "Epoch 211/10000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 80.7465 - mse: 80.7465 - val_loss: 43.5529 - val_mse: 43.5529\n",
      "Epoch 212/10000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 65.8150 - mse: 65.8150 - val_loss: 43.6724 - val_mse: 43.6724\n",
      "Epoch 213/10000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 80.5592 - mse: 80.5592 - val_loss: 43.7891 - val_mse: 43.7891\n",
      "Epoch 214/10000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 73.8494 - mse: 73.8494 - val_loss: 43.8507 - val_mse: 43.8507\n",
      "Epoch 215/10000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 91.7902 - mse: 91.7902 - val_loss: 43.8793 - val_mse: 43.8793\n",
      "Epoch 216/10000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 93.6943 - mse: 93.6943 - val_loss: 43.8821 - val_mse: 43.8821\n",
      "Epoch 217/10000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 51.2967 - mse: 51.2967 - val_loss: 43.8879 - val_mse: 43.8879\n",
      "Epoch 218/10000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 89.0773 - mse: 89.0773 - val_loss: 43.9084 - val_mse: 43.9084\n",
      "Epoch 219/10000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 71.1330 - mse: 71.1330 - val_loss: 43.8825 - val_mse: 43.8825\n",
      "Epoch 220/10000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 61.3811 - mse: 61.3811 - val_loss: 43.8185 - val_mse: 43.8185\n",
      "Epoch 221/10000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 81.6619 - mse: 81.6619 - val_loss: 43.7871 - val_mse: 43.7871\n",
      "Epoch 222/10000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 86.5751 - mse: 86.5751 - val_loss: 43.8014 - val_mse: 43.8014\n",
      "Epoch 223/10000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 82.1981 - mse: 82.1981 - val_loss: 43.9746 - val_mse: 43.9746\n",
      "Epoch 224/10000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 67.9212 - mse: 67.9212 - val_loss: 44.2168 - val_mse: 44.2168\n",
      "Epoch 225/10000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 83.0642 - mse: 83.0642 - val_loss: 44.3892 - val_mse: 44.3892\n",
      "Epoch 226/10000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 85.0405 - mse: 85.0405 - val_loss: 44.4588 - val_mse: 44.4588\n",
      "Epoch 227/10000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 83.4283 - mse: 83.4283 - val_loss: 44.4963 - val_mse: 44.4963\n",
      "Epoch 228/10000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 84.3261 - mse: 84.3261 - val_loss: 44.5184 - val_mse: 44.5184\n",
      "Epoch 229/10000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 89.6427 - mse: 89.6427 - val_loss: 44.5081 - val_mse: 44.5081\n",
      "Epoch 230/10000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 83.6410 - mse: 83.6410 - val_loss: 44.4190 - val_mse: 44.4190\n",
      "Epoch 231/10000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 75.0621 - mse: 75.0621 - val_loss: 44.3635 - val_mse: 44.3635\n",
      "Epoch 232/10000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 78.0647 - mse: 78.0647 - val_loss: 44.2710 - val_mse: 44.2710\n",
      "Epoch 233/10000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 88.8407 - mse: 88.8407 - val_loss: 44.1613 - val_mse: 44.1613\n",
      "Epoch 234/10000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 71.2258 - mse: 71.2258 - val_loss: 44.0316 - val_mse: 44.0316\n",
      "Epoch 235/10000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 84.8008 - mse: 84.8008 - val_loss: 43.9195 - val_mse: 43.9195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 236/10000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 66.3456 - mse: 66.3456 - val_loss: 43.7559 - val_mse: 43.7559\n",
      "Epoch 237/10000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 72.0898 - mse: 72.0898 - val_loss: 43.5342 - val_mse: 43.5342\n",
      "Epoch 238/10000\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 66.6673 - mse: 66.6673 - val_loss: 43.3462 - val_mse: 43.3462\n",
      "Epoch 239/10000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 88.3632 - mse: 88.3632 - val_loss: 43.2787 - val_mse: 43.2787\n",
      "Epoch 240/10000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 84.3058 - mse: 84.3058 - val_loss: 43.2292 - val_mse: 43.2292\n",
      "Epoch 241/10000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 70.8692 - mse: 70.8692 - val_loss: 43.2387 - val_mse: 43.2387\n",
      "Epoch 242/10000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 85.9627 - mse: 85.9627 - val_loss: 43.4012 - val_mse: 43.4012\n",
      "Epoch 243/10000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 82.7455 - mse: 82.7455 - val_loss: 43.7004 - val_mse: 43.7004\n",
      "Epoch 244/10000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 72.4791 - mse: 72.4791 - val_loss: 43.8765 - val_mse: 43.8765\n",
      "Epoch 245/10000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 73.5369 - mse: 73.5369 - val_loss: 43.9738 - val_mse: 43.9738\n",
      "Epoch 246/10000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 92.6006 - mse: 92.6006 - val_loss: 44.0413 - val_mse: 44.0413\n",
      "Epoch 247/10000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 66.8091 - mse: 66.8091 - val_loss: 44.3116 - val_mse: 44.3116\n",
      "Epoch 248/10000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 60.7706 - mse: 60.7706 - val_loss: 44.5963 - val_mse: 44.5963\n",
      "Epoch 249/10000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 76.0568 - mse: 76.0568 - val_loss: 44.6402 - val_mse: 44.6402\n",
      "Epoch 250/10000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 71.0318 - mse: 71.0318 - val_loss: 44.4631 - val_mse: 44.4631\n",
      "Epoch 251/10000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 71.6142 - mse: 71.6142 - val_loss: 44.0938 - val_mse: 44.0938\n",
      "Epoch 252/10000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 70.3612 - mse: 70.3612 - val_loss: 43.9477 - val_mse: 43.9477\n",
      "Epoch 253/10000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 61.4773 - mse: 61.4773 - val_loss: 43.8701 - val_mse: 43.8701\n",
      "Epoch 254/10000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 71.3156 - mse: 71.3156 - val_loss: 43.8478 - val_mse: 43.8478\n",
      "Epoch 255/10000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 76.6013 - mse: 76.6013 - val_loss: 43.7870 - val_mse: 43.7870\n",
      "Epoch 256/10000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 90.6628 - mse: 90.6628 - val_loss: 43.8212 - val_mse: 43.8212\n",
      "Epoch 257/10000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 74.2570 - mse: 74.2570 - val_loss: 43.9077 - val_mse: 43.9077\n",
      "Epoch 258/10000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 73.1346 - mse: 73.1346 - val_loss: 43.9443 - val_mse: 43.9443\n",
      "Epoch 259/10000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 78.5138 - mse: 78.5138 - val_loss: 44.2463 - val_mse: 44.2463\n",
      "Epoch 260/10000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 70.9985 - mse: 70.9985 - val_loss: 44.0153 - val_mse: 44.0153\n",
      "Epoch 261/10000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 89.7840 - mse: 89.7840 - val_loss: 44.2408 - val_mse: 44.2408\n",
      "Epoch 262/10000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 69.1181 - mse: 69.1181 - val_loss: 44.7780 - val_mse: 44.7780\n",
      "Epoch 263/10000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 64.8772 - mse: 64.8772 - val_loss: 46.2830 - val_mse: 46.2830\n",
      "Epoch 264/10000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 60.2637 - mse: 60.2637 - val_loss: 46.8418 - val_mse: 46.8418\n",
      "Epoch 265/10000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 69.7516 - mse: 69.7516 - val_loss: 46.3323 - val_mse: 46.3323\n",
      "Epoch 266/10000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 61.1477 - mse: 61.1477 - val_loss: 45.1699 - val_mse: 45.1699\n",
      "Epoch 267/10000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 73.9974 - mse: 73.9974 - val_loss: 44.5949 - val_mse: 44.5949\n",
      "Epoch 268/10000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 60.2758 - mse: 60.2758 - val_loss: 43.6885 - val_mse: 43.6885\n",
      "Epoch 269/10000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 66.2192 - mse: 66.2192 - val_loss: 42.6193 - val_mse: 42.6193\n",
      "Epoch 270/10000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 75.6567 - mse: 75.6567 - val_loss: 43.7728 - val_mse: 43.7728\n",
      "Epoch 271/10000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 67.2982 - mse: 67.2982 - val_loss: 44.6725 - val_mse: 44.6725\n",
      "Epoch 272/10000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 65.8129 - mse: 65.8129 - val_loss: 44.3870 - val_mse: 44.3870\n",
      "Epoch 273/10000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 70.4246 - mse: 70.4246 - val_loss: 44.6665 - val_mse: 44.6665\n",
      "Epoch 274/10000\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 64.5606 - mse: 64.5606 - val_loss: 45.3077 - val_mse: 45.3077\n",
      "Epoch 275/10000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 68.6844 - mse: 68.6844 - val_loss: 45.1442 - val_mse: 45.1442\n",
      "Epoch 276/10000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 65.1415 - mse: 65.1415 - val_loss: 43.6762 - val_mse: 43.6762\n",
      "Epoch 277/10000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 63.7382 - mse: 63.7382 - val_loss: 43.0785 - val_mse: 43.0785\n",
      "Epoch 278/10000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 73.2976 - mse: 73.2976 - val_loss: 42.5414 - val_mse: 42.5414\n",
      "Epoch 279/10000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 66.0995 - mse: 66.0995 - val_loss: 42.5349 - val_mse: 42.5349\n",
      "Epoch 280/10000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 55.2060 - mse: 55.2060 - val_loss: 42.7591 - val_mse: 42.7591\n",
      "Epoch 281/10000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 67.6614 - mse: 67.6614 - val_loss: 43.1689 - val_mse: 43.1689\n",
      "Epoch 282/10000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 63.9023 - mse: 63.9023 - val_loss: 43.4873 - val_mse: 43.4873\n",
      "Epoch 283/10000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 58.9793 - mse: 58.9793 - val_loss: 43.9313 - val_mse: 43.9313\n",
      "Epoch 284/10000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 54.8451 - mse: 54.8451 - val_loss: 43.9716 - val_mse: 43.9716\n",
      "Epoch 285/10000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 64.9456 - mse: 64.9456 - val_loss: 44.1824 - val_mse: 44.1824\n",
      "Epoch 286/10000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 47.9596 - mse: 47.9596 - val_loss: 44.0390 - val_mse: 44.0390\n",
      "Epoch 287/10000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 62.3244 - mse: 62.3244 - val_loss: 43.9599 - val_mse: 43.9599\n",
      "Epoch 288/10000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 61.3374 - mse: 61.3374 - val_loss: 45.9763 - val_mse: 45.9763\n",
      "Epoch 289/10000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 57.3391 - mse: 57.3391 - val_loss: 47.7773 - val_mse: 47.7773\n",
      "Epoch 290/10000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 57.8182 - mse: 57.8182 - val_loss: 47.5819 - val_mse: 47.5819\n",
      "Epoch 291/10000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 53.1302 - mse: 53.1302 - val_loss: 46.8472 - val_mse: 46.8472\n",
      "Epoch 292/10000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 73.4897 - mse: 73.4897 - val_loss: 46.5504 - val_mse: 46.5504\n",
      "Epoch 293/10000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 74.3304 - mse: 74.3304 - val_loss: 46.5433 - val_mse: 46.5433\n",
      "Epoch 294/10000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 61.7607 - mse: 61.7607 - val_loss: 46.1685 - val_mse: 46.1685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 295/10000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 58.8340 - mse: 58.8340 - val_loss: 45.7090 - val_mse: 45.7090\n",
      "Epoch 296/10000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 80.1365 - mse: 80.1365 - val_loss: 46.7501 - val_mse: 46.7501\n",
      "Epoch 297/10000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 59.8008 - mse: 59.8008 - val_loss: 45.4231 - val_mse: 45.4231\n",
      "Epoch 298/10000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 54.5854 - mse: 54.5854 - val_loss: 45.3527 - val_mse: 45.3527\n",
      "Epoch 299/10000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 58.3039 - mse: 58.3039 - val_loss: 45.8317 - val_mse: 45.8317\n",
      "Epoch 300/10000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 46.9059 - mse: 46.9059 - val_loss: 47.9933 - val_mse: 47.9933\n",
      "Epoch 301/10000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 68.3940 - mse: 68.3940 - val_loss: 50.4248 - val_mse: 50.4248\n",
      "Epoch 302/10000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 65.4325 - mse: 65.4325 - val_loss: 50.3097 - val_mse: 50.3097\n",
      "Epoch 303/10000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 64.0123 - mse: 64.0123 - val_loss: 48.9950 - val_mse: 48.9950\n",
      "Epoch 304/10000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 60.3732 - mse: 60.3732 - val_loss: 47.7246 - val_mse: 47.7246\n",
      "Epoch 305/10000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 55.7933 - mse: 55.7933 - val_loss: 46.5656 - val_mse: 46.5656\n",
      "Epoch 306/10000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 64.0508 - mse: 64.0508 - val_loss: 46.7767 - val_mse: 46.7767\n",
      "Epoch 307/10000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 67.4235 - mse: 67.4235 - val_loss: 47.0624 - val_mse: 47.0624\n",
      "Epoch 308/10000\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 60.4361 - mse: 60.4361 - val_loss: 47.0753 - val_mse: 47.0753\n",
      "Epoch 309/10000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 65.5683 - mse: 65.5683 - val_loss: 47.2062 - val_mse: 47.2062\n",
      "Epoch 310/10000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 54.6385 - mse: 54.6385 - val_loss: 46.4613 - val_mse: 46.4613\n",
      "Epoch 311/10000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 55.3516 - mse: 55.3516 - val_loss: 50.3195 - val_mse: 50.3195\n",
      "Epoch 312/10000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 62.0558 - mse: 62.0558 - val_loss: 50.3832 - val_mse: 50.3832\n",
      "Epoch 313/10000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 50.2779 - mse: 50.2779 - val_loss: 49.7958 - val_mse: 49.7958\n",
      "Epoch 314/10000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 58.3454 - mse: 58.3454 - val_loss: 50.1694 - val_mse: 50.1694\n",
      "Epoch 315/10000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 56.4679 - mse: 56.4679 - val_loss: 50.9878 - val_mse: 50.9878\n",
      "Epoch 316/10000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 51.2857 - mse: 51.2857 - val_loss: 52.8600 - val_mse: 52.8600\n",
      "Epoch 317/10000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 59.1176 - mse: 59.1176 - val_loss: 55.7173 - val_mse: 55.7173\n",
      "Epoch 318/10000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 53.2842 - mse: 53.2842 - val_loss: 56.6234 - val_mse: 56.6234\n",
      "Epoch 319/10000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 57.0512 - mse: 57.0512 - val_loss: 56.1432 - val_mse: 56.1432\n",
      "Epoch 320/10000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 52.9616 - mse: 52.9616 - val_loss: 54.8077 - val_mse: 54.8077\n",
      "Epoch 321/10000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 59.8639 - mse: 59.8639 - val_loss: 54.1010 - val_mse: 54.1010\n",
      "Epoch 322/10000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 55.9813 - mse: 55.9813 - val_loss: 54.3161 - val_mse: 54.3161\n",
      "Epoch 323/10000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 66.9752 - mse: 66.9752 - val_loss: 54.3953 - val_mse: 54.3953\n",
      "Epoch 324/10000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 52.1527 - mse: 52.1527 - val_loss: 56.6645 - val_mse: 56.6645\n",
      "Epoch 325/10000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 58.8818 - mse: 58.8818 - val_loss: 54.1103 - val_mse: 54.1103\n",
      "Epoch 326/10000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 54.2951 - mse: 54.2951 - val_loss: 52.0267 - val_mse: 52.0267\n",
      "Epoch 327/10000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 51.6991 - mse: 51.6991 - val_loss: 49.3076 - val_mse: 49.3076\n",
      "Epoch 328/10000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 52.5317 - mse: 52.5317 - val_loss: 49.7000 - val_mse: 49.7000\n",
      "Epoch 329/10000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 56.8724 - mse: 56.8724 - val_loss: 50.4604 - val_mse: 50.4604\n",
      "Epoch 330/10000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 59.7058 - mse: 59.7058 - val_loss: 51.3390 - val_mse: 51.3390\n",
      "Epoch 331/10000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 40.4978 - mse: 40.4978 - val_loss: 50.1668 - val_mse: 50.1668\n",
      "Epoch 332/10000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 57.5846 - mse: 57.5846 - val_loss: 49.8729 - val_mse: 49.8729\n",
      "Epoch 333/10000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 60.1301 - mse: 60.1301 - val_loss: 49.0530 - val_mse: 49.0530\n",
      "Epoch 334/10000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 51.7954 - mse: 51.7954 - val_loss: 49.7234 - val_mse: 49.7234\n",
      "Epoch 335/10000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 45.2572 - mse: 45.2572 - val_loss: 53.7422 - val_mse: 53.7422\n",
      "Epoch 336/10000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 54.3588 - mse: 54.3588 - val_loss: 58.1751 - val_mse: 58.1751\n",
      "Epoch 337/10000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 44.6473 - mse: 44.6473 - val_loss: 56.4090 - val_mse: 56.4090\n",
      "Epoch 338/10000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 40.2117 - mse: 40.2117 - val_loss: 55.0190 - val_mse: 55.0190\n",
      "Epoch 339/10000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 47.3724 - mse: 47.3724 - val_loss: 51.2064 - val_mse: 51.2064\n",
      "Epoch 340/10000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 54.2854 - mse: 54.2854 - val_loss: 49.3082 - val_mse: 49.3082\n",
      "Epoch 341/10000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 35.7589 - mse: 35.7589 - val_loss: 48.3546 - val_mse: 48.3546\n",
      "Epoch 342/10000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 43.9712 - mse: 43.9712 - val_loss: 50.2996 - val_mse: 50.2996\n",
      "Epoch 343/10000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 42.5970 - mse: 42.5970 - val_loss: 59.1252 - val_mse: 59.1252\n",
      "Epoch 344/10000\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 34.8798 - mse: 34.8798 - val_loss: 63.8366 - val_mse: 63.8366\n",
      "Epoch 345/10000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 51.7628 - mse: 51.7628 - val_loss: 69.0426 - val_mse: 69.0426\n",
      "Epoch 346/10000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 52.0583 - mse: 52.0583 - val_loss: 72.1334 - val_mse: 72.1334\n",
      "Epoch 347/10000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 50.7925 - mse: 50.7925 - val_loss: 70.0408 - val_mse: 70.0408\n",
      "Epoch 348/10000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 50.7360 - mse: 50.7360 - val_loss: 65.1361 - val_mse: 65.1361\n",
      "Epoch 349/10000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 34.3147 - mse: 34.3147 - val_loss: 52.6289 - val_mse: 52.6289\n",
      "Epoch 350/10000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 33.7488 - mse: 33.7488 - val_loss: 48.6903 - val_mse: 48.6903\n",
      "Epoch 351/10000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 41.2484 - mse: 41.2484 - val_loss: 49.7212 - val_mse: 49.7212\n",
      "Epoch 352/10000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 43.8697 - mse: 43.8697 - val_loss: 50.2948 - val_mse: 50.2948\n",
      "Epoch 353/10000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 35.8415 - mse: 35.8415 - val_loss: 50.0965 - val_mse: 50.0965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 354/10000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 44.4305 - mse: 44.4305 - val_loss: 54.3709 - val_mse: 54.3709\n",
      "Epoch 355/10000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 55.9329 - mse: 55.9329 - val_loss: 68.1334 - val_mse: 68.1334\n",
      "Epoch 356/10000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 53.9588 - mse: 53.9588 - val_loss: 75.8470 - val_mse: 75.8470\n",
      "Epoch 357/10000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 36.3606 - mse: 36.3606 - val_loss: 73.7114 - val_mse: 73.7114\n",
      "Epoch 358/10000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 45.0683 - mse: 45.0683 - val_loss: 73.8563 - val_mse: 73.8563\n",
      "Epoch 359/10000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 39.3279 - mse: 39.3279 - val_loss: 71.7777 - val_mse: 71.7777\n",
      "Epoch 360/10000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 38.2405 - mse: 38.2405 - val_loss: 70.4130 - val_mse: 70.4130\n",
      "Epoch 361/10000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 38.5763 - mse: 38.5763 - val_loss: 57.5134 - val_mse: 57.5134\n",
      "Epoch 362/10000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 37.4202 - mse: 37.4202 - val_loss: 55.7718 - val_mse: 55.7718\n",
      "Epoch 363/10000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 40.7644 - mse: 40.7644 - val_loss: 54.0114 - val_mse: 54.0114\n",
      "Epoch 364/10000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 33.4976 - mse: 33.4976 - val_loss: 55.1991 - val_mse: 55.1991\n",
      "Epoch 365/10000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 41.0602 - mse: 41.0602 - val_loss: 67.1613 - val_mse: 67.1613\n",
      "Epoch 366/10000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 46.1430 - mse: 46.1430 - val_loss: 72.1529 - val_mse: 72.1529\n",
      "Epoch 367/10000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 39.4961 - mse: 39.4961 - val_loss: 70.6912 - val_mse: 70.6912\n",
      "Epoch 368/10000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 42.1461 - mse: 42.1461 - val_loss: 63.0881 - val_mse: 63.0881\n",
      "Epoch 369/10000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 32.3339 - mse: 32.3339 - val_loss: 51.8318 - val_mse: 51.8318\n",
      "Epoch 370/10000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 32.2891 - mse: 32.2891 - val_loss: 49.8589 - val_mse: 49.8589\n",
      "Epoch 371/10000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 42.2308 - mse: 42.2308 - val_loss: 51.6698 - val_mse: 51.6698\n",
      "Epoch 372/10000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 41.7871 - mse: 41.7871 - val_loss: 56.7024 - val_mse: 56.7024\n",
      "Epoch 373/10000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 45.1988 - mse: 45.1988 - val_loss: 60.5957 - val_mse: 60.5957\n",
      "Epoch 374/10000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 32.8080 - mse: 32.8080 - val_loss: 66.5278 - val_mse: 66.5278\n",
      "Epoch 375/10000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 39.9093 - mse: 39.9093 - val_loss: 74.2602 - val_mse: 74.2602\n",
      "Epoch 376/10000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 32.5056 - mse: 32.5056 - val_loss: 77.2561 - val_mse: 77.2561\n",
      "Epoch 377/10000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 36.7279 - mse: 36.7279 - val_loss: 79.4566 - val_mse: 79.4566\n",
      "Epoch 378/10000\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 34.0760 - mse: 34.0760 - val_loss: 78.5926 - val_mse: 78.5926\n",
      "Epoch 379/10000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 28.4426 - mse: 28.4426 - val_loss: 72.2071 - val_mse: 72.2071\n",
      "Epoch 380/10000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 42.9234 - mse: 42.9234 - val_loss: 65.4322 - val_mse: 65.4322\n",
      "Epoch 381/10000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 56.0948 - mse: 56.0948 - val_loss: 61.7534 - val_mse: 61.7534\n",
      "Epoch 382/10000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 38.2436 - mse: 38.2436 - val_loss: 61.5935 - val_mse: 61.5935\n",
      "Epoch 383/10000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 37.0756 - mse: 37.0756 - val_loss: 63.6347 - val_mse: 63.6347\n",
      "Epoch 384/10000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 38.7088 - mse: 38.7088 - val_loss: 63.8877 - val_mse: 63.8877\n",
      "Epoch 385/10000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 43.8492 - mse: 43.8492 - val_loss: 63.9650 - val_mse: 63.9650\n",
      "Epoch 386/10000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 41.5319 - mse: 41.5319 - val_loss: 63.6779 - val_mse: 63.6779\n",
      "Epoch 387/10000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 42.7762 - mse: 42.7762 - val_loss: 65.4574 - val_mse: 65.4574\n",
      "Epoch 388/10000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 34.2044 - mse: 34.2044 - val_loss: 69.6947 - val_mse: 69.6947\n",
      "Epoch 389/10000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 28.5206 - mse: 28.5206 - val_loss: 73.8720 - val_mse: 73.8720\n",
      "Epoch 390/10000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 41.8828 - mse: 41.8828 - val_loss: 73.5129 - val_mse: 73.5129\n",
      "Epoch 391/10000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 28.5139 - mse: 28.5139 - val_loss: 87.6839 - val_mse: 87.6839\n",
      "Epoch 392/10000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 52.3895 - mse: 52.3895 - val_loss: 84.5363 - val_mse: 84.5363\n",
      "Epoch 393/10000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 42.6302 - mse: 42.6302 - val_loss: 87.6602 - val_mse: 87.6602\n",
      "Epoch 394/10000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 36.5947 - mse: 36.5947 - val_loss: 74.8973 - val_mse: 74.8973\n",
      "Epoch 395/10000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 23.9977 - mse: 23.9977 - val_loss: 60.1758 - val_mse: 60.1758\n",
      "Epoch 396/10000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 36.2717 - mse: 36.2717 - val_loss: 56.4259 - val_mse: 56.4259\n",
      "Epoch 397/10000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 35.8147 - mse: 35.8147 - val_loss: 55.6813 - val_mse: 55.6813\n",
      "Epoch 398/10000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 33.3958 - mse: 33.3958 - val_loss: 56.5275 - val_mse: 56.5275\n",
      "Epoch 399/10000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 48.2596 - mse: 48.2596 - val_loss: 62.3827 - val_mse: 62.3827\n",
      "Epoch 400/10000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 34.1441 - mse: 34.1441 - val_loss: 68.3725 - val_mse: 68.3725\n",
      "Epoch 401/10000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 28.7654 - mse: 28.7654 - val_loss: 77.8867 - val_mse: 77.8867\n",
      "Epoch 402/10000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 25.7588 - mse: 25.7588 - val_loss: 87.6148 - val_mse: 87.6148\n",
      "Epoch 403/10000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 33.1907 - mse: 33.1907 - val_loss: 94.3794 - val_mse: 94.3794\n",
      "Epoch 404/10000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 43.4039 - mse: 43.4039 - val_loss: 95.0799 - val_mse: 95.0799\n",
      "Epoch 405/10000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 39.9792 - mse: 39.9792 - val_loss: 89.6608 - val_mse: 89.6608\n",
      "Epoch 406/10000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 40.3295 - mse: 40.3295 - val_loss: 83.8736 - val_mse: 83.8736\n",
      "Epoch 407/10000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 44.3240 - mse: 44.3240 - val_loss: 75.1113 - val_mse: 75.1113\n",
      "Epoch 408/10000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 33.1580 - mse: 33.1580 - val_loss: 67.9839 - val_mse: 67.9839\n",
      "Epoch 409/10000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 29.4633 - mse: 29.4633 - val_loss: 64.4702 - val_mse: 64.4702\n",
      "Epoch 410/10000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 38.9771 - mse: 38.9771 - val_loss: 63.1136 - val_mse: 63.1136\n",
      "Epoch 411/10000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 33.0764 - mse: 33.0764 - val_loss: 62.2643 - val_mse: 62.2643\n",
      "Epoch 412/10000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 40.8395 - mse: 40.8395 - val_loss: 62.2254 - val_mse: 62.2254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 413/10000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 28.1063 - mse: 28.1063 - val_loss: 66.4838 - val_mse: 66.4838\n",
      "Epoch 414/10000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 37.4989 - mse: 37.4989 - val_loss: 70.9406 - val_mse: 70.9406\n",
      "Epoch 415/10000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 36.5626 - mse: 36.5626 - val_loss: 73.3881 - val_mse: 73.3881\n",
      "Epoch 416/10000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 33.8271 - mse: 33.8271 - val_loss: 77.4352 - val_mse: 77.4352\n",
      "Epoch 417/10000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 42.5469 - mse: 42.5469 - val_loss: 72.8935 - val_mse: 72.8935\n",
      "Epoch 418/10000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 39.9260 - mse: 39.9260 - val_loss: 66.7166 - val_mse: 66.7166\n",
      "Epoch 419/10000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 35.9578 - mse: 35.9578 - val_loss: 64.0369 - val_mse: 64.0369\n",
      "Epoch 420/10000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 37.3238 - mse: 37.3238 - val_loss: 64.7108 - val_mse: 64.7108\n",
      "Epoch 421/10000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 32.6230 - mse: 32.6230 - val_loss: 65.9619 - val_mse: 65.9619\n",
      "Epoch 422/10000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 27.5212 - mse: 27.5212 - val_loss: 66.2229 - val_mse: 66.2229\n",
      "Epoch 423/10000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 34.4874 - mse: 34.4874 - val_loss: 64.5207 - val_mse: 64.5207\n",
      "Epoch 424/10000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 33.9876 - mse: 33.9876 - val_loss: 64.2963 - val_mse: 64.2963\n",
      "Epoch 425/10000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 28.5362 - mse: 28.5362 - val_loss: 65.5747 - val_mse: 65.5747\n",
      "Epoch 426/10000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 29.8378 - mse: 29.8378 - val_loss: 66.2950 - val_mse: 66.2950\n",
      "Epoch 427/10000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 41.0045 - mse: 41.0045 - val_loss: 68.3873 - val_mse: 68.3873\n",
      "Epoch 428/10000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 42.5910 - mse: 42.5910 - val_loss: 69.8525 - val_mse: 69.8525\n",
      "Epoch 429/10000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 30.6632 - mse: 30.6632 - val_loss: 71.5041 - val_mse: 71.5041\n",
      "Epoch 430/10000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 33.9367 - mse: 33.9367 - val_loss: 74.9742 - val_mse: 74.9742\n",
      "Epoch 431/10000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 36.3179 - mse: 36.3179 - val_loss: 75.4989 - val_mse: 75.4989\n",
      "Epoch 432/10000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 36.9992 - mse: 36.9992 - val_loss: 71.0085 - val_mse: 71.0085\n",
      "Epoch 433/10000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 40.2881 - mse: 40.2881 - val_loss: 66.0458 - val_mse: 66.0458\n",
      "Epoch 434/10000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 44.0907 - mse: 44.0907 - val_loss: 61.4221 - val_mse: 61.4221\n",
      "Epoch 435/10000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 34.6897 - mse: 34.6897 - val_loss: 55.8460 - val_mse: 55.8460\n",
      "Epoch 436/10000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 30.0434 - mse: 30.0434 - val_loss: 49.7890 - val_mse: 49.7890\n",
      "Epoch 437/10000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 43.2600 - mse: 43.2600 - val_loss: 49.2296 - val_mse: 49.2296\n",
      "Epoch 438/10000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 37.5248 - mse: 37.5248 - val_loss: 51.7157 - val_mse: 51.7157\n",
      "Epoch 439/10000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 34.8620 - mse: 34.8620 - val_loss: 52.4530 - val_mse: 52.4530\n",
      "Epoch 440/10000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 39.2132 - mse: 39.2132 - val_loss: 58.1294 - val_mse: 58.1294\n",
      "Epoch 441/10000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 31.8006 - mse: 31.8006 - val_loss: 58.6568 - val_mse: 58.6568\n",
      "Epoch 442/10000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 32.7808 - mse: 32.7808 - val_loss: 64.6477 - val_mse: 64.6477\n",
      "Epoch 443/10000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 32.5139 - mse: 32.5139 - val_loss: 65.1681 - val_mse: 65.1681\n",
      "Epoch 444/10000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 35.0883 - mse: 35.0883 - val_loss: 63.6750 - val_mse: 63.6750\n",
      "Epoch 445/10000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 29.2715 - mse: 29.2715 - val_loss: 59.6902 - val_mse: 59.6902\n",
      "Epoch 446/10000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 31.5619 - mse: 31.5619 - val_loss: 57.2501 - val_mse: 57.2501\n",
      "Epoch 447/10000\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 33.4304 - mse: 33.4304 - val_loss: 55.5375 - val_mse: 55.5375\n",
      "Epoch 448/10000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 35.6704 - mse: 35.6704 - val_loss: 45.7306 - val_mse: 45.7306\n",
      "Epoch 449/10000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 45.1632 - mse: 45.1632 - val_loss: 45.6303 - val_mse: 45.6303\n",
      "Epoch 450/10000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 30.7841 - mse: 30.7841 - val_loss: 46.8386 - val_mse: 46.8386\n",
      "Epoch 451/10000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 40.0078 - mse: 40.0078 - val_loss: 48.3928 - val_mse: 48.3928\n",
      "Epoch 452/10000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 43.8470 - mse: 43.8470 - val_loss: 51.3468 - val_mse: 51.3468\n",
      "Epoch 453/10000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 30.6438 - mse: 30.6438 - val_loss: 54.9631 - val_mse: 54.9631\n",
      "Epoch 454/10000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 33.0598 - mse: 33.0598 - val_loss: 57.4368 - val_mse: 57.4368\n",
      "Epoch 455/10000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 33.5771 - mse: 33.5771 - val_loss: 56.3765 - val_mse: 56.3765\n",
      "Epoch 456/10000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 32.6117 - mse: 32.6117 - val_loss: 54.0714 - val_mse: 54.0714\n",
      "Epoch 457/10000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 28.6663 - mse: 28.6663 - val_loss: 52.4777 - val_mse: 52.4777\n",
      "Epoch 458/10000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 36.9313 - mse: 36.9313 - val_loss: 51.7206 - val_mse: 51.7206\n",
      "Epoch 459/10000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 32.5806 - mse: 32.5806 - val_loss: 51.8714 - val_mse: 51.8714\n",
      "Epoch 460/10000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 35.0990 - mse: 35.0990 - val_loss: 52.6230 - val_mse: 52.6230\n",
      "Epoch 461/10000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 31.0327 - mse: 31.0327 - val_loss: 54.4277 - val_mse: 54.4277\n",
      "Epoch 462/10000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 35.8146 - mse: 35.8146 - val_loss: 58.9411 - val_mse: 58.9411\n",
      "Epoch 463/10000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 40.6687 - mse: 40.6687 - val_loss: 62.6706 - val_mse: 62.6706\n",
      "Epoch 464/10000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 32.7551 - mse: 32.7551 - val_loss: 72.3871 - val_mse: 72.3871\n",
      "Epoch 465/10000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 36.3161 - mse: 36.3161 - val_loss: 76.0599 - val_mse: 76.0599\n",
      "Epoch 466/10000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 28.7022 - mse: 28.7022 - val_loss: 76.8065 - val_mse: 76.8065\n",
      "Epoch 467/10000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 25.1867 - mse: 25.1867 - val_loss: 72.5906 - val_mse: 72.5906\n",
      "Epoch 468/10000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 26.8668 - mse: 26.8668 - val_loss: 67.2018 - val_mse: 67.2018\n",
      "Epoch 469/10000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 27.4796 - mse: 27.4796 - val_loss: 62.4323 - val_mse: 62.4323\n",
      "Epoch 470/10000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 31.4026 - mse: 31.4026 - val_loss: 59.5548 - val_mse: 59.5548\n",
      "Epoch 471/10000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 35.9560 - mse: 35.9560 - val_loss: 60.1688 - val_mse: 60.1688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 472/10000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 26.2146 - mse: 26.2146 - val_loss: 59.6392 - val_mse: 59.6392\n",
      "Epoch 473/10000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 29.5367 - mse: 29.5367 - val_loss: 61.5502 - val_mse: 61.5502\n",
      "Epoch 474/10000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 40.0764 - mse: 40.0764 - val_loss: 66.9858 - val_mse: 66.9858\n",
      "Epoch 475/10000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 39.2941 - mse: 39.2941 - val_loss: 72.5161 - val_mse: 72.5161\n",
      "Epoch 476/10000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 31.3806 - mse: 31.3806 - val_loss: 76.7114 - val_mse: 76.7114\n",
      "Epoch 477/10000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 39.4790 - mse: 39.4790 - val_loss: 77.3142 - val_mse: 77.3142\n",
      "Epoch 478/10000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 32.3813 - mse: 32.3813 - val_loss: 73.0824 - val_mse: 73.0824\n",
      "Epoch 479/10000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 32.3683 - mse: 32.3683 - val_loss: 62.9902 - val_mse: 62.9902\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10000\n",
    "history = model.fit(\n",
    "    train_ds_b, \n",
    "    validation_data=val_ds_b,  \n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = history.history\n",
    "plt.plot(history.epoch, np.sqrt(metrics['mse']), np.sqrt(metrics['val_mse']))\n",
    "plt.legend(['rmse', 'val_rmse'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 91ms/step - loss: 93.9588 - mse: 93.9588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([9.69323403, 9.69323403])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(model.evaluate(test_ds.batch(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 96ms/step - loss: 62.9902 - mse: 62.9902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7.93663897, 7.93663897])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(model.evaluate(val_ds.batch(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 36s 36s/step - loss: 93.9588 - mse: 93.9588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([9.69323403, 9.69323403])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(model.evaluate(test_ds.batch(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(preprocess_dataset([train_files[0]]).batch(30), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(get_data(train_files[0])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data(train_files[5])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = meta.assign(split = '', predict = -99.99, predict_group = 'cc')\n",
    "for file in train_files:\n",
    "    ID = file.numpy().decode('utf-8').split('/')[-1].split('.')[0]\n",
    "    predict = model.predict(get_data(file)[0]).mean()\n",
    "    meta.at[np.where(meta.ID == (ID + ' '))[0][0], 'predict'] = max(1, min(predict, 30))\n",
    "    meta.at[np.where(meta.ID == (ID + ' '))[0][0], 'split'] = 'train'\n",
    "    if (predict < 24):\n",
    "        meta.at[np.where(meta.ID == (ID + ' '))[0][0], 'predict_group'] = 'cd'\n",
    "for file in test_files:\n",
    "    ID = file.numpy().decode('utf-8').split('/')[-1].split('.')[0]\n",
    "    predict = model.predict(get_data(file)[0]).mean()\n",
    "    meta.at[np.where(meta.ID == (ID + ' '))[0][0], 'predict'] = max(1, min(predict, 30))\n",
    "    meta.at[np.where(meta.ID == (ID + ' '))[0][0], 'split'] = 'test'\n",
    "    if (predict < 24):\n",
    "        meta.at[np.where(meta.ID == (ID + ' '))[0][0], 'predict_group'] = 'cd'\n",
    "for file in val_files:\n",
    "    ID = file.numpy().decode('utf-8').split('/')[-1].split('.')[0]\n",
    "    predict = model.predict(get_data(file)[0]).mean()\n",
    "    meta.at[np.where(meta.ID == (ID + ' '))[0][0], 'predict'] = max(1, min(predict, 30))\n",
    "    meta.at[np.where(meta.ID == (ID + ' '))[0][0], 'split'] = 'val'\n",
    "    if (predict < 24):\n",
    "        meta.at[np.where(meta.ID == (ID + ' '))[0][0], 'predict_group'] = 'cd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.predict.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, mean_squared_error\n",
    "def cal_rmse(g):\n",
    "    rmse = np.sqrt(mean_squared_error(g['MMSE'], g['predict'] ) )\n",
    "    return pd.Series(dict(rmse = rmse ))\n",
    "\n",
    "meta.groupby('split').apply(cal_rmse).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "meta.groupby('Gender').apply(cal_rmse).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(meta['MMSE'], meta['predict'] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(meta) + \\\n",
    "geom_point(aes(x = 'MMSE', y = 'predict', colour = 'split')) + \\\n",
    "facet_wrap('split', nrow = 1) + \\\n",
    "geom_abline(aes(intercept = 0, slope = 1, lty = 2)) + \\\n",
    "geom_hline(aes(yintercept = 24, lty = 2)) + \\\n",
    "geom_vline(aes(xintercept = 24, lty = 2)) + \\\n",
    "theme(figure_size = (15, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = meta.Group\n",
    "y_pred = meta.predict_group\n",
    "data = confusion_matrix(y_true, y_pred)\n",
    "df_cm = pd.DataFrame(data, columns=np.unique(y_true), index = np.unique(y_true))\n",
    "df_cm.index.name = 'Actual'\n",
    "df_cm.columns.name = 'Predicted'\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.set(font_scale=1.4)#for label size\n",
    "sn.heatmap(df_cm, cmap=\"Reds\", annot=True,annot_kws={\"size\": 16})# font size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('saved_model/base_line/20210222')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls saved_model/base_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
