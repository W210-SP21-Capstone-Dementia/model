{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "import pathlib\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from plotnine import *\n",
    "import seaborn as sn\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "\n",
    "seed = 30\n",
    "tf.random.set_seed(seed)\n",
    "gpus = tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## need this if training on GPU\n",
    "## tensorflow, get your shit together\n",
    "\n",
    "if len(gpus)>0:\n",
    "\n",
    "    from tensorflow.compat.v1 import ConfigProto\n",
    "    from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "    config = ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/tf/data/dementia/0extra/ADReSS-IS2020-data/train'\n",
    "\n",
    "filenames = tf.random.shuffle(tf.io.gfile.glob(data_path + '/Full_wave_enhanced_audio/*/*'))\n",
    "\n",
    "train_cutoff = int(len(filenames)*0.7)\n",
    "val_cutoff = int(len(filenames)*0.85)\n",
    "\n",
    "train_files = filenames[:train_cutoff]\n",
    "val_files = filenames[train_cutoff:val_cutoff]\n",
    "test_files = filenames[val_cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_cc = pd.read_csv(data_path + '/cc_meta_data.txt', sep=\";\", header=0, \n",
    "                  names = ['ID', 'Age', 'Gender', 'MMSE'])\n",
    "meta_cd = pd.read_csv(data_path + '/cd_meta_data.txt', sep=\";\", header=0, \n",
    "                      names = ['ID', 'Age', 'Gender', 'MMSE'])\n",
    "\n",
    "meta = meta_cc.assign(Group = 'cc').append(meta_cd.assign(Group = 'cd')).reset_index()\n",
    "meta.MMSE = pd.to_numeric(meta.MMSE.replace(' NA', 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(w):\n",
    "    ret = w + tf.where(tf.math.abs(w) > 0.1, tf.random.normal([len(w)], mean = 0, stddev = tf.math.reduce_std(w)), 0)\n",
    "    return ret\n",
    "    \n",
    "def window(x, size, stride):\n",
    "    length = int(len(x))\n",
    "    if length // size == 0:\n",
    "        zero_padding =  tf.zeros([size] - tf.shape(x), dtype=tf.float32)\n",
    "        x = tf.cast(x, tf.float32)\n",
    "        x = tf.concat([x, zero_padding], 0)\n",
    "        length = int(len(x))\n",
    "    return tf.map_fn(lambda i: add_noise(x[i*stride:i*stride+size]), \n",
    "                     tf.repeat(tf.range((length-size)//stride+1), 1), dtype=tf.float32)\n",
    "\n",
    "def get_data(file_path):\n",
    "\n",
    "    names = meta.ID\n",
    "    name = tf.strings.split(tf.strings.split(file_path, os.path.sep)[-1], '.')[0] + ' '\n",
    "    label = tf.gather(meta.MMSE, tf.where(tf.equal(names, name))[0][0])\n",
    "    \n",
    "    audio_binary = tf.io.read_file(file_path)\n",
    "    audio, _ = tf.audio.decode_wav(audio_binary)\n",
    "    waveform = tf.squeeze(audio, axis=-1)\n",
    "        \n",
    "    rolling_waveform_tensors = window(waveform, size=_*size_sec, stride=_*stride_sec)\n",
    "    rolling_spectrograms = tf.signal.stft(rolling_waveform_tensors, frame_length=512, frame_step=_)\n",
    "    rolling_spectrograms = tf.abs(rolling_spectrograms)\n",
    "    rolling_spectrograms = tf.expand_dims(rolling_spectrograms, -1)\n",
    "        \n",
    "    return rolling_spectrograms, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(files):\n",
    "    files_ds = tf.data.Dataset.from_tensor_slices(files)\n",
    "    output_ds = files_ds.map(get_data, num_parallel_calls=AUTOTUNE)\\\n",
    "                        .cache()\\\n",
    "                        .prefetch(100)\\\n",
    "                        .flat_map(lambda x,y: tf.data.Dataset.zip((\n",
    "                                    tf.data.Dataset.from_tensor_slices(x), \n",
    "                                    tf.data.Dataset.from_tensor_slices([y])\n",
    "                        )))\\\n",
    "                        .shuffle(100)\n",
    "    return output_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_sec = 30\n",
    "stride_sec = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:605: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n"
     ]
    }
   ],
   "source": [
    "train_ds = preprocess_dataset(tf.repeat(train_files, 100))\n",
    "val_ds = preprocess_dataset(tf.repeat(val_files, 100))\n",
    "test_ds = preprocess_dataset(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for spectrogram, y in train_ds.take(1):\n",
    "#     input_shape = spectrogram.shape\n",
    "#     print(input_shape)\n",
    "#     print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (30, 257, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_ds_b = train_ds.batch(batch_size)\n",
    "val_ds_b = val_ds.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (30, 257, 1)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 30, 257)           0         \n",
      "_________________________________________________________________\n",
      "normalization (Normalization (None, 30, 257)           3         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 30, 128)           197632    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 30, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 249,796\n",
      "Trainable params: 249,793\n",
      "Non-trainable params: 3\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print('Input shape:', input_shape)\n",
    "\n",
    "norm_layer = preprocessing.Normalization()\n",
    "norm_layer.adapt(train_ds.map(lambda x, _: x))\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=input_shape),\n",
    "    layers.Reshape((input_shape[0],input_shape[1])),\n",
    "    norm_layer,\n",
    "    \n",
    "#     layers.LSTM(256, activation='relu', kernel_initializer='he_normal', return_sequences=True),\n",
    "#     layers.Dropout(0.5),\n",
    "    layers.LSTM(128, activation='relu', kernel_initializer='he_normal', return_sequences=True),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.LSTM(64, activation='relu', kernel_initializer='he_normal'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(32, activation='relu', kernel_initializer='he_normal'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(16, activation='relu', kernel_initializer='he_normal'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(8, activation='relu', kernel_initializer='he_normal'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='relu', kernel_initializer='he_normal')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=200, restore_best_weights=True)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, clipnorm=1.0),\n",
    "    loss='mse',\n",
    "    metrics='mse'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f3f4451b780>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class SquareRootScheduler:\n",
    "    def __init__(self, lr=0.1):\n",
    "        self.lr = lr\n",
    "\n",
    "    def __call__(self, num_update):\n",
    "        return self.lr * pow(num_update + 1.0, -0.1)\n",
    "    \n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(SquareRootScheduler(lr=0.001))\n",
    "scheduler = SquareRootScheduler(lr=0.001)\n",
    "plt.plot(tf.range(1000), [scheduler(t) for t in range(1000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "30/30 - 78s - loss: 919.9403 - mse: 919.9403 - val_loss: 501.2048 - val_mse: 501.2048\n",
      "Epoch 2/10000\n",
      "30/30 - 2s - loss: 568.5717 - mse: 568.5717 - val_loss: 702.1910 - val_mse: 702.1910\n",
      "Epoch 3/10000\n",
      "30/30 - 2s - loss: 1065.0068 - mse: 1065.0068 - val_loss: 342.7120 - val_mse: 342.7120\n",
      "Epoch 4/10000\n",
      "30/30 - 2s - loss: 379.2697 - mse: 379.2697 - val_loss: 352.2323 - val_mse: 352.2323\n",
      "Epoch 5/10000\n",
      "30/30 - 2s - loss: 361.7126 - mse: 361.7126 - val_loss: 307.2768 - val_mse: 307.2768\n",
      "Epoch 6/10000\n",
      "30/30 - 2s - loss: 339.3107 - mse: 339.3107 - val_loss: 202.9383 - val_mse: 202.9383\n",
      "Epoch 7/10000\n",
      "30/30 - 2s - loss: 1220.1578 - mse: 1220.1578 - val_loss: 316.8748 - val_mse: 316.8748\n",
      "Epoch 8/10000\n",
      "30/30 - 2s - loss: 311.8332 - mse: 311.8332 - val_loss: 208.4263 - val_mse: 208.4263\n",
      "Epoch 9/10000\n",
      "30/30 - 2s - loss: 287.2213 - mse: 287.2213 - val_loss: 153.7802 - val_mse: 153.7802\n",
      "Epoch 10/10000\n",
      "30/30 - 2s - loss: 265.1424 - mse: 265.1424 - val_loss: 185.4435 - val_mse: 185.4435\n",
      "Epoch 11/10000\n",
      "30/30 - 2s - loss: 253.5418 - mse: 253.5418 - val_loss: 207.1033 - val_mse: 207.1033\n",
      "Epoch 12/10000\n",
      "30/30 - 2s - loss: 261.8909 - mse: 261.8909 - val_loss: 205.6691 - val_mse: 205.6691\n",
      "Epoch 13/10000\n",
      "30/30 - 2s - loss: 247.1977 - mse: 247.1977 - val_loss: 168.1138 - val_mse: 168.1138\n",
      "Epoch 14/10000\n",
      "30/30 - 2s - loss: 233.0318 - mse: 233.0318 - val_loss: 158.4531 - val_mse: 158.4531\n",
      "Epoch 15/10000\n",
      "30/30 - 2s - loss: 225.1444 - mse: 225.1444 - val_loss: 193.6908 - val_mse: 193.6908\n",
      "Epoch 16/10000\n",
      "30/30 - 2s - loss: 213.2705 - mse: 213.2705 - val_loss: 179.3413 - val_mse: 179.3413\n",
      "Epoch 17/10000\n",
      "30/30 - 2s - loss: 209.7249 - mse: 209.7249 - val_loss: 179.3730 - val_mse: 179.3730\n",
      "Epoch 18/10000\n",
      "30/30 - 2s - loss: 207.9848 - mse: 207.9848 - val_loss: 159.5603 - val_mse: 159.5603\n",
      "Epoch 19/10000\n",
      "30/30 - 2s - loss: 206.0860 - mse: 206.0860 - val_loss: 109.7937 - val_mse: 109.7937\n",
      "Epoch 20/10000\n",
      "30/30 - 2s - loss: 198.3833 - mse: 198.3833 - val_loss: 133.5485 - val_mse: 133.5485\n",
      "Epoch 21/10000\n",
      "30/30 - 2s - loss: 199.4391 - mse: 199.4391 - val_loss: 123.9707 - val_mse: 123.9707\n",
      "Epoch 22/10000\n",
      "30/30 - 2s - loss: 185.0854 - mse: 185.0854 - val_loss: 141.3360 - val_mse: 141.3360\n",
      "Epoch 23/10000\n",
      "30/30 - 2s - loss: 187.6005 - mse: 187.6005 - val_loss: 90.1302 - val_mse: 90.1302\n",
      "Epoch 24/10000\n",
      "30/30 - 2s - loss: 175.5707 - mse: 175.5707 - val_loss: 118.4049 - val_mse: 118.4049\n",
      "Epoch 25/10000\n",
      "30/30 - 2s - loss: 173.8357 - mse: 173.8357 - val_loss: 115.6853 - val_mse: 115.6853\n",
      "Epoch 26/10000\n",
      "30/30 - 2s - loss: 167.7906 - mse: 167.7906 - val_loss: 111.6596 - val_mse: 111.6596\n",
      "Epoch 27/10000\n",
      "30/30 - 2s - loss: 170.0400 - mse: 170.0400 - val_loss: 101.9299 - val_mse: 101.9299\n",
      "Epoch 28/10000\n",
      "30/30 - 2s - loss: 163.9791 - mse: 163.9791 - val_loss: 133.7432 - val_mse: 133.7432\n",
      "Epoch 29/10000\n",
      "30/30 - 2s - loss: 171.7626 - mse: 171.7626 - val_loss: 99.7970 - val_mse: 99.7970\n",
      "Epoch 30/10000\n",
      "30/30 - 2s - loss: 161.9181 - mse: 161.9181 - val_loss: 98.3030 - val_mse: 98.3030\n",
      "Epoch 31/10000\n",
      "30/30 - 2s - loss: 163.3148 - mse: 163.3148 - val_loss: 97.0288 - val_mse: 97.0288\n",
      "Epoch 32/10000\n",
      "30/30 - 2s - loss: 157.4881 - mse: 157.4881 - val_loss: 115.4363 - val_mse: 115.4363\n",
      "Epoch 33/10000\n",
      "30/30 - 2s - loss: 158.6595 - mse: 158.6595 - val_loss: 101.5750 - val_mse: 101.5750\n",
      "Epoch 34/10000\n",
      "30/30 - 2s - loss: 152.9923 - mse: 152.9923 - val_loss: 108.6331 - val_mse: 108.6331\n",
      "Epoch 35/10000\n",
      "30/30 - 2s - loss: 144.6568 - mse: 144.6568 - val_loss: 110.9288 - val_mse: 110.9288\n",
      "Epoch 36/10000\n",
      "30/30 - 2s - loss: 146.0982 - mse: 146.0982 - val_loss: 125.5360 - val_mse: 125.5360\n",
      "Epoch 37/10000\n",
      "30/30 - 2s - loss: 143.2686 - mse: 143.2686 - val_loss: 128.7219 - val_mse: 128.7219\n",
      "Epoch 38/10000\n",
      "30/30 - 2s - loss: 142.9052 - mse: 142.9052 - val_loss: 102.2053 - val_mse: 102.2053\n",
      "Epoch 39/10000\n",
      "30/30 - 2s - loss: 139.7834 - mse: 139.7834 - val_loss: 96.8446 - val_mse: 96.8446\n",
      "Epoch 40/10000\n",
      "30/30 - 2s - loss: 145.6177 - mse: 145.6177 - val_loss: 113.7581 - val_mse: 113.7581\n",
      "Epoch 41/10000\n",
      "30/30 - 2s - loss: 137.6692 - mse: 137.6692 - val_loss: 103.3110 - val_mse: 103.3110\n",
      "Epoch 42/10000\n",
      "30/30 - 2s - loss: 136.4175 - mse: 136.4175 - val_loss: 131.1583 - val_mse: 131.1583\n",
      "Epoch 43/10000\n",
      "30/30 - 2s - loss: 133.2008 - mse: 133.2008 - val_loss: 101.7318 - val_mse: 101.7318\n",
      "Epoch 44/10000\n",
      "30/30 - 2s - loss: 133.9663 - mse: 133.9663 - val_loss: 111.9729 - val_mse: 111.9729\n",
      "Epoch 45/10000\n",
      "30/30 - 2s - loss: 128.1803 - mse: 128.1803 - val_loss: 101.8946 - val_mse: 101.8946\n",
      "Epoch 46/10000\n",
      "30/30 - 2s - loss: 124.9562 - mse: 124.9562 - val_loss: 113.5211 - val_mse: 113.5211\n",
      "Epoch 47/10000\n",
      "30/30 - 2s - loss: 127.2759 - mse: 127.2759 - val_loss: 128.6121 - val_mse: 128.6121\n",
      "Epoch 48/10000\n",
      "30/30 - 2s - loss: 127.7872 - mse: 127.7872 - val_loss: 113.1174 - val_mse: 113.1174\n",
      "Epoch 49/10000\n",
      "30/30 - 2s - loss: 125.7644 - mse: 125.7644 - val_loss: 131.6382 - val_mse: 131.6382\n",
      "Epoch 50/10000\n",
      "30/30 - 2s - loss: 125.2270 - mse: 125.2270 - val_loss: 113.7739 - val_mse: 113.7739\n",
      "Epoch 51/10000\n",
      "30/30 - 2s - loss: 118.6792 - mse: 118.6792 - val_loss: 109.4669 - val_mse: 109.4669\n",
      "Epoch 52/10000\n",
      "30/30 - 2s - loss: 117.6882 - mse: 117.6882 - val_loss: 108.4668 - val_mse: 108.4668\n",
      "Epoch 53/10000\n",
      "30/30 - 2s - loss: 119.5434 - mse: 119.5434 - val_loss: 102.0519 - val_mse: 102.0519\n",
      "Epoch 54/10000\n",
      "30/30 - 2s - loss: 119.6898 - mse: 119.6898 - val_loss: 118.5402 - val_mse: 118.5402\n",
      "Epoch 55/10000\n",
      "30/30 - 2s - loss: 116.0060 - mse: 116.0060 - val_loss: 130.9572 - val_mse: 130.9572\n",
      "Epoch 56/10000\n",
      "30/30 - 2s - loss: 115.5508 - mse: 115.5508 - val_loss: 122.8186 - val_mse: 122.8186\n",
      "Epoch 57/10000\n",
      "30/30 - 2s - loss: 114.1975 - mse: 114.1975 - val_loss: 110.7058 - val_mse: 110.7058\n",
      "Epoch 58/10000\n",
      "30/30 - 2s - loss: 113.2011 - mse: 113.2011 - val_loss: 105.5896 - val_mse: 105.5896\n",
      "Epoch 59/10000\n",
      "30/30 - 2s - loss: 112.9484 - mse: 112.9484 - val_loss: 131.4337 - val_mse: 131.4337\n",
      "Epoch 60/10000\n",
      "30/30 - 2s - loss: 108.0158 - mse: 108.0158 - val_loss: 109.1404 - val_mse: 109.1404\n",
      "Epoch 61/10000\n",
      "30/30 - 2s - loss: 108.1338 - mse: 108.1338 - val_loss: 133.2699 - val_mse: 133.2699\n",
      "Epoch 62/10000\n",
      "30/30 - 3s - loss: 106.1015 - mse: 106.1015 - val_loss: 119.7687 - val_mse: 119.7687\n",
      "Epoch 63/10000\n",
      "30/30 - 2s - loss: 105.5547 - mse: 105.5547 - val_loss: 119.5531 - val_mse: 119.5531\n",
      "Epoch 64/10000\n",
      "30/30 - 2s - loss: 101.6964 - mse: 101.6964 - val_loss: 140.7148 - val_mse: 140.7148\n",
      "Epoch 65/10000\n",
      "30/30 - 2s - loss: 102.8672 - mse: 102.8672 - val_loss: 127.8874 - val_mse: 127.8874\n",
      "Epoch 66/10000\n",
      "30/30 - 2s - loss: 101.0847 - mse: 101.0847 - val_loss: 132.3432 - val_mse: 132.3432\n",
      "Epoch 67/10000\n",
      "30/30 - 2s - loss: 100.8452 - mse: 100.8452 - val_loss: 119.0836 - val_mse: 119.0836\n",
      "Epoch 68/10000\n",
      "30/30 - 2s - loss: 98.0651 - mse: 98.0651 - val_loss: 116.3089 - val_mse: 116.3089\n",
      "Epoch 69/10000\n",
      "30/30 - 2s - loss: 98.6550 - mse: 98.6550 - val_loss: 99.5047 - val_mse: 99.5047\n",
      "Epoch 70/10000\n",
      "30/30 - 2s - loss: 97.9181 - mse: 97.9181 - val_loss: 128.3519 - val_mse: 128.3519\n",
      "Epoch 71/10000\n",
      "30/30 - 2s - loss: 100.0923 - mse: 100.0923 - val_loss: 107.2790 - val_mse: 107.2790\n",
      "Epoch 72/10000\n",
      "30/30 - 2s - loss: 93.8128 - mse: 93.8128 - val_loss: 133.5355 - val_mse: 133.5355\n",
      "Epoch 73/10000\n",
      "30/30 - 2s - loss: 94.6102 - mse: 94.6102 - val_loss: 145.0056 - val_mse: 145.0056\n",
      "Epoch 74/10000\n",
      "30/30 - 2s - loss: 94.5529 - mse: 94.5529 - val_loss: 115.1842 - val_mse: 115.1842\n",
      "Epoch 75/10000\n",
      "30/30 - 2s - loss: 96.9483 - mse: 96.9483 - val_loss: 112.9783 - val_mse: 112.9783\n",
      "Epoch 76/10000\n",
      "30/30 - 2s - loss: 95.1968 - mse: 95.1968 - val_loss: 114.5906 - val_mse: 114.5906\n",
      "Epoch 77/10000\n",
      "30/30 - 2s - loss: 95.2975 - mse: 95.2975 - val_loss: 110.7729 - val_mse: 110.7729\n",
      "Epoch 78/10000\n",
      "30/30 - 2s - loss: 92.2461 - mse: 92.2461 - val_loss: 103.2257 - val_mse: 103.2257\n",
      "Epoch 79/10000\n",
      "30/30 - 2s - loss: 98.5031 - mse: 98.5031 - val_loss: 109.0346 - val_mse: 109.0346\n",
      "Epoch 80/10000\n",
      "30/30 - 2s - loss: 92.2250 - mse: 92.2250 - val_loss: 105.3148 - val_mse: 105.3148\n",
      "Epoch 81/10000\n",
      "30/30 - 2s - loss: 93.6974 - mse: 93.6974 - val_loss: 97.8389 - val_mse: 97.8389\n",
      "Epoch 82/10000\n",
      "30/30 - 2s - loss: 90.5940 - mse: 90.5940 - val_loss: 110.4002 - val_mse: 110.4002\n",
      "Epoch 83/10000\n",
      "30/30 - 2s - loss: 90.5800 - mse: 90.5800 - val_loss: 128.0975 - val_mse: 128.0975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/10000\n",
      "30/30 - 2s - loss: 87.0200 - mse: 87.0200 - val_loss: 101.6539 - val_mse: 101.6539\n",
      "Epoch 85/10000\n",
      "30/30 - 2s - loss: 88.4952 - mse: 88.4952 - val_loss: 106.8169 - val_mse: 106.8169\n",
      "Epoch 86/10000\n",
      "30/30 - 2s - loss: 88.0865 - mse: 88.0865 - val_loss: 96.1714 - val_mse: 96.1714\n",
      "Epoch 87/10000\n",
      "30/30 - 2s - loss: 89.4167 - mse: 89.4167 - val_loss: 101.2633 - val_mse: 101.2633\n",
      "Epoch 88/10000\n",
      "30/30 - 2s - loss: 85.8828 - mse: 85.8828 - val_loss: 89.9316 - val_mse: 89.9316\n",
      "Epoch 89/10000\n",
      "30/30 - 2s - loss: 88.5631 - mse: 88.5631 - val_loss: 93.6935 - val_mse: 93.6935\n",
      "Epoch 90/10000\n",
      "30/30 - 2s - loss: 85.3827 - mse: 85.3827 - val_loss: 111.6009 - val_mse: 111.6009\n",
      "Epoch 91/10000\n",
      "30/30 - 2s - loss: 85.8574 - mse: 85.8574 - val_loss: 97.9367 - val_mse: 97.9367\n",
      "Epoch 92/10000\n",
      "30/30 - 2s - loss: 87.5800 - mse: 87.5800 - val_loss: 96.7812 - val_mse: 96.7812\n",
      "Epoch 93/10000\n",
      "30/30 - 2s - loss: 85.2861 - mse: 85.2861 - val_loss: 100.9341 - val_mse: 100.9341\n",
      "Epoch 94/10000\n",
      "30/30 - 2s - loss: 86.1747 - mse: 86.1747 - val_loss: 103.0606 - val_mse: 103.0606\n",
      "Epoch 95/10000\n",
      "30/30 - 2s - loss: 85.7389 - mse: 85.7389 - val_loss: 113.3526 - val_mse: 113.3526\n",
      "Epoch 96/10000\n",
      "30/30 - 2s - loss: 85.4219 - mse: 85.4219 - val_loss: 104.0070 - val_mse: 104.0070\n",
      "Epoch 97/10000\n",
      "30/30 - 2s - loss: 86.7464 - mse: 86.7464 - val_loss: 105.1739 - val_mse: 105.1739\n",
      "Epoch 98/10000\n",
      "30/30 - 2s - loss: 84.1857 - mse: 84.1857 - val_loss: 107.3812 - val_mse: 107.3812\n",
      "Epoch 99/10000\n",
      "30/30 - 3s - loss: 83.1377 - mse: 83.1377 - val_loss: 122.2731 - val_mse: 122.2731\n",
      "Epoch 100/10000\n",
      "30/30 - 2s - loss: 83.6456 - mse: 83.6456 - val_loss: 116.5508 - val_mse: 116.5508\n",
      "Epoch 101/10000\n",
      "30/30 - 2s - loss: 84.0942 - mse: 84.0942 - val_loss: 129.7249 - val_mse: 129.7249\n",
      "Epoch 102/10000\n",
      "30/30 - 2s - loss: 81.2862 - mse: 81.2862 - val_loss: 120.5076 - val_mse: 120.5076\n",
      "Epoch 103/10000\n",
      "30/30 - 2s - loss: 83.2530 - mse: 83.2530 - val_loss: 91.8228 - val_mse: 91.8228\n",
      "Epoch 104/10000\n",
      "30/30 - 2s - loss: 83.4544 - mse: 83.4544 - val_loss: 112.8277 - val_mse: 112.8277\n",
      "Epoch 105/10000\n",
      "30/30 - 2s - loss: 85.1179 - mse: 85.1179 - val_loss: 104.6668 - val_mse: 104.6668\n",
      "Epoch 106/10000\n",
      "30/30 - 2s - loss: 78.5959 - mse: 78.5959 - val_loss: 98.8926 - val_mse: 98.8926\n",
      "Epoch 107/10000\n",
      "30/30 - 2s - loss: 80.5446 - mse: 80.5446 - val_loss: 108.8452 - val_mse: 108.8452\n",
      "Epoch 108/10000\n",
      "30/30 - 2s - loss: 80.5310 - mse: 80.5310 - val_loss: 98.2823 - val_mse: 98.2823\n",
      "Epoch 109/10000\n",
      "30/30 - 2s - loss: 80.2817 - mse: 80.2817 - val_loss: 95.0810 - val_mse: 95.0810\n",
      "Epoch 110/10000\n",
      "30/30 - 2s - loss: 79.9191 - mse: 79.9191 - val_loss: 113.6483 - val_mse: 113.6483\n",
      "Epoch 111/10000\n",
      "30/30 - 2s - loss: 80.8099 - mse: 80.8099 - val_loss: 114.4332 - val_mse: 114.4332\n",
      "Epoch 112/10000\n",
      "30/30 - 2s - loss: 79.0763 - mse: 79.0763 - val_loss: 85.9701 - val_mse: 85.9701\n",
      "Epoch 113/10000\n",
      "30/30 - 2s - loss: 80.7301 - mse: 80.7301 - val_loss: 111.5309 - val_mse: 111.5309\n",
      "Epoch 114/10000\n",
      "30/30 - 2s - loss: 81.2766 - mse: 81.2766 - val_loss: 110.0827 - val_mse: 110.0827\n",
      "Epoch 115/10000\n",
      "30/30 - 2s - loss: 79.1542 - mse: 79.1542 - val_loss: 104.8185 - val_mse: 104.8185\n",
      "Epoch 116/10000\n",
      "30/30 - 2s - loss: 77.0691 - mse: 77.0691 - val_loss: 117.5397 - val_mse: 117.5397\n",
      "Epoch 117/10000\n",
      "30/30 - 2s - loss: 74.7830 - mse: 74.7830 - val_loss: 100.2201 - val_mse: 100.2201\n",
      "Epoch 118/10000\n",
      "30/30 - 2s - loss: 78.1739 - mse: 78.1739 - val_loss: 138.0380 - val_mse: 138.0380\n",
      "Epoch 119/10000\n",
      "30/30 - 2s - loss: 79.1842 - mse: 79.1842 - val_loss: 93.2419 - val_mse: 93.2419\n",
      "Epoch 120/10000\n",
      "30/30 - 2s - loss: 76.3196 - mse: 76.3196 - val_loss: 121.6404 - val_mse: 121.6404\n",
      "Epoch 121/10000\n",
      "30/30 - 2s - loss: 77.3648 - mse: 77.3648 - val_loss: 113.1562 - val_mse: 113.1562\n",
      "Epoch 122/10000\n",
      "30/30 - 2s - loss: 75.9855 - mse: 75.9855 - val_loss: 115.5581 - val_mse: 115.5581\n",
      "Epoch 123/10000\n",
      "30/30 - 2s - loss: 77.7570 - mse: 77.7570 - val_loss: 129.5125 - val_mse: 129.5125\n",
      "Epoch 124/10000\n",
      "30/30 - 2s - loss: 75.5025 - mse: 75.5025 - val_loss: 98.7661 - val_mse: 98.7661\n",
      "Epoch 125/10000\n",
      "30/30 - 2s - loss: 78.5813 - mse: 78.5813 - val_loss: 102.1867 - val_mse: 102.1867\n",
      "Epoch 126/10000\n",
      "30/30 - 2s - loss: 78.5893 - mse: 78.5893 - val_loss: 99.0649 - val_mse: 99.0649\n",
      "Epoch 127/10000\n",
      "30/30 - 2s - loss: 76.7588 - mse: 76.7588 - val_loss: 95.3249 - val_mse: 95.3249\n",
      "Epoch 128/10000\n",
      "30/30 - 2s - loss: 76.1227 - mse: 76.1227 - val_loss: 87.5771 - val_mse: 87.5771\n",
      "Epoch 129/10000\n",
      "30/30 - 2s - loss: 73.7615 - mse: 73.7615 - val_loss: 85.5686 - val_mse: 85.5686\n",
      "Epoch 130/10000\n",
      "30/30 - 2s - loss: 75.6582 - mse: 75.6582 - val_loss: 93.1138 - val_mse: 93.1138\n",
      "Epoch 131/10000\n",
      "30/30 - 2s - loss: 74.2760 - mse: 74.2760 - val_loss: 95.5898 - val_mse: 95.5898\n",
      "Epoch 132/10000\n",
      "30/30 - 2s - loss: 76.6173 - mse: 76.6173 - val_loss: 109.3429 - val_mse: 109.3429\n",
      "Epoch 133/10000\n",
      "30/30 - 2s - loss: 73.4014 - mse: 73.4014 - val_loss: 110.5397 - val_mse: 110.5397\n",
      "Epoch 134/10000\n",
      "30/30 - 2s - loss: 75.3021 - mse: 75.3021 - val_loss: 122.8585 - val_mse: 122.8585\n",
      "Epoch 135/10000\n",
      "30/30 - 2s - loss: 73.3926 - mse: 73.3926 - val_loss: 101.3621 - val_mse: 101.3621\n",
      "Epoch 136/10000\n",
      "30/30 - 3s - loss: 72.2733 - mse: 72.2733 - val_loss: 102.1802 - val_mse: 102.1802\n",
      "Epoch 137/10000\n",
      "30/30 - 2s - loss: 70.8084 - mse: 70.8084 - val_loss: 103.1420 - val_mse: 103.1420\n",
      "Epoch 138/10000\n",
      "30/30 - 2s - loss: 74.3119 - mse: 74.3119 - val_loss: 100.4616 - val_mse: 100.4616\n",
      "Epoch 139/10000\n",
      "30/30 - 2s - loss: 72.4215 - mse: 72.4215 - val_loss: 104.8362 - val_mse: 104.8362\n",
      "Epoch 140/10000\n",
      "30/30 - 2s - loss: 70.7181 - mse: 70.7181 - val_loss: 98.9003 - val_mse: 98.9003\n",
      "Epoch 141/10000\n",
      "30/30 - 2s - loss: 71.2183 - mse: 71.2183 - val_loss: 98.2360 - val_mse: 98.2360\n",
      "Epoch 142/10000\n",
      "30/30 - 2s - loss: 71.5978 - mse: 71.5978 - val_loss: 99.9382 - val_mse: 99.9382\n",
      "Epoch 143/10000\n",
      "30/30 - 2s - loss: 68.7709 - mse: 68.7709 - val_loss: 112.0922 - val_mse: 112.0922\n",
      "Epoch 144/10000\n",
      "30/30 - 2s - loss: 71.8076 - mse: 71.8076 - val_loss: 106.8824 - val_mse: 106.8824\n",
      "Epoch 145/10000\n",
      "30/30 - 2s - loss: 71.5906 - mse: 71.5906 - val_loss: 97.2037 - val_mse: 97.2037\n",
      "Epoch 146/10000\n",
      "30/30 - 2s - loss: 71.1431 - mse: 71.1431 - val_loss: 89.0852 - val_mse: 89.0852\n",
      "Epoch 147/10000\n",
      "30/30 - 2s - loss: 70.9172 - mse: 70.9172 - val_loss: 106.0591 - val_mse: 106.0591\n",
      "Epoch 148/10000\n",
      "30/30 - 2s - loss: 68.3501 - mse: 68.3501 - val_loss: 122.8625 - val_mse: 122.8625\n",
      "Epoch 149/10000\n",
      "30/30 - 2s - loss: 69.0934 - mse: 69.0934 - val_loss: 96.9367 - val_mse: 96.9367\n",
      "Epoch 150/10000\n",
      "30/30 - 2s - loss: 77.2338 - mse: 77.2338 - val_loss: 111.8106 - val_mse: 111.8106\n",
      "Epoch 151/10000\n",
      "30/30 - 2s - loss: 71.2016 - mse: 71.2016 - val_loss: 96.5630 - val_mse: 96.5630\n",
      "Epoch 152/10000\n",
      "30/30 - 2s - loss: 69.3423 - mse: 69.3423 - val_loss: 97.5824 - val_mse: 97.5824\n",
      "Epoch 153/10000\n",
      "30/30 - 2s - loss: 71.5910 - mse: 71.5910 - val_loss: 89.2953 - val_mse: 89.2953\n",
      "Epoch 154/10000\n",
      "30/30 - 2s - loss: 89.6169 - mse: 89.6169 - val_loss: 108.8298 - val_mse: 108.8298\n",
      "Epoch 155/10000\n",
      "30/30 - 2s - loss: 65.7347 - mse: 65.7347 - val_loss: 95.1708 - val_mse: 95.1708\n",
      "Epoch 156/10000\n",
      "30/30 - 2s - loss: 67.9644 - mse: 67.9644 - val_loss: 94.8240 - val_mse: 94.8240\n",
      "Epoch 157/10000\n",
      "30/30 - 2s - loss: 69.7867 - mse: 69.7867 - val_loss: 98.5306 - val_mse: 98.5306\n",
      "Epoch 158/10000\n",
      "30/30 - 2s - loss: 67.9386 - mse: 67.9386 - val_loss: 97.8014 - val_mse: 97.8014\n",
      "Epoch 159/10000\n",
      "30/30 - 2s - loss: 65.8577 - mse: 65.8577 - val_loss: 90.2352 - val_mse: 90.2352\n",
      "Epoch 160/10000\n",
      "30/30 - 2s - loss: 128.4866 - mse: 128.4866 - val_loss: 86.3002 - val_mse: 86.3002\n",
      "Epoch 161/10000\n",
      "30/30 - 2s - loss: 77.4315 - mse: 77.4315 - val_loss: 90.7695 - val_mse: 90.7695\n",
      "Epoch 162/10000\n",
      "30/30 - 2s - loss: 69.9825 - mse: 69.9825 - val_loss: 94.2122 - val_mse: 94.2122\n",
      "Epoch 163/10000\n",
      "30/30 - 2s - loss: 69.4848 - mse: 69.4848 - val_loss: 80.9594 - val_mse: 80.9594\n",
      "Epoch 164/10000\n",
      "30/30 - 2s - loss: 79.4133 - mse: 79.4133 - val_loss: 109.7341 - val_mse: 109.7341\n",
      "Epoch 165/10000\n",
      "30/30 - 2s - loss: 65.6956 - mse: 65.6956 - val_loss: 100.2408 - val_mse: 100.2408\n",
      "Epoch 166/10000\n",
      "30/30 - 2s - loss: 67.0074 - mse: 67.0074 - val_loss: 95.1725 - val_mse: 95.1725\n",
      "Epoch 167/10000\n",
      "30/30 - 2s - loss: 67.3264 - mse: 67.3264 - val_loss: 99.9279 - val_mse: 99.9279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/10000\n",
      "30/30 - 2s - loss: 68.5339 - mse: 68.5339 - val_loss: 94.6164 - val_mse: 94.6164\n",
      "Epoch 169/10000\n",
      "30/30 - 2s - loss: 66.7059 - mse: 66.7059 - val_loss: 91.0433 - val_mse: 91.0433\n",
      "Epoch 170/10000\n",
      "30/30 - 2s - loss: 67.8494 - mse: 67.8494 - val_loss: 97.2695 - val_mse: 97.2695\n",
      "Epoch 171/10000\n",
      "30/30 - 2s - loss: 66.3238 - mse: 66.3238 - val_loss: 101.0003 - val_mse: 101.0003\n",
      "Epoch 172/10000\n",
      "30/30 - 2s - loss: 67.2634 - mse: 67.2634 - val_loss: 96.7364 - val_mse: 96.7364\n",
      "Epoch 173/10000\n",
      "30/30 - 2s - loss: 66.5154 - mse: 66.5154 - val_loss: 108.4120 - val_mse: 108.4120\n",
      "Epoch 174/10000\n",
      "30/30 - 3s - loss: 66.2292 - mse: 66.2292 - val_loss: 99.2596 - val_mse: 99.2596\n",
      "Epoch 175/10000\n",
      "30/30 - 2s - loss: 66.5149 - mse: 66.5149 - val_loss: 103.6086 - val_mse: 103.6086\n",
      "Epoch 176/10000\n",
      "30/30 - 2s - loss: 65.7661 - mse: 65.7661 - val_loss: 98.0402 - val_mse: 98.0402\n",
      "Epoch 177/10000\n",
      "30/30 - 2s - loss: 69.5416 - mse: 69.5416 - val_loss: 81.9903 - val_mse: 81.9903\n",
      "Epoch 178/10000\n",
      "30/30 - 2s - loss: 65.6599 - mse: 65.6599 - val_loss: 92.7721 - val_mse: 92.7721\n",
      "Epoch 179/10000\n",
      "30/30 - 2s - loss: 64.4668 - mse: 64.4668 - val_loss: 99.3535 - val_mse: 99.3535\n",
      "Epoch 180/10000\n",
      "30/30 - 2s - loss: 66.2697 - mse: 66.2697 - val_loss: 113.3771 - val_mse: 113.3771\n",
      "Epoch 181/10000\n",
      "30/30 - 2s - loss: 63.1593 - mse: 63.1593 - val_loss: 100.6123 - val_mse: 100.6123\n",
      "Epoch 182/10000\n",
      "30/30 - 2s - loss: 64.4448 - mse: 64.4448 - val_loss: 96.0709 - val_mse: 96.0709\n",
      "Epoch 183/10000\n",
      "30/30 - 2s - loss: 65.9886 - mse: 65.9886 - val_loss: 99.2993 - val_mse: 99.2993\n",
      "Epoch 184/10000\n",
      "30/30 - 2s - loss: 65.1771 - mse: 65.1771 - val_loss: 93.1490 - val_mse: 93.1490\n",
      "Epoch 185/10000\n",
      "30/30 - 2s - loss: 65.5482 - mse: 65.5482 - val_loss: 93.8051 - val_mse: 93.8051\n",
      "Epoch 186/10000\n",
      "30/30 - 2s - loss: 66.5673 - mse: 66.5673 - val_loss: 90.4154 - val_mse: 90.4154\n",
      "Epoch 187/10000\n",
      "30/30 - 2s - loss: 61.9598 - mse: 61.9598 - val_loss: 106.7454 - val_mse: 106.7454\n",
      "Epoch 188/10000\n",
      "30/30 - 2s - loss: 64.6241 - mse: 64.6241 - val_loss: 98.8103 - val_mse: 98.8103\n",
      "Epoch 189/10000\n",
      "30/30 - 2s - loss: 63.5538 - mse: 63.5538 - val_loss: 95.3290 - val_mse: 95.3290\n",
      "Epoch 190/10000\n",
      "30/30 - 2s - loss: 64.9625 - mse: 64.9625 - val_loss: 91.4155 - val_mse: 91.4155\n",
      "Epoch 191/10000\n",
      "30/30 - 2s - loss: 65.7011 - mse: 65.7011 - val_loss: 90.8125 - val_mse: 90.8125\n",
      "Epoch 192/10000\n",
      "30/30 - 2s - loss: 66.1321 - mse: 66.1321 - val_loss: 92.2575 - val_mse: 92.2575\n",
      "Epoch 193/10000\n",
      "30/30 - 2s - loss: 65.7784 - mse: 65.7784 - val_loss: 92.1260 - val_mse: 92.1260\n",
      "Epoch 194/10000\n",
      "30/30 - 2s - loss: 64.7777 - mse: 64.7777 - val_loss: 101.6662 - val_mse: 101.6662\n",
      "Epoch 195/10000\n",
      "30/30 - 2s - loss: 63.7629 - mse: 63.7629 - val_loss: 99.9631 - val_mse: 99.9631\n",
      "Epoch 196/10000\n",
      "30/30 - 2s - loss: 64.9167 - mse: 64.9167 - val_loss: 106.3506 - val_mse: 106.3506\n",
      "Epoch 197/10000\n",
      "30/30 - 2s - loss: 62.8072 - mse: 62.8072 - val_loss: 94.7284 - val_mse: 94.7284\n",
      "Epoch 198/10000\n",
      "30/30 - 2s - loss: 64.8304 - mse: 64.8304 - val_loss: 105.0730 - val_mse: 105.0730\n",
      "Epoch 199/10000\n",
      "30/30 - 2s - loss: 65.0108 - mse: 65.0108 - val_loss: 94.8498 - val_mse: 94.8498\n",
      "Epoch 200/10000\n",
      "30/30 - 2s - loss: 91.6218 - mse: 91.6218 - val_loss: 107.3673 - val_mse: 107.3673\n",
      "Epoch 201/10000\n",
      "30/30 - 2s - loss: 65.3189 - mse: 65.3189 - val_loss: 104.8004 - val_mse: 104.8004\n",
      "Epoch 202/10000\n",
      "30/30 - 2s - loss: 62.9076 - mse: 62.9076 - val_loss: 96.0508 - val_mse: 96.0508\n",
      "Epoch 203/10000\n",
      "30/30 - 2s - loss: 63.2093 - mse: 63.2093 - val_loss: 91.4237 - val_mse: 91.4237\n",
      "Epoch 204/10000\n",
      "30/30 - 2s - loss: 62.5210 - mse: 62.5210 - val_loss: 99.3662 - val_mse: 99.3662\n",
      "Epoch 205/10000\n",
      "30/30 - 3s - loss: 63.5250 - mse: 63.5250 - val_loss: 97.4119 - val_mse: 97.4119\n",
      "Epoch 206/10000\n",
      "30/30 - 2s - loss: 180.6279 - mse: 180.6279 - val_loss: 107.1832 - val_mse: 107.1832\n",
      "Epoch 207/10000\n",
      "30/30 - 2s - loss: 64.4099 - mse: 64.4099 - val_loss: 112.8186 - val_mse: 112.8186\n",
      "Epoch 208/10000\n",
      "30/30 - 2s - loss: 63.4002 - mse: 63.4002 - val_loss: 86.6859 - val_mse: 86.6859\n",
      "Epoch 209/10000\n",
      "30/30 - 2s - loss: 68.6751 - mse: 68.6751 - val_loss: 95.0341 - val_mse: 95.0341\n",
      "Epoch 210/10000\n",
      "30/30 - 2s - loss: 61.9840 - mse: 61.9840 - val_loss: 90.6701 - val_mse: 90.6701\n",
      "Epoch 211/10000\n",
      "30/30 - 2s - loss: 75.4374 - mse: 75.4374 - val_loss: 93.8387 - val_mse: 93.8387\n",
      "Epoch 212/10000\n",
      "30/30 - 2s - loss: 64.7146 - mse: 64.7146 - val_loss: 79.9716 - val_mse: 79.9716\n",
      "Epoch 213/10000\n",
      "30/30 - 2s - loss: 62.9585 - mse: 62.9585 - val_loss: 84.5833 - val_mse: 84.5833\n",
      "Epoch 214/10000\n",
      "30/30 - 2s - loss: 62.6481 - mse: 62.6481 - val_loss: 84.1979 - val_mse: 84.1979\n",
      "Epoch 215/10000\n",
      "30/30 - 2s - loss: 61.9449 - mse: 61.9449 - val_loss: 104.3428 - val_mse: 104.3428\n",
      "Epoch 216/10000\n",
      "30/30 - 2s - loss: 63.8391 - mse: 63.8391 - val_loss: 94.6262 - val_mse: 94.6262\n",
      "Epoch 217/10000\n",
      "30/30 - 2s - loss: 61.8502 - mse: 61.8502 - val_loss: 94.0555 - val_mse: 94.0555\n",
      "Epoch 218/10000\n",
      "30/30 - 2s - loss: 1757.2289 - mse: 1757.2289 - val_loss: 90.2107 - val_mse: 90.2107\n",
      "Epoch 219/10000\n",
      "30/30 - 2s - loss: 62.9629 - mse: 62.9629 - val_loss: 87.3488 - val_mse: 87.3488\n",
      "Epoch 220/10000\n",
      "30/30 - 2s - loss: 61.7243 - mse: 61.7243 - val_loss: 93.5338 - val_mse: 93.5338\n",
      "Epoch 221/10000\n",
      "30/30 - 2s - loss: 204.3682 - mse: 204.3682 - val_loss: 93.0923 - val_mse: 93.0923\n",
      "Epoch 222/10000\n",
      "30/30 - 2s - loss: 63.0026 - mse: 63.0026 - val_loss: 99.4058 - val_mse: 99.4058\n",
      "Epoch 223/10000\n",
      "30/30 - 2s - loss: 60.9485 - mse: 60.9485 - val_loss: 93.1871 - val_mse: 93.1871\n",
      "Epoch 224/10000\n",
      "30/30 - 2s - loss: 62.2315 - mse: 62.2315 - val_loss: 99.5924 - val_mse: 99.5924\n",
      "Epoch 225/10000\n",
      "30/30 - 2s - loss: 63.2573 - mse: 63.2573 - val_loss: 90.1563 - val_mse: 90.1563\n",
      "Epoch 226/10000\n",
      "30/30 - 2s - loss: 60.5042 - mse: 60.5042 - val_loss: 88.0635 - val_mse: 88.0635\n",
      "Epoch 227/10000\n",
      "30/30 - 2s - loss: 61.7068 - mse: 61.7068 - val_loss: 97.6447 - val_mse: 97.6447\n",
      "Epoch 228/10000\n",
      "30/30 - 2s - loss: 76.5661 - mse: 76.5661 - val_loss: 95.3351 - val_mse: 95.3351\n",
      "Epoch 229/10000\n",
      "30/30 - 2s - loss: 62.6220 - mse: 62.6220 - val_loss: 95.4332 - val_mse: 95.4332\n",
      "Epoch 230/10000\n",
      "30/30 - 2s - loss: 62.7889 - mse: 62.7889 - val_loss: 91.0489 - val_mse: 91.0489\n",
      "Epoch 231/10000\n",
      "30/30 - 2s - loss: 60.3125 - mse: 60.3125 - val_loss: 91.1540 - val_mse: 91.1540\n",
      "Epoch 232/10000\n",
      "30/30 - 2s - loss: 62.1316 - mse: 62.1316 - val_loss: 101.3714 - val_mse: 101.3714\n",
      "Epoch 233/10000\n",
      "30/30 - 2s - loss: 60.6273 - mse: 60.6273 - val_loss: 93.7495 - val_mse: 93.7495\n",
      "Epoch 234/10000\n",
      "30/30 - 2s - loss: 60.8611 - mse: 60.8611 - val_loss: 86.2379 - val_mse: 86.2379\n",
      "Epoch 235/10000\n",
      "30/30 - 2s - loss: 61.6664 - mse: 61.6664 - val_loss: 83.6354 - val_mse: 83.6354\n",
      "Epoch 236/10000\n",
      "30/30 - 2s - loss: 30245.4668 - mse: 30245.4668 - val_loss: 102.9302 - val_mse: 102.9302\n",
      "Epoch 237/10000\n",
      "30/30 - 2s - loss: 60.7240 - mse: 60.7240 - val_loss: 87.4613 - val_mse: 87.4613\n",
      "Epoch 238/10000\n",
      "30/30 - 2s - loss: 61.5444 - mse: 61.5444 - val_loss: 85.8600 - val_mse: 85.8600\n",
      "Epoch 239/10000\n",
      "30/30 - 2s - loss: 59.4206 - mse: 59.4206 - val_loss: 108.8851 - val_mse: 108.8851\n",
      "Epoch 240/10000\n",
      "30/30 - 2s - loss: 61.1814 - mse: 61.1814 - val_loss: 90.7724 - val_mse: 90.7724\n",
      "Epoch 241/10000\n",
      "30/30 - 2s - loss: 62.2762 - mse: 62.2762 - val_loss: 90.2971 - val_mse: 90.2971\n",
      "Epoch 242/10000\n",
      "30/30 - 2s - loss: 59.6264 - mse: 59.6264 - val_loss: 90.3138 - val_mse: 90.3138\n",
      "Epoch 243/10000\n",
      "30/30 - 2s - loss: 60.1101 - mse: 60.1101 - val_loss: 90.8732 - val_mse: 90.8732\n",
      "Epoch 244/10000\n",
      "30/30 - 2s - loss: 59.9547 - mse: 59.9547 - val_loss: 89.3111 - val_mse: 89.3111\n",
      "Epoch 245/10000\n",
      "30/30 - 2s - loss: 58.1344 - mse: 58.1344 - val_loss: 97.5962 - val_mse: 97.5962\n",
      "Epoch 246/10000\n",
      "30/30 - 2s - loss: 59.1925 - mse: 59.1925 - val_loss: 90.9550 - val_mse: 90.9550\n",
      "Epoch 247/10000\n",
      "30/30 - 2s - loss: 60.2583 - mse: 60.2583 - val_loss: 94.6565 - val_mse: 94.6565\n",
      "Epoch 248/10000\n",
      "30/30 - 2s - loss: 59.5600 - mse: 59.5600 - val_loss: 94.3009 - val_mse: 94.3009\n",
      "Epoch 249/10000\n",
      "30/30 - 2s - loss: 60.8343 - mse: 60.8343 - val_loss: 91.8872 - val_mse: 91.8872\n",
      "Epoch 250/10000\n",
      "30/30 - 2s - loss: 59.4015 - mse: 59.4015 - val_loss: 89.9973 - val_mse: 89.9973\n",
      "Epoch 251/10000\n",
      "30/30 - 3s - loss: 60.0978 - mse: 60.0978 - val_loss: 100.0771 - val_mse: 100.0771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 252/10000\n",
      "30/30 - 2s - loss: 58.8771 - mse: 58.8771 - val_loss: 86.7353 - val_mse: 86.7353\n",
      "Epoch 253/10000\n",
      "30/30 - 2s - loss: 64.9242 - mse: 64.9242 - val_loss: 90.1347 - val_mse: 90.1347\n",
      "Epoch 254/10000\n",
      "30/30 - 2s - loss: 60.5268 - mse: 60.5268 - val_loss: 96.3861 - val_mse: 96.3861\n",
      "Epoch 255/10000\n",
      "30/30 - 2s - loss: 59.8604 - mse: 59.8604 - val_loss: 93.1788 - val_mse: 93.1788\n",
      "Epoch 256/10000\n",
      "30/30 - 2s - loss: 60.0307 - mse: 60.0307 - val_loss: 89.8337 - val_mse: 89.8337\n",
      "Epoch 257/10000\n",
      "30/30 - 2s - loss: 59.8380 - mse: 59.8380 - val_loss: 89.5480 - val_mse: 89.5480\n",
      "Epoch 258/10000\n",
      "30/30 - 2s - loss: 59.9638 - mse: 59.9638 - val_loss: 87.8704 - val_mse: 87.8704\n",
      "Epoch 259/10000\n",
      "30/30 - 2s - loss: 57.7833 - mse: 57.7833 - val_loss: 86.0831 - val_mse: 86.0831\n",
      "Epoch 260/10000\n",
      "30/30 - 2s - loss: 58.5890 - mse: 58.5890 - val_loss: 83.7250 - val_mse: 83.7250\n",
      "Epoch 261/10000\n",
      "30/30 - 2s - loss: 59.5849 - mse: 59.5849 - val_loss: 89.4667 - val_mse: 89.4667\n",
      "Epoch 262/10000\n",
      "30/30 - 2s - loss: 62.2351 - mse: 62.2351 - val_loss: 85.3394 - val_mse: 85.3394\n",
      "Epoch 263/10000\n",
      "30/30 - 2s - loss: 57.5813 - mse: 57.5813 - val_loss: 87.0100 - val_mse: 87.0100\n",
      "Epoch 264/10000\n",
      "30/30 - 2s - loss: 77.0355 - mse: 77.0355 - val_loss: 80.8855 - val_mse: 80.8855\n",
      "Epoch 265/10000\n",
      "30/30 - 2s - loss: 58.0139 - mse: 58.0139 - val_loss: 106.6525 - val_mse: 106.6525\n",
      "Epoch 266/10000\n",
      "30/30 - 2s - loss: 60.1520 - mse: 60.1520 - val_loss: 89.5266 - val_mse: 89.5266\n",
      "Epoch 267/10000\n",
      "30/30 - 2s - loss: 58.7929 - mse: 58.7929 - val_loss: 87.2391 - val_mse: 87.2391\n",
      "Epoch 268/10000\n",
      "30/30 - 2s - loss: 60.4275 - mse: 60.4275 - val_loss: 106.0314 - val_mse: 106.0314\n",
      "Epoch 269/10000\n",
      "30/30 - 2s - loss: 58.7811 - mse: 58.7811 - val_loss: 98.7720 - val_mse: 98.7720\n",
      "Epoch 270/10000\n",
      "30/30 - 2s - loss: 58.4568 - mse: 58.4568 - val_loss: 99.3116 - val_mse: 99.3116\n",
      "Epoch 271/10000\n",
      "30/30 - 2s - loss: 59.2568 - mse: 59.2568 - val_loss: 101.4724 - val_mse: 101.4724\n",
      "Epoch 272/10000\n",
      "30/30 - 2s - loss: 103.2894 - mse: 103.2894 - val_loss: 98.4055 - val_mse: 98.4055\n",
      "Epoch 273/10000\n",
      "30/30 - 2s - loss: 59.1429 - mse: 59.1429 - val_loss: 84.4130 - val_mse: 84.4130\n",
      "Epoch 274/10000\n",
      "30/30 - 2s - loss: 1035.7585 - mse: 1035.7585 - val_loss: 95.7237 - val_mse: 95.7237\n",
      "Epoch 275/10000\n",
      "30/30 - 2s - loss: 56.4359 - mse: 56.4359 - val_loss: 98.6234 - val_mse: 98.6234\n",
      "Epoch 276/10000\n",
      "30/30 - 2s - loss: 58.3302 - mse: 58.3302 - val_loss: 88.6732 - val_mse: 88.6732\n",
      "Epoch 277/10000\n",
      "30/30 - 2s - loss: 61.2145 - mse: 61.2145 - val_loss: 94.9117 - val_mse: 94.9117\n",
      "Epoch 278/10000\n",
      "30/30 - 2s - loss: 56.8628 - mse: 56.8628 - val_loss: 92.6892 - val_mse: 92.6892\n",
      "Epoch 279/10000\n",
      "30/30 - 2s - loss: 57.6411 - mse: 57.6411 - val_loss: 94.4346 - val_mse: 94.4346\n",
      "Epoch 280/10000\n",
      "30/30 - 2s - loss: 58.7485 - mse: 58.7485 - val_loss: 88.5715 - val_mse: 88.5715\n",
      "Epoch 281/10000\n",
      "30/30 - 2s - loss: 57.6830 - mse: 57.6830 - val_loss: 87.0500 - val_mse: 87.0500\n",
      "Epoch 282/10000\n",
      "30/30 - 2s - loss: 60.1535 - mse: 60.1535 - val_loss: 82.5332 - val_mse: 82.5332\n",
      "Epoch 283/10000\n",
      "30/30 - 2s - loss: 102.3534 - mse: 102.3534 - val_loss: 83.7063 - val_mse: 83.7063\n",
      "Epoch 284/10000\n",
      "30/30 - 2s - loss: 55.6572 - mse: 55.6572 - val_loss: 85.3011 - val_mse: 85.3011\n",
      "Epoch 285/10000\n",
      "30/30 - 2s - loss: 57.3808 - mse: 57.3808 - val_loss: 91.2767 - val_mse: 91.2767\n",
      "Epoch 286/10000\n",
      "30/30 - 2s - loss: 57.2895 - mse: 57.2895 - val_loss: 95.9825 - val_mse: 95.9825\n",
      "Epoch 287/10000\n",
      "30/30 - 2s - loss: 58.1882 - mse: 58.1882 - val_loss: 85.0305 - val_mse: 85.0305\n",
      "Epoch 288/10000\n",
      "30/30 - 2s - loss: 55.1234 - mse: 55.1234 - val_loss: 82.4978 - val_mse: 82.4978\n",
      "Epoch 289/10000\n",
      "30/30 - 2s - loss: 56.3863 - mse: 56.3863 - val_loss: 87.0642 - val_mse: 87.0642\n",
      "Epoch 290/10000\n",
      "30/30 - 2s - loss: 57.1131 - mse: 57.1131 - val_loss: 83.4973 - val_mse: 83.4973\n",
      "Epoch 291/10000\n",
      "30/30 - 2s - loss: 92.6501 - mse: 92.6501 - val_loss: 86.1758 - val_mse: 86.1758\n",
      "Epoch 292/10000\n",
      "30/30 - 2s - loss: 56.5754 - mse: 56.5754 - val_loss: 92.7770 - val_mse: 92.7770\n",
      "Epoch 293/10000\n",
      "30/30 - 2s - loss: 55.4210 - mse: 55.4210 - val_loss: 94.0407 - val_mse: 94.0407\n",
      "Epoch 294/10000\n",
      "30/30 - 2s - loss: 55.9497 - mse: 55.9497 - val_loss: 91.6350 - val_mse: 91.6350\n",
      "Epoch 295/10000\n",
      "30/30 - 2s - loss: 56.1325 - mse: 56.1325 - val_loss: 86.4511 - val_mse: 86.4511\n",
      "Epoch 296/10000\n",
      "30/30 - 2s - loss: 56.8910 - mse: 56.8910 - val_loss: 86.6861 - val_mse: 86.6861\n",
      "Epoch 297/10000\n",
      "30/30 - 2s - loss: 56.9185 - mse: 56.9185 - val_loss: 86.9664 - val_mse: 86.9664\n",
      "Epoch 298/10000\n",
      "30/30 - 3s - loss: 66.5026 - mse: 66.5027 - val_loss: 86.2772 - val_mse: 86.2772\n",
      "Epoch 299/10000\n",
      "30/30 - 2s - loss: 100.2332 - mse: 100.2332 - val_loss: 93.9644 - val_mse: 93.9644\n",
      "Epoch 300/10000\n",
      "30/30 - 2s - loss: 55.4173 - mse: 55.4173 - val_loss: 103.4988 - val_mse: 103.4988\n",
      "Epoch 301/10000\n",
      "30/30 - 2s - loss: 55.2458 - mse: 55.2458 - val_loss: 95.0758 - val_mse: 95.0758\n",
      "Epoch 302/10000\n",
      "30/30 - 2s - loss: 58.3091 - mse: 58.3091 - val_loss: 87.8899 - val_mse: 87.8899\n",
      "Epoch 303/10000\n",
      "30/30 - 2s - loss: 57.8469 - mse: 57.8469 - val_loss: 85.4964 - val_mse: 85.4964\n",
      "Epoch 304/10000\n",
      "30/30 - 2s - loss: 137.5187 - mse: 137.5187 - val_loss: 86.0457 - val_mse: 86.0457\n",
      "Epoch 305/10000\n",
      "30/30 - 2s - loss: 56.5555 - mse: 56.5555 - val_loss: 89.3361 - val_mse: 89.3361\n",
      "Epoch 306/10000\n",
      "30/30 - 2s - loss: 1201.7535 - mse: 1201.7535 - val_loss: 85.3849 - val_mse: 85.3849\n",
      "Epoch 307/10000\n",
      "30/30 - 2s - loss: 64.3057 - mse: 64.3057 - val_loss: 86.9760 - val_mse: 86.9760\n",
      "Epoch 308/10000\n",
      "30/30 - 2s - loss: 175.4711 - mse: 175.4711 - val_loss: 82.0134 - val_mse: 82.0134\n",
      "Epoch 309/10000\n",
      "30/30 - 2s - loss: 56.0155 - mse: 56.0155 - val_loss: 82.7714 - val_mse: 82.7714\n",
      "Epoch 310/10000\n",
      "30/30 - 2s - loss: 58.1648 - mse: 58.1648 - val_loss: 91.1493 - val_mse: 91.1493\n",
      "Epoch 311/10000\n",
      "30/30 - 2s - loss: 55.5388 - mse: 55.5388 - val_loss: 94.7584 - val_mse: 94.7584\n",
      "Epoch 312/10000\n",
      "30/30 - 2s - loss: 55.8865 - mse: 55.8865 - val_loss: 93.7041 - val_mse: 93.7041\n",
      "Epoch 313/10000\n",
      "30/30 - 2s - loss: 56.0293 - mse: 56.0293 - val_loss: 108.7063 - val_mse: 108.7063\n",
      "Epoch 314/10000\n",
      "30/30 - 2s - loss: 56.0446 - mse: 56.0446 - val_loss: 90.4347 - val_mse: 90.4347\n",
      "Epoch 315/10000\n",
      "30/30 - 2s - loss: 56.6467 - mse: 56.6467 - val_loss: 88.6466 - val_mse: 88.6466\n",
      "Epoch 316/10000\n",
      "30/30 - 2s - loss: 56.8464 - mse: 56.8464 - val_loss: 97.2714 - val_mse: 97.2714\n",
      "Epoch 317/10000\n",
      "30/30 - 2s - loss: 54.7742 - mse: 54.7742 - val_loss: 88.0561 - val_mse: 88.0561\n",
      "Epoch 318/10000\n",
      "30/30 - 2s - loss: 55.0897 - mse: 55.0897 - val_loss: 97.2397 - val_mse: 97.2397\n",
      "Epoch 319/10000\n",
      "30/30 - 2s - loss: 55.9392 - mse: 55.9392 - val_loss: 99.1866 - val_mse: 99.1866\n",
      "Epoch 320/10000\n",
      "30/30 - 2s - loss: 58.4035 - mse: 58.4035 - val_loss: 103.8036 - val_mse: 103.8036\n",
      "Epoch 321/10000\n",
      "30/30 - 2s - loss: 53.3683 - mse: 53.3683 - val_loss: 102.5497 - val_mse: 102.5497\n",
      "Epoch 322/10000\n",
      "30/30 - 2s - loss: 54.4698 - mse: 54.4698 - val_loss: 96.9388 - val_mse: 96.9388\n",
      "Epoch 323/10000\n",
      "30/30 - 2s - loss: 54.5294 - mse: 54.5294 - val_loss: 98.3377 - val_mse: 98.3377\n",
      "Epoch 324/10000\n",
      "30/30 - 2s - loss: 55.6976 - mse: 55.6976 - val_loss: 102.8657 - val_mse: 102.8657\n",
      "Epoch 325/10000\n",
      "30/30 - 2s - loss: 54.3419 - mse: 54.3419 - val_loss: 96.3956 - val_mse: 96.3956\n",
      "Epoch 326/10000\n",
      "30/30 - 2s - loss: 54.9758 - mse: 54.9758 - val_loss: 100.9381 - val_mse: 100.9381\n",
      "Epoch 327/10000\n",
      "30/30 - 2s - loss: 27506.3672 - mse: 27506.3672 - val_loss: 88.1560 - val_mse: 88.1560\n",
      "Epoch 328/10000\n",
      "30/30 - 2s - loss: 53.8251 - mse: 53.8251 - val_loss: 95.7548 - val_mse: 95.7548\n",
      "Epoch 329/10000\n",
      "30/30 - 2s - loss: 52.6593 - mse: 52.6593 - val_loss: 95.0935 - val_mse: 95.0935\n",
      "Epoch 330/10000\n",
      "30/30 - 2s - loss: 57.6210 - mse: 57.6210 - val_loss: 86.9884 - val_mse: 86.9884\n",
      "Epoch 331/10000\n",
      "30/30 - 2s - loss: 55.3532 - mse: 55.3532 - val_loss: 87.5712 - val_mse: 87.5712\n",
      "Epoch 332/10000\n",
      "30/30 - 2s - loss: 283388.0312 - mse: 283388.0312 - val_loss: 89.7716 - val_mse: 89.7716\n",
      "Epoch 333/10000\n",
      "30/30 - 2s - loss: 54.2247 - mse: 54.2247 - val_loss: 89.9055 - val_mse: 89.9055\n",
      "Epoch 334/10000\n",
      "30/30 - 2s - loss: 55.4385 - mse: 55.4385 - val_loss: 91.3063 - val_mse: 91.3063\n",
      "Epoch 335/10000\n",
      "30/30 - 2s - loss: 53.6742 - mse: 53.6742 - val_loss: 90.2472 - val_mse: 90.2472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 336/10000\n",
      "30/30 - 2s - loss: 54.1826 - mse: 54.1826 - val_loss: 87.2604 - val_mse: 87.2604\n",
      "Epoch 337/10000\n",
      "30/30 - 2s - loss: 54.1097 - mse: 54.1097 - val_loss: 91.6554 - val_mse: 91.6554\n",
      "Epoch 338/10000\n",
      "30/30 - 2s - loss: 53.8454 - mse: 53.8454 - val_loss: 95.8602 - val_mse: 95.8602\n",
      "Epoch 339/10000\n",
      "30/30 - 2s - loss: 54.5269 - mse: 54.5269 - val_loss: 82.8562 - val_mse: 82.8562\n",
      "Epoch 340/10000\n",
      "30/30 - 2s - loss: 55.1978 - mse: 55.1978 - val_loss: 85.0027 - val_mse: 85.0027\n",
      "Epoch 341/10000\n",
      "30/30 - 2s - loss: 54.7860 - mse: 54.7860 - val_loss: 77.9513 - val_mse: 77.9513\n",
      "Epoch 342/10000\n",
      "30/30 - 2s - loss: 53.4841 - mse: 53.4841 - val_loss: 76.4876 - val_mse: 76.4876\n",
      "Epoch 343/10000\n",
      "30/30 - 2s - loss: 54.3299 - mse: 54.3299 - val_loss: 89.6779 - val_mse: 89.6779\n",
      "Epoch 344/10000\n",
      "30/30 - 2s - loss: 3324726.5000 - mse: 3324726.5000 - val_loss: 88.7890 - val_mse: 88.7890\n",
      "Epoch 345/10000\n",
      "30/30 - 3s - loss: 51.7677 - mse: 51.7677 - val_loss: 91.5585 - val_mse: 91.5585\n",
      "Epoch 346/10000\n",
      "30/30 - 2s - loss: 54.2484 - mse: 54.2484 - val_loss: 83.4891 - val_mse: 83.4891\n",
      "Epoch 347/10000\n",
      "30/30 - 2s - loss: 54.7612 - mse: 54.7612 - val_loss: 77.9487 - val_mse: 77.9487\n",
      "Epoch 348/10000\n",
      "30/30 - 2s - loss: 113.8156 - mse: 113.8156 - val_loss: 83.3175 - val_mse: 83.3175\n",
      "Epoch 349/10000\n",
      "30/30 - 2s - loss: 99.1040 - mse: 99.1040 - val_loss: 96.0512 - val_mse: 96.0512\n",
      "Epoch 350/10000\n",
      "30/30 - 2s - loss: 52.7617 - mse: 52.7617 - val_loss: 100.2631 - val_mse: 100.2631\n",
      "Epoch 351/10000\n",
      "30/30 - 2s - loss: 52.5564 - mse: 52.5564 - val_loss: 78.9970 - val_mse: 78.9970\n",
      "Epoch 352/10000\n",
      "30/30 - 2s - loss: 53.3326 - mse: 53.3326 - val_loss: 78.7846 - val_mse: 78.7846\n",
      "Epoch 353/10000\n",
      "30/30 - 2s - loss: 53.0739 - mse: 53.0739 - val_loss: 79.8888 - val_mse: 79.8888\n",
      "Epoch 354/10000\n",
      "30/30 - 2s - loss: 913.4341 - mse: 913.4341 - val_loss: 84.3516 - val_mse: 84.3516\n",
      "Epoch 355/10000\n",
      "30/30 - 2s - loss: 53.8815 - mse: 53.8815 - val_loss: 90.3408 - val_mse: 90.3408\n",
      "Epoch 356/10000\n",
      "30/30 - 2s - loss: 1304.0509 - mse: 1304.0509 - val_loss: 82.1832 - val_mse: 82.1832\n",
      "Epoch 357/10000\n",
      "30/30 - 2s - loss: 59.4469 - mse: 59.4469 - val_loss: 82.8306 - val_mse: 82.8306\n",
      "Epoch 358/10000\n",
      "30/30 - 2s - loss: 55.0181 - mse: 55.0181 - val_loss: 95.5989 - val_mse: 95.5989\n",
      "Epoch 359/10000\n",
      "30/30 - 2s - loss: 52.9417 - mse: 52.9417 - val_loss: 81.9628 - val_mse: 81.9628\n",
      "Epoch 360/10000\n",
      "30/30 - 2s - loss: 53.9068 - mse: 53.9068 - val_loss: 80.4115 - val_mse: 80.4115\n",
      "Epoch 361/10000\n",
      "30/30 - 2s - loss: 54.1619 - mse: 54.1619 - val_loss: 90.2711 - val_mse: 90.2711\n",
      "Epoch 362/10000\n",
      "30/30 - 2s - loss: 31986.2578 - mse: 31986.2578 - val_loss: 102.7933 - val_mse: 102.7933\n",
      "Epoch 363/10000\n",
      "30/30 - 2s - loss: 54.0472 - mse: 54.0472 - val_loss: 83.9792 - val_mse: 83.9792\n",
      "Epoch 364/10000\n",
      "30/30 - 2s - loss: 419.8472 - mse: 419.8472 - val_loss: 86.8777 - val_mse: 86.8777\n",
      "Epoch 365/10000\n",
      "30/30 - 2s - loss: 53.3605 - mse: 53.3605 - val_loss: 95.9902 - val_mse: 95.9902\n",
      "Epoch 366/10000\n",
      "30/30 - 2s - loss: 401.1135 - mse: 401.1135 - val_loss: 90.2036 - val_mse: 90.2036\n",
      "Epoch 367/10000\n",
      "30/30 - 2s - loss: 52.4798 - mse: 52.4798 - val_loss: 93.0861 - val_mse: 93.0861\n",
      "Epoch 368/10000\n",
      "30/30 - 2s - loss: 52.0260 - mse: 52.0260 - val_loss: 93.4025 - val_mse: 93.4025\n",
      "Epoch 369/10000\n",
      "30/30 - 2s - loss: 50.6614 - mse: 50.6614 - val_loss: 86.4942 - val_mse: 86.4942\n",
      "Epoch 370/10000\n",
      "30/30 - 2s - loss: 51.2999 - mse: 51.2999 - val_loss: 86.9050 - val_mse: 86.9050\n",
      "Epoch 371/10000\n",
      "30/30 - 2s - loss: 53.9631 - mse: 53.9631 - val_loss: 91.8188 - val_mse: 91.8188\n",
      "Epoch 372/10000\n",
      "30/30 - 2s - loss: 51.7468 - mse: 51.7468 - val_loss: 86.9331 - val_mse: 86.9331\n",
      "Epoch 373/10000\n",
      "30/30 - 2s - loss: 52.7597 - mse: 52.7597 - val_loss: 90.7677 - val_mse: 90.7677\n",
      "Epoch 374/10000\n",
      "30/30 - 2s - loss: 50.9885 - mse: 50.9885 - val_loss: 90.8868 - val_mse: 90.8868\n",
      "Epoch 375/10000\n",
      "30/30 - 2s - loss: 53.5062 - mse: 53.5062 - val_loss: 83.9557 - val_mse: 83.9557\n",
      "Epoch 376/10000\n",
      "30/30 - 2s - loss: 139.4689 - mse: 139.4689 - val_loss: 88.5485 - val_mse: 88.5485\n",
      "Epoch 377/10000\n",
      "30/30 - 2s - loss: 51.1937 - mse: 51.1937 - val_loss: 106.0553 - val_mse: 106.0553\n",
      "Epoch 378/10000\n",
      "30/30 - 2s - loss: 52.0951 - mse: 52.0951 - val_loss: 103.2941 - val_mse: 103.2941\n",
      "Epoch 379/10000\n",
      "30/30 - 2s - loss: 56.2003 - mse: 56.2003 - val_loss: 98.0360 - val_mse: 98.0360\n",
      "Epoch 380/10000\n",
      "30/30 - 2s - loss: 53.1247 - mse: 53.1247 - val_loss: 82.4224 - val_mse: 82.4224\n",
      "Epoch 381/10000\n",
      "30/30 - 2s - loss: 51.8699 - mse: 51.8699 - val_loss: 89.2783 - val_mse: 89.2783\n",
      "Epoch 382/10000\n",
      "30/30 - 3s - loss: 51.2472 - mse: 51.2472 - val_loss: 83.1314 - val_mse: 83.1314\n",
      "Epoch 383/10000\n",
      "30/30 - 2s - loss: 51.7787 - mse: 51.7787 - val_loss: 96.8729 - val_mse: 96.8729\n",
      "Epoch 384/10000\n",
      "30/30 - 2s - loss: 51.0135 - mse: 51.0135 - val_loss: 89.2061 - val_mse: 89.2061\n",
      "Epoch 385/10000\n",
      "30/30 - 2s - loss: 52.0901 - mse: 52.0901 - val_loss: 81.0883 - val_mse: 81.0883\n",
      "Epoch 386/10000\n",
      "30/30 - 2s - loss: 50.3254 - mse: 50.3254 - val_loss: 83.3005 - val_mse: 83.3005\n",
      "Epoch 387/10000\n",
      "30/30 - 2s - loss: 28150.1348 - mse: 28150.1348 - val_loss: 84.2870 - val_mse: 84.2870\n",
      "Epoch 388/10000\n",
      "30/30 - 2s - loss: 52.2249 - mse: 52.2249 - val_loss: 86.7605 - val_mse: 86.7605\n",
      "Epoch 389/10000\n",
      "30/30 - 2s - loss: 71.7944 - mse: 71.7944 - val_loss: 89.2344 - val_mse: 89.2344\n",
      "Epoch 390/10000\n",
      "30/30 - 2s - loss: 201.0301 - mse: 201.0301 - val_loss: 75.8021 - val_mse: 75.8021\n",
      "Epoch 391/10000\n",
      "30/30 - 2s - loss: 51.4799 - mse: 51.4799 - val_loss: 89.7184 - val_mse: 89.7184\n",
      "Epoch 392/10000\n",
      "30/30 - 2s - loss: 51.2113 - mse: 51.2113 - val_loss: 87.8875 - val_mse: 87.8875\n",
      "Epoch 393/10000\n",
      "30/30 - 2s - loss: 56.1599 - mse: 56.1599 - val_loss: 93.3877 - val_mse: 93.3877\n",
      "Epoch 394/10000\n",
      "30/30 - 2s - loss: 50.7929 - mse: 50.7929 - val_loss: 92.7774 - val_mse: 92.7774\n",
      "Epoch 395/10000\n",
      "30/30 - 2s - loss: 50.3873 - mse: 50.3873 - val_loss: 86.5986 - val_mse: 86.5986\n",
      "Epoch 396/10000\n",
      "30/30 - 2s - loss: 51.4219 - mse: 51.4219 - val_loss: 90.3746 - val_mse: 90.3746\n",
      "Epoch 397/10000\n",
      "30/30 - 2s - loss: 50.9130 - mse: 50.9130 - val_loss: 82.5530 - val_mse: 82.5530\n",
      "Epoch 398/10000\n",
      "30/30 - 2s - loss: 51.0474 - mse: 51.0474 - val_loss: 95.8703 - val_mse: 95.8703\n",
      "Epoch 399/10000\n",
      "30/30 - 2s - loss: 51.8977 - mse: 51.8977 - val_loss: 88.7799 - val_mse: 88.7799\n",
      "Epoch 400/10000\n",
      "30/30 - 2s - loss: 49.3697 - mse: 49.3697 - val_loss: 80.4277 - val_mse: 80.4277\n",
      "Epoch 401/10000\n",
      "30/30 - 2s - loss: 48.8116 - mse: 48.8116 - val_loss: 80.2608 - val_mse: 80.2608\n",
      "Epoch 402/10000\n",
      "30/30 - 2s - loss: 50.6730 - mse: 50.6730 - val_loss: 82.6800 - val_mse: 82.6800\n",
      "Epoch 403/10000\n",
      "30/30 - 2s - loss: 50.0893 - mse: 50.0893 - val_loss: 88.7432 - val_mse: 88.7432\n",
      "Epoch 404/10000\n",
      "30/30 - 2s - loss: 50.3569 - mse: 50.3569 - val_loss: 99.5534 - val_mse: 99.5534\n",
      "Epoch 405/10000\n",
      "30/30 - 2s - loss: 149.2870 - mse: 149.2870 - val_loss: 100.3571 - val_mse: 100.3571\n",
      "Epoch 406/10000\n",
      "30/30 - 2s - loss: 50.7457 - mse: 50.7457 - val_loss: 83.7777 - val_mse: 83.7777\n",
      "Epoch 407/10000\n",
      "30/30 - 2s - loss: 50.5260 - mse: 50.5260 - val_loss: 94.7423 - val_mse: 94.7423\n",
      "Epoch 408/10000\n",
      "30/30 - 2s - loss: 51.0231 - mse: 51.0231 - val_loss: 85.0780 - val_mse: 85.0780\n",
      "Epoch 409/10000\n",
      "30/30 - 2s - loss: 54.3003 - mse: 54.3003 - val_loss: 87.2015 - val_mse: 87.2015\n",
      "Epoch 410/10000\n",
      "30/30 - 2s - loss: 48.7367 - mse: 48.7367 - val_loss: 101.4992 - val_mse: 101.4992\n",
      "Epoch 411/10000\n",
      "30/30 - 2s - loss: 107.1635 - mse: 107.1635 - val_loss: 93.6108 - val_mse: 93.6108\n",
      "Epoch 412/10000\n",
      "30/30 - 2s - loss: 93662.0625 - mse: 93662.0625 - val_loss: 91.3415 - val_mse: 91.3415\n",
      "Epoch 413/10000\n",
      "30/30 - 2s - loss: 49.2682 - mse: 49.2682 - val_loss: 85.0405 - val_mse: 85.0405\n",
      "Epoch 414/10000\n",
      "30/30 - 2s - loss: 51.3881 - mse: 51.3881 - val_loss: 89.8332 - val_mse: 89.8332\n",
      "Epoch 415/10000\n",
      "30/30 - 2s - loss: 49.5490 - mse: 49.5490 - val_loss: 91.9461 - val_mse: 91.9461\n",
      "Epoch 416/10000\n",
      "30/30 - 2s - loss: 49.7037 - mse: 49.7037 - val_loss: 93.2274 - val_mse: 93.2274\n",
      "Epoch 417/10000\n",
      "30/30 - 2s - loss: 49.9289 - mse: 49.9289 - val_loss: 81.1231 - val_mse: 81.1231\n",
      "Epoch 418/10000\n",
      "30/30 - 2s - loss: 51.0252 - mse: 51.0252 - val_loss: 81.5793 - val_mse: 81.5793\n",
      "Epoch 419/10000\n",
      "30/30 - 3s - loss: 49.3928 - mse: 49.3928 - val_loss: 94.0487 - val_mse: 94.0487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 420/10000\n",
      "30/30 - 2s - loss: 50.1598 - mse: 50.1598 - val_loss: 96.3687 - val_mse: 96.3687\n",
      "Epoch 421/10000\n",
      "30/30 - 2s - loss: 49.5231 - mse: 49.5231 - val_loss: 82.9219 - val_mse: 82.9219\n",
      "Epoch 422/10000\n",
      "30/30 - 2s - loss: 49.6954 - mse: 49.6954 - val_loss: 81.3453 - val_mse: 81.3453\n",
      "Epoch 423/10000\n",
      "30/30 - 2s - loss: 50.5696 - mse: 50.5696 - val_loss: 91.0305 - val_mse: 91.0305\n",
      "Epoch 424/10000\n",
      "30/30 - 2s - loss: 47.9345 - mse: 47.9345 - val_loss: 92.5756 - val_mse: 92.5756\n",
      "Epoch 425/10000\n",
      "30/30 - 2s - loss: 49.2713 - mse: 49.2713 - val_loss: 82.4836 - val_mse: 82.4836\n",
      "Epoch 426/10000\n",
      "30/30 - 2s - loss: 4059.8342 - mse: 4059.8342 - val_loss: 84.7965 - val_mse: 84.7965\n",
      "Epoch 427/10000\n",
      "30/30 - 2s - loss: 49.7116 - mse: 49.7116 - val_loss: 84.0049 - val_mse: 84.0049\n",
      "Epoch 428/10000\n",
      "30/30 - 2s - loss: 48.9510 - mse: 48.9510 - val_loss: 80.5281 - val_mse: 80.5281\n",
      "Epoch 429/10000\n",
      "30/30 - 2s - loss: 12261.4541 - mse: 12261.4541 - val_loss: 82.5227 - val_mse: 82.5227\n",
      "Epoch 430/10000\n",
      "30/30 - 2s - loss: 50.3883 - mse: 50.3883 - val_loss: 80.8016 - val_mse: 80.8016\n",
      "Epoch 431/10000\n",
      "30/30 - 2s - loss: 47.7017 - mse: 47.7017 - val_loss: 81.6826 - val_mse: 81.6826\n",
      "Epoch 432/10000\n",
      "30/30 - 2s - loss: 50.1127 - mse: 50.1127 - val_loss: 91.7102 - val_mse: 91.7102\n",
      "Epoch 433/10000\n",
      "30/30 - 2s - loss: 49.7927 - mse: 49.7927 - val_loss: 84.3065 - val_mse: 84.3065\n",
      "Epoch 434/10000\n",
      "30/30 - 2s - loss: 48.4473 - mse: 48.4473 - val_loss: 85.2804 - val_mse: 85.2804\n",
      "Epoch 435/10000\n",
      "30/30 - 2s - loss: 51.0638 - mse: 51.0638 - val_loss: 77.8233 - val_mse: 77.8233\n",
      "Epoch 436/10000\n",
      "30/30 - 2s - loss: 118021.9219 - mse: 118021.9219 - val_loss: 84.2037 - val_mse: 84.2037\n",
      "Epoch 437/10000\n",
      "30/30 - 2s - loss: 49.7103 - mse: 49.7103 - val_loss: 77.2725 - val_mse: 77.2725\n",
      "Epoch 438/10000\n",
      "30/30 - 2s - loss: 48.6629 - mse: 48.6629 - val_loss: 81.5875 - val_mse: 81.5875\n",
      "Epoch 439/10000\n",
      "30/30 - 2s - loss: 50.0319 - mse: 50.0319 - val_loss: 83.6038 - val_mse: 83.6038\n",
      "Epoch 440/10000\n",
      "30/30 - 2s - loss: 50.8681 - mse: 50.8681 - val_loss: 82.9461 - val_mse: 82.9461\n",
      "Epoch 441/10000\n",
      "30/30 - 2s - loss: 48.6861 - mse: 48.6861 - val_loss: 81.1782 - val_mse: 81.1782\n",
      "Epoch 442/10000\n",
      "30/30 - 2s - loss: 50.7138 - mse: 50.7138 - val_loss: 87.1992 - val_mse: 87.1992\n",
      "Epoch 443/10000\n",
      "30/30 - 2s - loss: 48.8468 - mse: 48.8468 - val_loss: 86.2208 - val_mse: 86.2208\n",
      "Epoch 444/10000\n",
      "30/30 - 2s - loss: 47.3175 - mse: 47.3175 - val_loss: 93.3810 - val_mse: 93.3810\n",
      "Epoch 445/10000\n",
      "30/30 - 2s - loss: 49.3726 - mse: 49.3726 - val_loss: 85.2470 - val_mse: 85.2470\n",
      "Epoch 446/10000\n",
      "30/30 - 2s - loss: 48.1112 - mse: 48.1112 - val_loss: 84.0327 - val_mse: 84.0327\n",
      "Epoch 447/10000\n",
      "30/30 - 2s - loss: 49.2995 - mse: 49.2995 - val_loss: 87.0716 - val_mse: 87.0716\n",
      "Epoch 448/10000\n",
      "30/30 - 2s - loss: 48.3520 - mse: 48.3520 - val_loss: 83.2734 - val_mse: 83.2734\n",
      "Epoch 449/10000\n",
      "30/30 - 2s - loss: 50.0758 - mse: 50.0758 - val_loss: 84.5689 - val_mse: 84.5689\n",
      "Epoch 450/10000\n",
      "30/30 - 2s - loss: 47.7095 - mse: 47.7095 - val_loss: 77.0031 - val_mse: 77.0031\n",
      "Epoch 451/10000\n",
      "30/30 - 2s - loss: 48.6485 - mse: 48.6485 - val_loss: 83.8730 - val_mse: 83.8730\n",
      "Epoch 452/10000\n",
      "30/30 - 2s - loss: 48.7416 - mse: 48.7416 - val_loss: 89.8220 - val_mse: 89.8220\n",
      "Epoch 453/10000\n",
      "30/30 - 2s - loss: 79.1582 - mse: 79.1582 - val_loss: 87.9650 - val_mse: 87.9650\n",
      "Epoch 454/10000\n",
      "30/30 - 2s - loss: 50.4493 - mse: 50.4493 - val_loss: 80.2065 - val_mse: 80.2065\n",
      "Epoch 455/10000\n",
      "30/30 - 2s - loss: 49.1204 - mse: 49.1204 - val_loss: 91.5786 - val_mse: 91.5786\n",
      "Epoch 456/10000\n",
      "30/30 - 2s - loss: 48.6659 - mse: 48.6659 - val_loss: 94.1202 - val_mse: 94.1202\n",
      "Epoch 457/10000\n",
      "30/30 - 3s - loss: 49.3144 - mse: 49.3144 - val_loss: 80.3761 - val_mse: 80.3761\n",
      "Epoch 458/10000\n",
      "30/30 - 2s - loss: 47.5745 - mse: 47.5745 - val_loss: 90.7883 - val_mse: 90.7883\n",
      "Epoch 459/10000\n",
      "30/30 - 2s - loss: 47.1531 - mse: 47.1531 - val_loss: 95.3212 - val_mse: 95.3212\n",
      "Epoch 460/10000\n",
      "30/30 - 2s - loss: 161.3076 - mse: 161.3076 - val_loss: 90.4237 - val_mse: 90.4237\n",
      "Epoch 461/10000\n",
      "30/30 - 2s - loss: 64.9814 - mse: 64.9814 - val_loss: 80.0330 - val_mse: 80.0330\n",
      "Epoch 462/10000\n",
      "30/30 - 2s - loss: 46.6422 - mse: 46.6422 - val_loss: 74.5926 - val_mse: 74.5926\n",
      "Epoch 463/10000\n",
      "30/30 - 2s - loss: 46.9753 - mse: 46.9753 - val_loss: 75.1174 - val_mse: 75.1174\n",
      "Epoch 464/10000\n",
      "30/30 - 2s - loss: 46.9690 - mse: 46.9690 - val_loss: 70.8857 - val_mse: 70.8857\n",
      "Epoch 465/10000\n",
      "30/30 - 2s - loss: 47.2522 - mse: 47.2522 - val_loss: 72.8651 - val_mse: 72.8651\n",
      "Epoch 466/10000\n",
      "30/30 - 2s - loss: 47.8752 - mse: 47.8752 - val_loss: 74.7469 - val_mse: 74.7469\n",
      "Epoch 467/10000\n",
      "30/30 - 2s - loss: 47.2199 - mse: 47.2199 - val_loss: 76.7490 - val_mse: 76.7490\n",
      "Epoch 468/10000\n",
      "30/30 - 2s - loss: 47.1699 - mse: 47.1699 - val_loss: 95.1048 - val_mse: 95.1048\n",
      "Epoch 469/10000\n",
      "30/30 - 2s - loss: 46.7089 - mse: 46.7089 - val_loss: 79.5513 - val_mse: 79.5513\n",
      "Epoch 470/10000\n",
      "30/30 - 2s - loss: 47.7389 - mse: 47.7389 - val_loss: 77.2758 - val_mse: 77.2758\n",
      "Epoch 471/10000\n",
      "30/30 - 2s - loss: 48.0322 - mse: 48.0322 - val_loss: 89.5605 - val_mse: 89.5605\n",
      "Epoch 472/10000\n",
      "30/30 - 2s - loss: 46.1139 - mse: 46.1139 - val_loss: 86.0188 - val_mse: 86.0188\n",
      "Epoch 473/10000\n",
      "30/30 - 2s - loss: 47.1508 - mse: 47.1508 - val_loss: 76.1392 - val_mse: 76.1392\n",
      "Epoch 474/10000\n",
      "30/30 - 2s - loss: 45.9671 - mse: 45.9671 - val_loss: 84.1471 - val_mse: 84.1471\n",
      "Epoch 475/10000\n",
      "30/30 - 2s - loss: 47.2559 - mse: 47.2559 - val_loss: 78.1563 - val_mse: 78.1563\n",
      "Epoch 476/10000\n",
      "30/30 - 2s - loss: 46.6812 - mse: 46.6812 - val_loss: 95.9049 - val_mse: 95.9049\n",
      "Epoch 477/10000\n",
      "30/30 - 2s - loss: 47.7699 - mse: 47.7699 - val_loss: 88.7369 - val_mse: 88.7369\n",
      "Epoch 478/10000\n",
      "30/30 - 2s - loss: 46.9324 - mse: 46.9324 - val_loss: 75.7139 - val_mse: 75.7139\n",
      "Epoch 479/10000\n",
      "30/30 - 2s - loss: 2126.6904 - mse: 2126.6904 - val_loss: 73.4392 - val_mse: 73.4392\n",
      "Epoch 480/10000\n",
      "30/30 - 2s - loss: 46.6022 - mse: 46.6022 - val_loss: 74.0743 - val_mse: 74.0743\n",
      "Epoch 481/10000\n",
      "30/30 - 2s - loss: 52.4864 - mse: 52.4864 - val_loss: 79.0406 - val_mse: 79.0406\n",
      "Epoch 482/10000\n",
      "30/30 - 2s - loss: 46.1358 - mse: 46.1358 - val_loss: 88.0639 - val_mse: 88.0639\n",
      "Epoch 483/10000\n",
      "30/30 - 2s - loss: 46.4364 - mse: 46.4364 - val_loss: 85.4625 - val_mse: 85.4625\n",
      "Epoch 484/10000\n",
      "30/30 - 2s - loss: 45.5500 - mse: 45.5500 - val_loss: 89.7302 - val_mse: 89.7302\n",
      "Epoch 485/10000\n",
      "30/30 - 2s - loss: 46.4184 - mse: 46.4184 - val_loss: 87.9771 - val_mse: 87.9771\n",
      "Epoch 486/10000\n",
      "30/30 - 2s - loss: 238.3154 - mse: 238.3154 - val_loss: 89.0839 - val_mse: 89.0839\n",
      "Epoch 487/10000\n",
      "30/30 - 2s - loss: 46.1520 - mse: 46.1520 - val_loss: 85.3304 - val_mse: 85.3304\n",
      "Epoch 488/10000\n",
      "30/30 - 2s - loss: 46.8556 - mse: 46.8556 - val_loss: 73.8803 - val_mse: 73.8803\n",
      "Epoch 489/10000\n",
      "30/30 - 2s - loss: 46.6620 - mse: 46.6620 - val_loss: 86.2844 - val_mse: 86.2844\n",
      "Epoch 490/10000\n",
      "30/30 - 2s - loss: 47.8750 - mse: 47.8750 - val_loss: 91.0914 - val_mse: 91.0914\n",
      "Epoch 491/10000\n",
      "30/30 - 2s - loss: 46.0810 - mse: 46.0810 - val_loss: 83.4076 - val_mse: 83.4076\n",
      "Epoch 492/10000\n",
      "30/30 - 2s - loss: 46.2673 - mse: 46.2673 - val_loss: 85.7413 - val_mse: 85.7413\n",
      "Epoch 493/10000\n",
      "30/30 - 2s - loss: 46.9969 - mse: 46.9969 - val_loss: 93.9582 - val_mse: 93.9582\n",
      "Epoch 494/10000\n",
      "30/30 - 2s - loss: 45.7061 - mse: 45.7061 - val_loss: 84.2565 - val_mse: 84.2565\n",
      "Epoch 495/10000\n",
      "30/30 - 2s - loss: 44.5994 - mse: 44.5994 - val_loss: 80.3664 - val_mse: 80.3664\n",
      "Epoch 496/10000\n",
      "30/30 - 2s - loss: 45.7778 - mse: 45.7778 - val_loss: 80.7160 - val_mse: 80.7160\n",
      "Epoch 497/10000\n",
      "30/30 - 2s - loss: 46.8587 - mse: 46.8587 - val_loss: 93.0670 - val_mse: 93.0670\n",
      "Epoch 498/10000\n",
      "30/30 - 2s - loss: 140452.1719 - mse: 140452.1719 - val_loss: 96.8060 - val_mse: 96.8060\n",
      "Epoch 499/10000\n",
      "30/30 - 2s - loss: 45.0669 - mse: 45.0669 - val_loss: 90.4178 - val_mse: 90.4178\n",
      "Epoch 500/10000\n",
      "30/30 - 2s - loss: 45.7335 - mse: 45.7335 - val_loss: 78.5814 - val_mse: 78.5814\n",
      "Epoch 501/10000\n",
      "30/30 - 2s - loss: 51.6804 - mse: 51.6804 - val_loss: 78.7100 - val_mse: 78.7100\n",
      "Epoch 502/10000\n",
      "30/30 - 2s - loss: 44.6639 - mse: 44.6639 - val_loss: 89.8164 - val_mse: 89.8164\n",
      "Epoch 503/10000\n",
      "30/30 - 2s - loss: 44.5376 - mse: 44.5376 - val_loss: 78.1413 - val_mse: 78.1413\n",
      "Epoch 504/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 - 2s - loss: 45.7272 - mse: 45.7272 - val_loss: 73.6750 - val_mse: 73.6750\n",
      "Epoch 505/10000\n",
      "30/30 - 2s - loss: 46.5599 - mse: 46.5599 - val_loss: 82.5374 - val_mse: 82.5374\n",
      "Epoch 506/10000\n",
      "30/30 - 2s - loss: 44.8723 - mse: 44.8723 - val_loss: 90.9195 - val_mse: 90.9195\n",
      "Epoch 507/10000\n",
      "30/30 - 2s - loss: 45.9945 - mse: 45.9945 - val_loss: 91.3163 - val_mse: 91.3163\n",
      "Epoch 508/10000\n",
      "30/30 - 2s - loss: 46.2379 - mse: 46.2379 - val_loss: 95.2116 - val_mse: 95.2116\n",
      "Epoch 509/10000\n",
      "30/30 - 2s - loss: 45.1568 - mse: 45.1568 - val_loss: 84.2289 - val_mse: 84.2289\n",
      "Epoch 510/10000\n",
      "30/30 - 2s - loss: 45.6628 - mse: 45.6628 - val_loss: 98.5632 - val_mse: 98.5632\n",
      "Epoch 511/10000\n",
      "30/30 - 2s - loss: 73.5003 - mse: 73.5003 - val_loss: 83.5030 - val_mse: 83.5030\n",
      "Epoch 512/10000\n",
      "30/30 - 2s - loss: 45.3868 - mse: 45.3868 - val_loss: 80.0437 - val_mse: 80.0437\n",
      "Epoch 513/10000\n",
      "30/30 - 2s - loss: 66.7086 - mse: 66.7086 - val_loss: 79.4848 - val_mse: 79.4848\n",
      "Epoch 514/10000\n",
      "30/30 - 2s - loss: 43.5146 - mse: 43.5146 - val_loss: 87.6686 - val_mse: 87.6686\n",
      "Epoch 515/10000\n",
      "30/30 - 2s - loss: 45.1650 - mse: 45.1650 - val_loss: 79.6268 - val_mse: 79.6268\n",
      "Epoch 516/10000\n",
      "30/30 - 2s - loss: 45.2299 - mse: 45.2299 - val_loss: 81.1104 - val_mse: 81.1104\n",
      "Epoch 517/10000\n",
      "30/30 - 2s - loss: 45.2770 - mse: 45.2770 - val_loss: 101.1177 - val_mse: 101.1177\n",
      "Epoch 518/10000\n",
      "30/30 - 2s - loss: 43.6721 - mse: 43.6721 - val_loss: 83.7130 - val_mse: 83.7130\n",
      "Epoch 519/10000\n",
      "30/30 - 2s - loss: 47.7705 - mse: 47.7705 - val_loss: 84.6783 - val_mse: 84.6783\n",
      "Epoch 520/10000\n",
      "30/30 - 2s - loss: 45.2447 - mse: 45.2447 - val_loss: 94.1115 - val_mse: 94.1115\n",
      "Epoch 521/10000\n",
      "30/30 - 2s - loss: 51.6334 - mse: 51.6334 - val_loss: 87.6844 - val_mse: 87.6844\n",
      "Epoch 522/10000\n",
      "30/30 - 2s - loss: 43.7644 - mse: 43.7644 - val_loss: 95.6577 - val_mse: 95.6577\n",
      "Epoch 523/10000\n",
      "30/30 - 2s - loss: 60.3339 - mse: 60.3339 - val_loss: 97.7423 - val_mse: 97.7423\n",
      "Epoch 524/10000\n",
      "30/30 - 2s - loss: 44.1493 - mse: 44.1493 - val_loss: 104.3882 - val_mse: 104.3882\n",
      "Epoch 525/10000\n",
      "30/30 - 2s - loss: 43.9800 - mse: 43.9800 - val_loss: 92.1276 - val_mse: 92.1276\n",
      "Epoch 526/10000\n",
      "30/30 - 2s - loss: 43.8908 - mse: 43.8908 - val_loss: 80.5782 - val_mse: 80.5782\n",
      "Epoch 527/10000\n",
      "30/30 - 2s - loss: 44.1509 - mse: 44.1509 - val_loss: 88.4604 - val_mse: 88.4604\n",
      "Epoch 528/10000\n",
      "30/30 - 2s - loss: 44.4101 - mse: 44.4101 - val_loss: 82.5203 - val_mse: 82.5203\n",
      "Epoch 529/10000\n",
      "30/30 - 2s - loss: 44.1277 - mse: 44.1277 - val_loss: 82.2248 - val_mse: 82.2248\n",
      "Epoch 530/10000\n",
      "30/30 - 2s - loss: 44.3421 - mse: 44.3421 - val_loss: 90.3821 - val_mse: 90.3821\n",
      "Epoch 531/10000\n",
      "30/30 - 2s - loss: 44.9932 - mse: 44.9932 - val_loss: 96.5353 - val_mse: 96.5353\n",
      "Epoch 532/10000\n",
      "30/30 - 2s - loss: 44.9693 - mse: 44.9693 - val_loss: 94.3461 - val_mse: 94.3461\n",
      "Epoch 533/10000\n",
      "30/30 - 2s - loss: 45.6394 - mse: 45.6394 - val_loss: 92.3923 - val_mse: 92.3923\n",
      "Epoch 534/10000\n",
      "30/30 - 3s - loss: 44.1808 - mse: 44.1808 - val_loss: 81.6512 - val_mse: 81.6512\n",
      "Epoch 535/10000\n",
      "30/30 - 2s - loss: 45.0728 - mse: 45.0728 - val_loss: 77.4242 - val_mse: 77.4242\n",
      "Epoch 536/10000\n",
      "30/30 - 2s - loss: 43.7516 - mse: 43.7516 - val_loss: 78.2004 - val_mse: 78.2004\n",
      "Epoch 537/10000\n",
      "30/30 - 2s - loss: 173.3090 - mse: 173.3090 - val_loss: 81.4719 - val_mse: 81.4719\n",
      "Epoch 538/10000\n",
      "30/30 - 2s - loss: 44.0000 - mse: 44.0000 - val_loss: 96.9970 - val_mse: 96.9970\n",
      "Epoch 539/10000\n",
      "30/30 - 2s - loss: 46.0436 - mse: 46.0436 - val_loss: 89.7722 - val_mse: 89.7722\n",
      "Epoch 540/10000\n",
      "30/30 - 2s - loss: 100.2199 - mse: 100.2199 - val_loss: 76.1791 - val_mse: 76.1791\n",
      "Epoch 541/10000\n",
      "30/30 - 2s - loss: 44.8263 - mse: 44.8263 - val_loss: 71.4924 - val_mse: 71.4924\n",
      "Epoch 542/10000\n",
      "30/30 - 2s - loss: 43.8780 - mse: 43.8780 - val_loss: 74.8670 - val_mse: 74.8670\n",
      "Epoch 543/10000\n",
      "30/30 - 2s - loss: 43.7880 - mse: 43.7880 - val_loss: 90.0869 - val_mse: 90.0869\n",
      "Epoch 544/10000\n",
      "30/30 - 2s - loss: 43.5517 - mse: 43.5517 - val_loss: 75.9085 - val_mse: 75.9085\n",
      "Epoch 545/10000\n",
      "30/30 - 2s - loss: 43.8215 - mse: 43.8215 - val_loss: 79.1797 - val_mse: 79.1797\n",
      "Epoch 546/10000\n",
      "30/30 - 2s - loss: 43.2655 - mse: 43.2655 - val_loss: 81.0541 - val_mse: 81.0541\n",
      "Epoch 547/10000\n",
      "30/30 - 2s - loss: 43.8889 - mse: 43.8889 - val_loss: 79.5126 - val_mse: 79.5126\n",
      "Epoch 548/10000\n",
      "30/30 - 2s - loss: 43.9697 - mse: 43.9697 - val_loss: 77.8989 - val_mse: 77.8989\n",
      "Epoch 549/10000\n",
      "30/30 - 2s - loss: 43.0782 - mse: 43.0782 - val_loss: 95.9714 - val_mse: 95.9714\n",
      "Epoch 550/10000\n",
      "30/30 - 2s - loss: 43.4996 - mse: 43.4996 - val_loss: 83.1590 - val_mse: 83.1590\n",
      "Epoch 551/10000\n",
      "30/30 - 2s - loss: 43.9940 - mse: 43.9940 - val_loss: 81.5994 - val_mse: 81.5994\n",
      "Epoch 552/10000\n",
      "30/30 - 2s - loss: 42.9091 - mse: 42.9091 - val_loss: 78.1942 - val_mse: 78.1942\n",
      "Epoch 553/10000\n",
      "30/30 - 2s - loss: 44.2147 - mse: 44.2147 - val_loss: 77.3979 - val_mse: 77.3979\n",
      "Epoch 554/10000\n",
      "30/30 - 2s - loss: 43.0010 - mse: 43.0010 - val_loss: 77.2290 - val_mse: 77.2290\n",
      "Epoch 555/10000\n",
      "30/30 - 2s - loss: 44.5247 - mse: 44.5247 - val_loss: 82.2780 - val_mse: 82.2780\n",
      "Epoch 556/10000\n",
      "30/30 - 2s - loss: 43.3850 - mse: 43.3850 - val_loss: 75.8388 - val_mse: 75.8388\n",
      "Epoch 557/10000\n",
      "30/30 - 2s - loss: 49.0729 - mse: 49.0729 - val_loss: 75.0158 - val_mse: 75.0158\n",
      "Epoch 558/10000\n",
      "30/30 - 2s - loss: 43.1732 - mse: 43.1732 - val_loss: 77.3362 - val_mse: 77.3362\n",
      "Epoch 559/10000\n",
      "30/30 - 2s - loss: 43.7256 - mse: 43.7256 - val_loss: 74.0841 - val_mse: 74.0841\n",
      "Epoch 560/10000\n",
      "30/30 - 2s - loss: 43.7382 - mse: 43.7382 - val_loss: 73.4343 - val_mse: 73.4343\n",
      "Epoch 561/10000\n",
      "30/30 - 2s - loss: 43.3408 - mse: 43.3408 - val_loss: 86.4431 - val_mse: 86.4431\n",
      "Epoch 562/10000\n",
      "30/30 - 2s - loss: 43.3334 - mse: 43.3334 - val_loss: 88.7506 - val_mse: 88.7506\n",
      "Epoch 563/10000\n",
      "30/30 - 2s - loss: 44.3615 - mse: 44.3615 - val_loss: 76.4990 - val_mse: 76.4990\n",
      "Epoch 564/10000\n",
      "30/30 - 2s - loss: 941.5989 - mse: 941.5989 - val_loss: 75.4473 - val_mse: 75.4473\n",
      "Epoch 565/10000\n",
      "30/30 - 2s - loss: 42.8807 - mse: 42.8807 - val_loss: 78.0223 - val_mse: 78.0223\n",
      "Epoch 566/10000\n",
      "30/30 - 2s - loss: 43.6601 - mse: 43.6601 - val_loss: 93.5975 - val_mse: 93.5975\n",
      "Epoch 567/10000\n",
      "30/30 - 2s - loss: 124.0026 - mse: 124.0026 - val_loss: 77.8102 - val_mse: 77.8102\n",
      "Epoch 568/10000\n",
      "30/30 - 2s - loss: 41.7991 - mse: 41.7991 - val_loss: 81.4473 - val_mse: 81.4473\n",
      "Epoch 569/10000\n",
      "30/30 - 2s - loss: 48.7643 - mse: 48.7643 - val_loss: 85.1241 - val_mse: 85.1241\n",
      "Epoch 570/10000\n",
      "30/30 - 2s - loss: 42.1985 - mse: 42.1985 - val_loss: 85.0554 - val_mse: 85.0554\n",
      "Epoch 571/10000\n",
      "30/30 - 2s - loss: 43.2596 - mse: 43.2596 - val_loss: 87.7746 - val_mse: 87.7746\n",
      "Epoch 572/10000\n",
      "30/30 - 2s - loss: 404.3794 - mse: 404.3794 - val_loss: 83.3756 - val_mse: 83.3756\n",
      "Epoch 573/10000\n",
      "30/30 - 2s - loss: 43.7683 - mse: 43.7683 - val_loss: 84.0580 - val_mse: 84.0580\n",
      "Epoch 574/10000\n",
      "30/30 - 2s - loss: 43.0460 - mse: 43.0460 - val_loss: 85.4767 - val_mse: 85.4767\n",
      "Epoch 575/10000\n",
      "30/30 - 2s - loss: 44.0726 - mse: 44.0726 - val_loss: 83.3916 - val_mse: 83.3916\n",
      "Epoch 576/10000\n",
      "30/30 - 2s - loss: 46.0580 - mse: 46.0580 - val_loss: 82.8614 - val_mse: 82.8614\n",
      "Epoch 577/10000\n",
      "30/30 - 2s - loss: 42.5310 - mse: 42.5310 - val_loss: 79.8286 - val_mse: 79.8286\n",
      "Epoch 578/10000\n",
      "30/30 - 2s - loss: 57.6703 - mse: 57.6703 - val_loss: 78.2497 - val_mse: 78.2497\n",
      "Epoch 579/10000\n",
      "30/30 - 2s - loss: 86832.5859 - mse: 86832.5859 - val_loss: 79.0768 - val_mse: 79.0768\n",
      "Epoch 580/10000\n",
      "30/30 - 2s - loss: 42.9841 - mse: 42.9841 - val_loss: 78.4839 - val_mse: 78.4839\n",
      "Epoch 581/10000\n",
      "30/30 - 3s - loss: 43.0411 - mse: 43.0411 - val_loss: 76.8770 - val_mse: 76.8770\n",
      "Epoch 582/10000\n",
      "30/30 - 2s - loss: 42.0771 - mse: 42.0771 - val_loss: 75.4953 - val_mse: 75.4953\n",
      "Epoch 583/10000\n",
      "30/30 - 2s - loss: 42.3232 - mse: 42.3232 - val_loss: 77.5504 - val_mse: 77.5504\n",
      "Epoch 584/10000\n",
      "30/30 - 2s - loss: 3564.1846 - mse: 3564.1846 - val_loss: 88.2574 - val_mse: 88.2574\n",
      "Epoch 585/10000\n",
      "30/30 - 2s - loss: 44.3456 - mse: 44.3456 - val_loss: 80.2740 - val_mse: 80.2740\n",
      "Epoch 586/10000\n",
      "30/30 - 2s - loss: 43.0951 - mse: 43.0951 - val_loss: 79.7227 - val_mse: 79.7227\n",
      "Epoch 587/10000\n",
      "30/30 - 2s - loss: 42.3971 - mse: 42.3971 - val_loss: 77.9754 - val_mse: 77.9754\n",
      "Epoch 588/10000\n",
      "30/30 - 2s - loss: 42.7412 - mse: 42.7412 - val_loss: 73.3898 - val_mse: 73.3898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 589/10000\n",
      "30/30 - 2s - loss: 41.1820 - mse: 41.1820 - val_loss: 75.4318 - val_mse: 75.4318\n",
      "Epoch 590/10000\n",
      "30/30 - 2s - loss: 43.4302 - mse: 43.4302 - val_loss: 79.9822 - val_mse: 79.9822\n",
      "Epoch 591/10000\n",
      "30/30 - 2s - loss: 42.8057 - mse: 42.8057 - val_loss: 91.6570 - val_mse: 91.6570\n",
      "Epoch 592/10000\n",
      "30/30 - 2s - loss: 41.1364 - mse: 41.1364 - val_loss: 78.7375 - val_mse: 78.7375\n",
      "Epoch 593/10000\n",
      "30/30 - 2s - loss: 40.9626 - mse: 40.9626 - val_loss: 88.1025 - val_mse: 88.1025\n",
      "Epoch 594/10000\n",
      "30/30 - 2s - loss: 41.3467 - mse: 41.3467 - val_loss: 77.9292 - val_mse: 77.9292\n",
      "Epoch 595/10000\n",
      "30/30 - 2s - loss: 41.8762 - mse: 41.8762 - val_loss: 89.7249 - val_mse: 89.7249\n",
      "Epoch 596/10000\n",
      "30/30 - 2s - loss: 52.6738 - mse: 52.6738 - val_loss: 76.6811 - val_mse: 76.6811\n",
      "Epoch 597/10000\n",
      "30/30 - 2s - loss: 42.4763 - mse: 42.4763 - val_loss: 77.3375 - val_mse: 77.3375\n",
      "Epoch 598/10000\n",
      "30/30 - 2s - loss: 41.3742 - mse: 41.3742 - val_loss: 84.7092 - val_mse: 84.7092\n",
      "Epoch 599/10000\n",
      "30/30 - 2s - loss: 52.6431 - mse: 52.6431 - val_loss: 97.0353 - val_mse: 97.0353\n",
      "Epoch 600/10000\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10000\n",
    "history = model.fit(\n",
    "    train_ds_b, \n",
    "    validation_data=val_ds_b,  \n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[lr_callback],\n",
    "    verbose = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = history.history\n",
    "plt.plot(history.epoch, np.sqrt(metrics['mse']), np.sqrt(metrics['val_mse']))\n",
    "plt.legend(['rmse', 'val_rmse'])\n",
    "axes = plt.axes()\n",
    "axes.set_ylim([0, 30])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(model.evaluate(val_ds.batch(batch_size))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.sqrt(model.evaluate(test_ds.batch(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_eval(x, size, stride):\n",
    "    length = int(len(x))\n",
    "    if length // size == 0:\n",
    "        zero_padding =  tf.zeros([size] - tf.shape(x), dtype=tf.float32)\n",
    "        x = tf.cast(x, tf.float32)\n",
    "        x = tf.concat([x, zero_padding], 0)\n",
    "        length = int(len(x))\n",
    "    return tf.map_fn(lambda i: x[i*stride:i*stride+size], tf.range((length-size)//stride+1), dtype=tf.float32)\n",
    "\n",
    "def get_data_eval(file_path):\n",
    "\n",
    "    names = meta.ID\n",
    "    name = tf.strings.split(tf.strings.split(file_path, os.path.sep)[-1], '.')[0] + ' '\n",
    "    label = tf.gather(meta.MMSE, tf.where(tf.equal(names, name))[0][0])\n",
    "    \n",
    "    audio_binary = tf.io.read_file(file_path)\n",
    "    audio, _ = tf.audio.decode_wav(audio_binary)\n",
    "    waveform = tf.squeeze(audio, axis=-1)\n",
    "        \n",
    "    rolling_waveform_tensors = window_eval(waveform, size=_*size_sec, stride=_*stride_sec)\n",
    "    rolling_spectrograms = tf.signal.stft(rolling_waveform_tensors, frame_length=512, frame_step=_)\n",
    "    rolling_spectrograms = tf.abs(rolling_spectrograms)\n",
    "    rolling_spectrograms = tf.expand_dims(rolling_spectrograms, -1)\n",
    "        \n",
    "    return rolling_spectrograms, label/30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model('saved_model/base_line/20210222')\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = meta.assign(split = '', predict = -99.99, predict_group = 'cc')\n",
    "for file in train_files:\n",
    "    ID = file.numpy().decode('utf-8').split('/')[-1].split('.')[0]\n",
    "    predict = model.predict(get_data_eval(file)[0]).mean()  \n",
    "    meta.at[np.where(meta.ID == (ID + ' '))[0][0], 'predict'] = max(1, min(predict, 30))\n",
    "    meta.at[np.where(meta.ID == (ID + ' '))[0][0], 'split'] = 'train'\n",
    "    if (predict < 24):\n",
    "        meta.at[np.where(meta.ID == (ID + ' '))[0][0], 'predict_group'] = 'cd'\n",
    "for file in test_files:\n",
    "    ID = file.numpy().decode('utf-8').split('/')[-1].split('.')[0]\n",
    "    predict = model.predict(get_data_eval(file)[0]).mean() \n",
    "    meta.at[np.where(meta.ID == (ID + ' '))[0][0], 'predict'] = max(1, min(predict, 30))\n",
    "    meta.at[np.where(meta.ID == (ID + ' '))[0][0], 'split'] = 'test'\n",
    "    if (predict < 24):\n",
    "        meta.at[np.where(meta.ID == (ID + ' '))[0][0], 'predict_group'] = 'cd'\n",
    "for file in val_files:\n",
    "    ID = file.numpy().decode('utf-8').split('/')[-1].split('.')[0]\n",
    "    predict = model.predict(get_data_eval(file)[0]).mean() \n",
    "    meta.at[np.where(meta.ID == (ID + ' '))[0][0], 'predict'] = max(1, min(predict, 30))\n",
    "    meta.at[np.where(meta.ID == (ID + ' '))[0][0], 'split'] = 'val'\n",
    "    if (predict < 24):\n",
    "        meta.at[np.where(meta.ID == (ID + ' '))[0][0], 'predict_group'] = 'cd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.predict.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, mean_squared_error, classification_report\n",
    "def cal_rmse(g):\n",
    "    rmse = np.sqrt(mean_squared_error(g['MMSE'], g['predict'] ) )\n",
    "    return pd.Series(dict(rmse = rmse ))\n",
    "\n",
    "meta.groupby('split').apply(cal_rmse).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "meta.groupby('Gender').apply(cal_rmse).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(meta['MMSE'], meta['predict'] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.MMSE.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(meta) + \\\n",
    "geom_point(aes(x = 'MMSE', y = 'predict', colour = 'split')) + \\\n",
    "facet_wrap('split', nrow = 1) + \\\n",
    "geom_abline(aes(intercept = 0, slope = 1, lty = 2)) + \\\n",
    "geom_hline(aes(yintercept = 24, lty = 2)) + \\\n",
    "geom_vline(aes(xintercept = 24, lty = 2)) + \\\n",
    "theme(figure_size = (15, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = meta.Group\n",
    "y_pred = meta.predict_group\n",
    "data = confusion_matrix(y_true, y_pred)\n",
    "df_cm = pd.DataFrame(data, columns=np.unique(y_true), index = np.unique(y_true))\n",
    "df_cm.index.name = 'Actual'\n",
    "df_cm.columns.name = 'Predicted'\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.set(font_scale=1.4)#for label size\n",
    "sn.heatmap(df_cm, cmap=\"Reds\", annot=True,annot_kws={\"size\": 16})# font size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('saved_model/michael/rl_lstm_wn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls saved_model/michael"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pitts Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_pitt = '/tf/data/dementia/English/Pitt/'\n",
    "files_pitt = tf.io.gfile.glob(data_path_pitt + 'Control/cookie/*.wav') + \\\n",
    "             tf.io.gfile.glob(data_path_pitt + 'Dementia/cookie/*.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_inference(filepath):\n",
    "\n",
    "    import tensorflow as tf\n",
    "    import numpy as np\n",
    "    import json\n",
    "    import requests\t\n",
    "    import os\n",
    "    from datetime import datetime\n",
    "    \n",
    "    input_file = filepath\n",
    "    if not filepath.lower().endswith(\".wav\"):\n",
    "#         tmp_name = \"tmp-\"+datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        input_file = input_file.split('.mp3')[0] + '.wav'\n",
    "        cmd = \"ffmpeg -i \" + filepath + \" \" + input_file\n",
    "        os.system(cmd)\n",
    "    \n",
    "    audio_binary = tf.io.read_file(input_file)\n",
    "    audio, _ = tf.audio.decode_wav(audio_binary)\n",
    "    if audio.shape[1] > 1:\n",
    "        audio = tf.reshape(audio[:, 0], (audio.shape[0],1))\n",
    "\n",
    "    waveform = tf.squeeze(audio, axis=-1)    \n",
    "    rolling_waveform_tensors = window_eval(waveform, size=_*30, stride=_*1)\n",
    "    rolling_spectrograms = tf.signal.stft(rolling_waveform_tensors, frame_length=512, frame_step=_)\n",
    "    rolling_spectrograms = tf.abs(rolling_spectrograms)\n",
    "    rolling_spectrograms = tf.expand_dims(rolling_spectrograms, -1)\n",
    "    rolling_spectrograms = rolling_spectrograms.numpy().tolist()\n",
    "    \n",
    "    predictions = model.predict(rolling_spectrograms)\n",
    "    results = [x[0] for x in predictions]\n",
    "    result = sum(results)/len(results) \n",
    "\n",
    "#     os.system('rm ' + input_file)\n",
    "    return result, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_pitt = pd.DataFrame(columns= ['file', 'ID', 'Group', 'MMSE', 'predict', 'predict_group', 'predicts'])\n",
    "for file in tqdm(files_pitt):\n",
    "#     print(file)\n",
    "    ID = file.split('/')[-1].split('.')[0]\n",
    "    Group = file.split('/')[6]\n",
    "    cha = pd.read_fwf(data_path_pitt + 'Pitt/' + Group + '/cookie/' + ID + '.cha')  \n",
    "    cha_id = [x for x in cha['@UTF8'] if str.startswith(x, '@ID:')][0]\n",
    "    \n",
    "    if (cha_id.split('|')[-3] == ''):\n",
    "        MMSE = np.NaN\n",
    "    else:\n",
    "        MMSE = int(cha_id.split('|')[-3])\n",
    "        \n",
    "    predict, predicts = model_inference(file)\n",
    "    if (predict < 24):\n",
    "        predict_group = 'Dementia'\n",
    "    else:\n",
    "        predict_group = 'Control'\n",
    "    meta_pitt = meta_pitt.append(pd.DataFrame([[file, ID, Group, MMSE, predict, predict_group, predicts]], \n",
    "                                  columns = list(meta_pitt.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_pitt['predict'] = [x if x < 30 else 30 for x in meta_pitt.predict]\n",
    "meta_pitt['predict_group'] = ['Control' if x >= 24 else 'Dementia' for x in meta_pitt.predict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_pitt['predict_min'] = [min(x) for x in meta_pitt.predicts]\n",
    "meta_pitt['predict_group_min'] = ['Control' if x >= 24 else 'Dementia' for x in meta_pitt.predict_min]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "meta_pitt_eval = meta_pitt[meta_pitt.MMSE.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_pitt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_pitt_eval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_pitt_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_pitt_eval.predict.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(meta_pitt_eval['MMSE'], meta_pitt_eval['predict'] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_pitt.to_csv(path_or_buf = '4-RollingWindow+LSTM-pitt.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = meta_pitt.Group\n",
    "y_pred = meta_pitt.predict_group\n",
    "data = confusion_matrix(y_true, y_pred)\n",
    "df_cm = pd.DataFrame(data, columns=np.unique(y_true), index = np.unique(y_true))\n",
    "df_cm.index.name = 'Actual'\n",
    "df_cm.columns.name = 'Predicted'\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.set(font_scale=1.4)#for label size\n",
    "sn.heatmap(df_cm, cmap=\"Reds\", annot=True, annot_kws={\"size\": 16})# font size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(meta_pitt) + \\\n",
    "geom_point(aes(x = 'MMSE', y = 'predict', colour = 'Group')) + \\\n",
    "geom_hline(aes(yintercept = 24, lty = 2)) + \\\n",
    "geom_vline(aes(xintercept = 20, lty = 2)) + \\\n",
    "theme(figure_size = (15, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta_pitt.to_csv(path_or_buf = 'meta_pitt_rollingwindow_lstm.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
