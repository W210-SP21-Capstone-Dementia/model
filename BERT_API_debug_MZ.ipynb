{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==3.0.2\n",
      "  Downloading transformers-3.0.2-py3-none-any.whl (769 kB)\n",
      "\u001b[K     |████████████████████████████████| 769 kB 18.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tokenizers==0.8.1.rc1\n",
      "  Downloading tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 59.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (2.23.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (1.19.2)\n",
      "Collecting sentencepiece!=0.1.92\n",
      "  Downloading sentencepiece-0.1.95-cp36-cp36m-manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 50.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sacremoses\n",
      "  Downloading sacremoses-0.0.44.tar.gz (862 kB)\n",
      "\u001b[K     |████████████████████████████████| 862 kB 47.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (4.43.0)\n",
      "Collecting dataclasses; python_version < \"3.7\"\n",
      "  Downloading dataclasses-0.8-py3-none-any.whl (19 kB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2021.4.4-cp36-cp36m-manylinux2014_x86_64.whl (722 kB)\n",
      "\u001b[K     |████████████████████████████████| 722 kB 50.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.0.2) (20.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.2) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.2) (2019.11.28)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.2) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.0.2) (3.0.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.0.2) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.0.2) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.0.2) (0.14.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.0.2) (2.4.6)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.44-py3-none-any.whl size=886084 sha256=f46a900b2c022e4865c41f8d75729450e40a2e33680e8e4f652ebb375691445b\n",
      "  Stored in directory: /root/.cache/pip/wheels/d4/6d/ad/81106f259084ee9e99156f754f8a4957e4c2cb9c1ccf866f8a\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: tokenizers, sentencepiece, regex, sacremoses, filelock, dataclasses, transformers\n",
      "Successfully installed dataclasses-0.8 filelock-3.0.12 regex-2021.4.4 sacremoses-0.0.44 sentencepiece-0.1.95 tokenizers-0.8.1rc1 transformers-3.0.2\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==3.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import transformers\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from transformers import BertTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9023b750015f4bf68440ce71b2267d1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bert_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_name,\n",
    "                                          add_special_tokens=True,\n",
    "                                          do_lower_case=True,\n",
    "                                          max_length=256,\n",
    "                                          pad_to_max_length=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_encoder(input_text):\n",
    "    # txt = input_text.numpy().decode('utf-8')\n",
    "    txt = input_text\n",
    "    encoded = tokenizer.encode_plus(txt, add_special_tokens=True, \n",
    "                                    max_length=256, \n",
    "                                    pad_to_max_length=True, \n",
    "                                    return_attention_mask=True, \n",
    "                                    return_token_type_ids=True,\n",
    "                                    truncation=True)\n",
    "    return encoded['input_ids'], encoded['token_type_ids'], \\\n",
    "           encoded['attention_mask']\n",
    "\n",
    "def build_model(transformer, max_len=512):\n",
    "    \"\"\"\n",
    "    https://www.kaggle.com/xhlulu/jigsaw-tpu-distilbert-with-huggingface-and-keras\n",
    "    \"\"\"\n",
    "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n",
    "    sequence_output = transformer(input_word_ids)[0]\n",
    "    cls_token = sequence_output[:, 0, :]\n",
    "    out = Dense(1, activation='relu', kernel_initializer='he_normal')(cls_token)\n",
    "    model = Model(inputs=input_word_ids, outputs=out)\n",
    "    for layer in model.layers[:-1]:\n",
    "      layer.trainable = False\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
    "    model.compile(optimizer = optimizer, \n",
    "                  loss=tf.keras.metrics.mean_squared_error,\n",
    "                  metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "    return model\n",
    "\n",
    "MAX_LEN = 256\n",
    "def create_model():\n",
    "  transformer_layer = (\n",
    "      transformers.TFAutoModelWithLMHead.from_pretrained(bert_name)\n",
    "  )\n",
    "  model = build_model(transformer_layer, max_len=MAX_LEN)\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a63e8aa277cf45d2a8a75a67ee0b741d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a80ea57af5b42438055aa994fbf3e5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=536063208.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing TFBertForMaskedLM: ['nsp___cls']\n",
      "- This IS expected if you are initializing TFBertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertForMaskedLM were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_ids (InputLayer)       [(None, 256)]             0         \n",
      "_________________________________________________________________\n",
      "tf_bert_for_masked_lm (TFBer ((None, 256, 30522),)     110104890 \n",
      "_________________________________________________________________\n",
      "tf.__operators__.getitem (Sl (None, 30522)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 30523     \n",
      "=================================================================\n",
      "Total params: 110,135,413\n",
      "Trainable params: 30,523\n",
      "Non-trainable params: 110,104,890\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"/tf/saved_model/checkpoints/cp.ckpt\"\n",
    "model_reload = create_model()\n",
    "model_reload.load_weights(checkpoint_path)\n",
    "model_reload.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, encoder_layer_call_and_return_conditional_losses, encoder_layer_call_fn, pooler_layer_call_and_return_conditional_losses while saving (showing 5 of 1085). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, encoder_layer_call_and_return_conditional_losses, encoder_layer_call_fn, pooler_layer_call_and_return_conditional_losses while saving (showing 5 of 1085). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/michael/BERT/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/michael/BERT/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model_reload, export_dir='saved_model/michael/BERT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>S001</td>\n",
       "      <td>74</td>\n",
       "      <td>male</td>\n",
       "      <td>well there's a mother standing there washing ...</td>\n",
       "      <td>30</td>\n",
       "      <td>cc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>S002</td>\n",
       "      <td>62</td>\n",
       "      <td>female</td>\n",
       "      <td>somebody's getting cookies out_of the cookie ...</td>\n",
       "      <td>30</td>\n",
       "      <td>cc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>S003</td>\n",
       "      <td>69</td>\n",
       "      <td>female</td>\n",
       "      <td>okay . there's a little boy and he's standing...</td>\n",
       "      <td>29</td>\n",
       "      <td>cc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>S004</td>\n",
       "      <td>71</td>\n",
       "      <td>female</td>\n",
       "      <td>are you ready ? well the sink is overflowing ...</td>\n",
       "      <td>30</td>\n",
       "      <td>cc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>S005</td>\n",
       "      <td>74</td>\n",
       "      <td>female</td>\n",
       "      <td>okay . the mother's washing the dishes and th...</td>\n",
       "      <td>30</td>\n",
       "      <td>cc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    ID  Age    Gender  \\\n",
       "0           0  S001   74     male    \n",
       "1           1  S002   62   female    \n",
       "2           2  S003   69   female    \n",
       "3           3  S004   71   female    \n",
       "4           4  S005   74   female    \n",
       "\n",
       "                                                TEXT  MMSE Group  \n",
       "0   well there's a mother standing there washing ...    30    cc  \n",
       "1   somebody's getting cookies out_of the cookie ...    30    cc  \n",
       "2   okay . there's a little boy and he's standing...    29    cc  \n",
       "3   are you ready ? well the sink is overflowing ...    30    cc  \n",
       "4   okay . the mother's washing the dishes and th...    30    cc  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription_txt_file_path = \"/tf/data/\" + \"transcription_original_id_txt_mmse.csv\"\n",
    "filtered_merged_data = pd.read_csv(transcription_txt_file_path)\n",
    "filtered_merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" well there's a mother standing there washing the dishes and the sink is overflowing . and the window's open . and outside the window there's a curved walk with a garden . and you can see another building there . looks like a garage or something with curtains and the grass in the garden . and there are two cups and a saucer on the sink . and she's getting her feet wet from the overflow of the water from the sink . she seems to be oblivious to the fact that the sink is overflowing . she's also oblivious to the fact that her kids are stealing cookies out of the cookie jar . and the kid on the stool is gonna fall off the stool . he's standing up there in the cupboard taking cookies out of the jar , handing them to a girl about the same age . the kids are somewhere around seven or eight years old or nine . and the mother is gonna get shocked when he tumbles and the cookie jar comes down . and I think that's about all .\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_merged_data.TEXT[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_train = [bert_encoder(r) for r in filtered_merged_data[\"TEXT\"]]\n",
    "bert_lbl = filtered_merged_data[\"MMSE\"]\n",
    "bert_train = np.array(bert_train)\n",
    "sc_reviews, sc_segments, sc_masks = np.split(bert_train, 3, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>Group</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>S001</td>\n",
       "      <td>74</td>\n",
       "      <td>male</td>\n",
       "      <td>well there's a mother standing there washing ...</td>\n",
       "      <td>30</td>\n",
       "      <td>cc</td>\n",
       "      <td>26.000887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>S002</td>\n",
       "      <td>62</td>\n",
       "      <td>female</td>\n",
       "      <td>somebody's getting cookies out_of the cookie ...</td>\n",
       "      <td>30</td>\n",
       "      <td>cc</td>\n",
       "      <td>28.357553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>S003</td>\n",
       "      <td>69</td>\n",
       "      <td>female</td>\n",
       "      <td>okay . there's a little boy and he's standing...</td>\n",
       "      <td>29</td>\n",
       "      <td>cc</td>\n",
       "      <td>25.372938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>S004</td>\n",
       "      <td>71</td>\n",
       "      <td>female</td>\n",
       "      <td>are you ready ? well the sink is overflowing ...</td>\n",
       "      <td>30</td>\n",
       "      <td>cc</td>\n",
       "      <td>23.448494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>S005</td>\n",
       "      <td>74</td>\n",
       "      <td>female</td>\n",
       "      <td>okay . the mother's washing the dishes and th...</td>\n",
       "      <td>30</td>\n",
       "      <td>cc</td>\n",
       "      <td>26.735819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    ID  Age    Gender  \\\n",
       "0           0  S001   74     male    \n",
       "1           1  S002   62   female    \n",
       "2           2  S003   69   female    \n",
       "3           3  S004   71   female    \n",
       "4           4  S005   74   female    \n",
       "\n",
       "                                                TEXT  MMSE Group    predict  \n",
       "0   well there's a mother standing there washing ...    30    cc  26.000887  \n",
       "1   somebody's getting cookies out_of the cookie ...    30    cc  28.357553  \n",
       "2   okay . there's a little boy and he's standing...    29    cc  25.372938  \n",
       "3   are you ready ? well the sink is overflowing ...    30    cc  23.448494  \n",
       "4   okay . the mother's washing the dishes and th...    30    cc  26.735819  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = model_reload.predict(sc_reviews.squeeze(), batch_size=64)\n",
    "filtered_merged_data['predict'] = [x[0] if x[0] <= 30 else 30 for x in predict]\n",
    "filtered_merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  101,  2092,  2045, ...,     0,     0,     0],\n",
       "       [  101,  8307,  1005, ...,     0,     0,     0],\n",
       "       [  101,  3100,  1012, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  101,  2821,  2017, ...,     0,     0,     0],\n",
       "       [  101,  2017,  2215, ...,     0,     0,     0],\n",
       "       [  101,  1049, 14227, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc_reviews.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256,)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(sc_reviews.squeeze()[0]).reshape(1, 256).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[26.000887]], dtype=float32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_reload.predict(np.array(sc_reviews.squeeze()[0]).reshape(1, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>Group</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>S041</td>\n",
       "      <td>57</td>\n",
       "      <td>female</td>\n",
       "      <td>water's pouring out_of the sink . and the wom...</td>\n",
       "      <td>30</td>\n",
       "      <td>cc</td>\n",
       "      <td>26.420732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0    ID  Age    Gender  \\\n",
       "32          32  S041   57   female    \n",
       "\n",
       "                                                 TEXT  MMSE Group    predict  \n",
       "32   water's pouring out_of the sink . and the wom...    30    cc  26.420732  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_merged_data[filtered_merged_data.ID == 'S041']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: saved_model/michael/BERT/variables/variables.index to s3://w210-audio-files-bucket/bert/variables/variables.index\n",
      "upload: saved_model/michael/BERT/saved_model.pb to s3://w210-audio-files-bucket/bert/saved_model.pb\n",
      "upload: saved_model/michael/BERT/variables/variables.data-00000-of-00001 to s3://w210-audio-files-bucket/bert/variables/variables.data-00000-of-00001\n"
     ]
    }
   ],
   "source": [
    "!aws s3 sync /tf/saved_model/michael/BERT s3://w210-audio-files-bucket/bert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting SpeechRecognition\n",
      "  Downloading SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 32.8 MB 21.7 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: SpeechRecognition\n",
      "Successfully installed SpeechRecognition-3.8.1\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub\n",
      "Successfully installed pydub-0.25.1\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/home/ubuntu/model/data/S041.wav\"\n",
    "            \n",
    "audio_path = \"/tf/data/\" + os.path.basename(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the speech recognizer\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# a function that splits the audio file into chunks \n",
    "# and applies speech recognition \n",
    "def silence_based_conversion(path, wav_file): \n",
    "    text_df = pd.DataFrame()\n",
    "  \n",
    "    # open the audio file stored in \n",
    "    # the local system as a wav file. \n",
    "    song = AudioSegment.from_wav(path + wav_file) \n",
    "    print(song)\n",
    "  \n",
    "    # open a file where we will concatenate   \n",
    "    # and store the recognized text \n",
    "    text_file = wav_file.partition('.')[0] + \".txt\"\n",
    "    text_file_dir = path + \"output_text/\" \n",
    "    if not os.path.exists(text_file_dir):\n",
    "        os.makedirs(text_file_dir)    \n",
    "    text_file_path = text_file_dir + text_file\n",
    "    fh = open(text_file_path, \"w+\") \n",
    "          \n",
    "\n",
    "    dBFS = song.dBFS\n",
    "    print('dBFS: ' + str(dBFS))\n",
    "    # chunks = split_on_silence(song, \n",
    "    #     min_silence_len = 500,\n",
    "    #     silence_thresh = dBFS-16,\n",
    "    #     keep_silence = 250 \n",
    "    # )\n",
    "\n",
    "    # split track where silence is 0.5 seconds  \n",
    "    # or more and get chunks \n",
    "    chunks = split_on_silence(song, \n",
    "        # must be silent for at least 0.5 seconds \n",
    "        # or 500 ms. adjust this value based on user \n",
    "        # requirement. if the speaker stays silent for  \n",
    "        # longer, increase this value. else, decrease it. \n",
    "        min_silence_len = 250, \n",
    "  \n",
    "        # consider it silent if quieter than -16 dBFS \n",
    "        # adjust this per requirement \n",
    "        silence_thresh = dBFS - 16\n",
    "        # keep_silence = 250\n",
    "    ) \n",
    "    # setting minimum length of each chunk to 25 seconds\n",
    "    target_length = 20 * 1000 \n",
    "    output_chunks = [chunks[0]]\n",
    "    for chunk in chunks[1:]:\n",
    "      print('Length of chunk: ' + str(len(output_chunks[-1])) )\n",
    "      if len(output_chunks[-1]) < target_length:\n",
    "        output_chunks[-1] += chunk\n",
    "      else:\n",
    "        # if the last output chunk is longer than the target length,\n",
    "        # we can start a new one\n",
    "        output_chunks.append(chunk)    \n",
    "    # print(chunks)\n",
    "  \n",
    "    # create a directory to store the audio chunks. \n",
    "    try: \n",
    "        os.mkdir(path + 'bert_audio_chunks') \n",
    "    except(FileExistsError): \n",
    "        pass\n",
    "  \n",
    "    # move into the directory to \n",
    "    # store the audio files. \n",
    "    os.chdir(path +'bert_audio_chunks') \n",
    "  \n",
    "    i = 0\n",
    "    transcript = ''\n",
    "    # process each chunk \n",
    "    for chunk in output_chunks: \n",
    "              \n",
    "        # Create 0.5 seconds silence chunk \n",
    "        chunk_silent = AudioSegment.silent(duration = 10) \n",
    "  \n",
    "        # add 0.5 sec silence to beginning and  \n",
    "        # end of audio chunk. This is done so that \n",
    "        # it doesn't seem abruptly sliced. \n",
    "        audio_chunk = chunk_silent + chunk + chunk_silent \n",
    "  \n",
    "        # export audio chunk and save it in  \n",
    "        # the current directory. \n",
    "        text_file_id = text_file.partition('.')[0]\n",
    "        chunk_file_name = text_file_id + \"_\" + \"chunk\" + str(i) + \".wav\"\n",
    "        print(\"saving \" + chunk_file_name) \n",
    "        # specify the bitrate to be 192 k \n",
    "        audio_chunk.export(\"./\" + chunk_file_name, bitrate ='192k', format =\"wav\") \n",
    "  \n",
    "        # the name of the newly created chunk \n",
    "        filename = chunk_file_name\n",
    "  \n",
    "        print(\"Processing chunk file: \" + filename) \n",
    "  \n",
    "        # get the name of the newly created chunk \n",
    "        # in the AUDIO_FILE variable for later use. \n",
    "        file = filename \n",
    "  \n",
    "        # create a speech recognition object \n",
    "        r = sr.Recognizer() \n",
    "  \n",
    "        # recognize the chunk \n",
    "        with sr.AudioFile(file) as source: \n",
    "            # remove this if it is not working \n",
    "            # correctly. \n",
    "            #r.adjust_for_ambient_noise(source) \n",
    "            audio_listened = r.record(source) \n",
    "  \n",
    "        try: \n",
    "            # try converting it to text \n",
    "            rec = r.recognize_google(audio_listened) \n",
    "            # write the output to the file. \n",
    "#             fh.write(rec+\". \") \n",
    "#             text_df = text_df.append({'ID': text_file_id, 'Text': rec}, ignore_index = True)\n",
    "            transcript = transcript + rec + ' '\n",
    "        # catch any errors. \n",
    "        except sr.UnknownValueError: \n",
    "            print(\"Could not understand audio\") \n",
    "  \n",
    "        except sr.RequestError as e: \n",
    "            print(\"Could not request results. check your internet connection\") \n",
    "  \n",
    "        i += 1\n",
    "    shutil.rmtree(path + 'bert_audio_chunks')     \n",
    "    return transcript\n",
    "\n",
    "# silence_based_conversion(audio_path_cc, 'S001.wav')        \n",
    "# text_df = silence_based_conversion(audio_path_cd, 'S079.wav')        \n",
    "# print(text_df)\n",
    "# silence_based_conversion(audio_path_cc + 'spkr0.wav')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pydub.audio_segment.AudioSegment object at 0x7f05bc7dbf60>\n",
      "dBFS: -30.995559274792225\n",
      "Length of chunk: 2185\n",
      "Length of chunk: 4442\n",
      "Length of chunk: 10851\n",
      "Length of chunk: 13546\n",
      "Length of chunk: 15626\n",
      "Length of chunk: 19261\n",
      "Length of chunk: 20252\n",
      "Length of chunk: 1474\n",
      "Length of chunk: 3874\n",
      "Length of chunk: 5254\n",
      "Length of chunk: 7643\n",
      "Length of chunk: 8832\n",
      "Length of chunk: 12535\n",
      "Length of chunk: 13921\n",
      "Length of chunk: 14996\n",
      "Length of chunk: 19556\n",
      "Length of chunk: 22148\n",
      "Length of chunk: 1132\n",
      "Length of chunk: 2829\n",
      "Length of chunk: 4079\n",
      "Length of chunk: 8412\n",
      "Length of chunk: 9717\n",
      "saving S041_chunk0.wav\n",
      "Processing chunk file: S041_chunk0.wav\n",
      "saving S041_chunk1.wav\n",
      "Processing chunk file: S041_chunk1.wav\n",
      "saving S041_chunk2.wav\n",
      "Processing chunk file: S041_chunk2.wav\n"
     ]
    }
   ],
   "source": [
    "transcript = silence_based_conversion(\"/tf/data/\" , os.path.basename(file_path))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"water pouring out of the sink and the woman is washing dishes the child is a honest or falling off as he's reaching for the cookie jar was right hand and Friday and the other cookies to a little girl who's reaching up with her left hand to get the cookie and her rice and looks like she's almost trying to make us signal Silence of the mother doesn't hear it from others was here in the water is it pouring on the floor and the window is open you can see a yard outside is Edition cups on this thing and the curtains are pulled back to you can see out the window the cupboard doors open and they're all fully dressed and they have sort of a nondescript expression on her face the woman has her mouth open a little bit which wasn't having other than a little bit \""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript = \"water pouring out of the sink and the woman is washing dishes the child is a honest or falling off as he's reaching for the cookie jar was right hand and Friday and the other cookies to a little girl who's reaching up with her left hand to get the cookie and her rice and looks like she's almost trying to make us signal Silence of the mother doesn't hear it from others was here in the water is it pouring on the floor and the window is open you can see a yard outside is Edition cups on this thing and the curtains are pulled back to you can see out the window the cupboard doors open and they're all fully dressed and they have sort of a nondescript expression on her face the woman has her mouth open a little bit which wasn't having other than a little bit \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript = [transcript]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"water pouring out of the sink and the woman is washing dishes the child is a honest or falling off as he's reaching for the cookie jar was right hand and Friday and the other cookies to a little girl who's reaching up with her left hand to get the cookie and her rice and looks like she's almost trying to make us signal Silence of the mother doesn't hear it from others was here in the water is it pouring on the floor and the window is open you can see a yard outside is Edition cups on this thing and the curtains are pulled back to you can see out the window the cupboard doors open and they're all fully dressed and they have sort of a nondescript expression on her face the woman has her mouth open a little bit which wasn't having other than a little bit \"]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_name,\n",
    "                                        add_special_tokens=True,\n",
    "                                        do_lower_case=True,\n",
    "                                        max_length=256,\n",
    "                                        pad_to_max_length=True)\n",
    "def bert_encoder(input_text):\n",
    "    # txt = input_text.numpy().decode('utf-8')\n",
    "    txt = input_text\n",
    "    encoded = tokenizer.encode_plus(txt, add_special_tokens=True, \n",
    "                                    max_length=256, \n",
    "                                    pad_to_max_length=True, \n",
    "                                    return_attention_mask=True, \n",
    "                                    return_token_type_ids=True,\n",
    "                                    truncation=True)\n",
    "    return encoded['input_ids'], encoded['token_type_ids'], \\\n",
    "        encoded['attention_mask']\n",
    "\n",
    "bert_train = [bert_encoder(r) for r in transcript]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_train = np.array(bert_train)\n",
    "sc_reviews, sc_segments, sc_masks = np.split(bert_train, 3, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25.492697]], dtype=float32)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_reload.predict(sc_reviews.squeeze().reshape(1, 256), batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.dumps({\n",
    "        \"instances\": sc_reviews.squeeze().reshape(1, 256).tolist()\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"content-type\": \"application/json\"}\n",
    "response = requests.post('http://' + 'model_server' + ':8501/v1/models/bert:predict', data=data, headers=headers, \n",
    "                         timeout=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"predictions\": [[25.4926872]\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
